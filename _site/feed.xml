<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Vitor Meriat</title>
    <description></description>
    <link>/</link>
    <atom:link href="/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Sun, 16 Apr 2017 21:08:28 -0300</pubDate>
    <lastBuildDate>Sun, 16 Apr 2017 21:08:28 -0300</lastBuildDate>
    <generator>Jekyll v3.4.0</generator>
    
      <item>
        <title>Hello World R - Da base à Regressão Linear</title>
        <description>&lt;p&gt;A linguagem R é um projeto GNU de software livre. O &lt;strong&gt;R&lt;/strong&gt; derivou de uma linguagem chamada &lt;strong&gt;S&lt;/strong&gt; (de “statistics”), criada na &lt;strong&gt;Bell Laboratories&lt;/strong&gt; nos anos 70. Esta é uma linguagem usada por programadores e cientistas de dados para computação estatística.&lt;/p&gt;

&lt;p&gt;R foi desenvolvida por estatísticos para estatística, dado seu foco na resolução de problemas matemáticos, ele possui um estrutura simples o que facilita a implementação e traz ganhos na otimização no tempo de desenvolvimento. Você pode obter todas as referncias na documentação oficial em &lt;a href=&quot;https://www.rdocumentation.org/&quot;&gt;rdocumentation.org&lt;/a&gt;, fora que é possível contar com um riquíssimo ecossistema de pacotes para diferentes áreas de aplicação.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Para começar vamos criar um exemplo de regressão linear, uma espécie de &lt;strong&gt;“Hello World”&lt;/strong&gt; da computação estatística. Então, mãos a obra…&lt;/p&gt;

&lt;h2 id=&quot;regressão-linear&quot;&gt;Regressão Linear&lt;/h2&gt;

&lt;p&gt;A regressão linear é uma técnica estatística usada para descrever a relação entre uma variável numérica (na estatística, chamada de variável dependente) e uma ou mais variáveis explicativas (chamadas de variáveis independentes) que podem ser numéricas ou categóricas. Quando há apenas uma única variável explicativa/de previsão, a técnica é chamada de regressão linear simples. Quando houver duas ou mais variáveis independentes, a técnica é chamada de regressão linear múltipla.&lt;/p&gt;

&lt;p&gt;Para iniciar vamos começar importando o arquivo de texto que será utilizado no exemplo.&lt;/p&gt;

&lt;pre style=&quot;font-size: 1.6em !important&quot;&gt;
    &lt;code class=&quot;r&quot;&gt;
    data &amp;lt;- read.table(&quot;sementes.txt&quot;, header=TRUE, sep=&quot;,&quot;)
    &lt;/code&gt;
&lt;/pre&gt;

&lt;p&gt;No trecho de código acima estamos utilizando a importação de um &lt;strong&gt;TXT&lt;/strong&gt; como DataSet. Na operação que estamos utilizando, podemos observar que a linguagem &lt;strong&gt;R&lt;/strong&gt; usa parâmetros nomeados. O parâmetro de cabeçalho informa se a primeira linha é de cabeçalho ou não. O parâmetro &lt;strong&gt;sep&lt;/strong&gt; (separador) indica como os valores em cada linha são separados. Por exemplo, (\t) indica valores delimitados por tabulação, e (“ “) indica valores delimitados por espaço.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;O R diferencia maiúsculas de minúsculas e você geralmente pode usar o operador (&amp;lt;-) para atribuir valores, ou o operador (=). Essa escolha é uma questão de preferência pessoal, já que ambos exercem a mesma função. Tipicamente, a boa prática aponta para o uso do operador (&amp;lt;-) na atribuição de objetos e (=) para atribuição de valores de parâmetro.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Para se trabalhar com o &lt;strong&gt;CSV&lt;/strong&gt;, formato mais comun nestes casos, seria tão simples quanto passar o caminho do arquivo.&lt;/p&gt;

&lt;pre style=&quot;font-size: 1.6em !important&quot;&gt;
    &lt;code class=&quot;r&quot;&gt;
    data &amp;lt;- read.csv(&quot;sementes.csv&quot;)
    &lt;/code&gt;
&lt;/pre&gt;

&lt;p&gt;Vamos olhar a estrutura de nosso arquivo. Se trata de uma listagem de sementes classificada por cor, comprimento, largura e índice de nutrientes. Nosso objetivo aqui é prever os valores da coluna nutrientes com base nos dados anteriores da semente.&lt;/p&gt;

&lt;p&gt;Uma vez que temos nosso arquivo carregado, podemos utilizar alguns comandos a fim de vizualizar o nosso conjunto de dados.&lt;/p&gt;

&lt;pre style=&quot;font-size: 1.6em !important&quot;&gt;
    &lt;code class=&quot;r&quot;&gt;
    # Exibe o shape dos dados
    dim(data)

    # Concatena duas strings
    paste(&quot;Linhas: &quot;, dim(data)[1], sep=&quot; &quot;)
    paste(&quot;Colunas: &quot;, dim(data)[2], sep=&quot; &quot;)

    # Exibe o dados
    print(data)
    &lt;/code&gt;
&lt;/pre&gt;

&lt;p&gt;A primeira função exibe a estrutura básica dos dados, retornando a quantidade de linhas e colunas do dataset. Notem que estou utilizando a função &lt;strong&gt;paste()&lt;/strong&gt; para concatenar duas strings. Aqui podemos ver que o resultado pode ser lido como um &lt;strong&gt;array&lt;/strong&gt;, onde tenho na posição 1 o primeiro item, e na posição 2 o segundo item. Depois apenas nomeio qual é a coluna e qual é a linha. A próxima função irá exibir os dados como extraído do arquivo. Usamos a função &lt;strong&gt;print()&lt;/strong&gt; para exibir qualquer saída para o nosso programa.&lt;/p&gt;

&lt;p&gt;Nossa saída seria algo como o que se segue abaixo:&lt;/p&gt;

&lt;pre style=&quot;font-size: 1.2em !important&quot;&gt;
    &lt;code class=&quot;r&quot;&gt;
    8 4

    'Linhas:  8'
    'Colunas:  4'

       Color Length Width Nutrients
    1   blue    5.4   1.8       0.9
    2   blue    4.8   1.5       0.7
    3   blue    4.9   1.6       0.8
    4 yellow    5.0   1.9       0.4
    5 yellow    5.2   1.5       0.3
    6 yellow    4.7   1.9       0.4
    7  green    3.7   2.2       1.4
    8  green    4.2   1.9       1.2
    &lt;/code&gt;
&lt;/pre&gt;

&lt;blockquote&gt;
  &lt;p&gt;Observe que a saída acima exibe os índices do &lt;strong&gt;array de dados, começando em 1&lt;/strong&gt;. Este é um ponto importante a se notar, já que na maioria das linguagens estamos acostumados com os índices de &lt;strong&gt;base 0&lt;/strong&gt;, como em C# ou Python.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Agora vamos executar a análise da função de &lt;strong&gt;Modelo Linear&lt;/strong&gt;. Para isso execute os comandos abaixo:&lt;/p&gt;

&lt;pre style=&quot;font-size: 1.4em !important&quot;&gt;
    &lt;code class=&quot;r&quot;&gt;
  model &amp;lt;- lm(data$Nutrients ~ (data$Color + data$Length + data$Width))

  summary(model)
    &lt;/code&gt;
&lt;/pre&gt;

&lt;p&gt;Neste trecho de código temos a variável &lt;strong&gt;model&lt;/strong&gt; que é o resultado da nossa análise de regressão linear. Aqui estamos usando a função &lt;strong&gt;lm()&lt;/strong&gt; &lt;strong&gt;(linear model)&lt;/strong&gt;, na qual temos a &lt;strong&gt;variável dependente&lt;/strong&gt; a ser prevista (data$Nutrients), e as variáveis independentes, a saber: &lt;strong&gt;data$Color, data$Length, data$Width&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;O próximo commando &lt;strong&gt;(summary(model))&lt;/strong&gt;, vai exibir o resultádo básico formatado da análise que foi armazenda no objeto model. Teremos a seguinte saída para o código acima:&lt;/p&gt;

&lt;pre style=&quot;font-size: 1.2em !important&quot;&gt;
    &lt;code class=&quot;r&quot;&gt;
  Call:
  lm(formula = data$Nutrients ~ (data$Color + data$Length + data$Width))

  Residuals:
          1         2         3         4         5         6         7         8
   0.009418 -0.030030  0.020611 -0.028320  0.044164 -0.015844  0.042596 -0.042596

  Coefficients:
                   Estimate Std. Error t value Pr(&amp;gt;|t|)   
  (Intercept)      -0.14758    0.48286  -0.306  0.77986   
  data$Colorgreen   0.35672    0.09990   3.571  0.03754 *
  data$Coloryellow -0.49083    0.04507 -10.891  0.00166 **
  data$Length       0.04159    0.07876   0.528  0.63406   
  data$Width        0.45200    0.11973   3.775  0.03255 *
  ---
  Signif. codes:  0 ‘\***\’ 0.001 ‘\**\’ 0.01 ‘\*\’ 0.05 ‘.’ 0.1 ‘ ’ 1

  Residual standard error: 0.05179 on 3 degrees of freedom
  Multiple R-squared:  0.9927,	Adjusted R-squared:  0.9829
  F-statistic: 101.6 on 4 and 3 DF,  p-value: 0.00156
    &lt;/code&gt;
&lt;/pre&gt;

&lt;p&gt;Olhando para o nosso conjunto de dados responda a seguinte pergunta: Qual seria o valor de &lt;u&gt;Nutrientes&lt;/u&gt; para uma determinada semente se a &lt;u&gt;cor&lt;/u&gt; da mesma fosse &lt;u&gt;yellow&lt;/u&gt; e suas &lt;u&gt;largura&lt;/u&gt; e &lt;u&gt;altura&lt;/u&gt; fossem &lt;u&gt;1.9&lt;/u&gt; e &lt;u&gt;4.7&lt;/u&gt; respectivamente?&lt;/p&gt;

&lt;p&gt;E ai? Já sabe a resposta?&lt;/p&gt;

&lt;p&gt;Olhando para o nosso dataset é fácil de responder esta pergunta. Estamos falando do item &lt;u&gt;[6]&lt;/u&gt; de nossa lista. Sendo assim sabemos que o valor de nutrientes será &lt;u&gt;0.4&lt;/u&gt;.&lt;/p&gt;

&lt;p&gt;Agora queremos &lt;u&gt;prever&lt;/u&gt; este valor usando nosso modelo. Como faremos isso?&lt;/p&gt;

&lt;p&gt;Vamos olhar para o resultado da análse que fizemos anteriormente. Em Coefficients vamos utilizar apenas a primeira e segunda colunas. Temos aqui nossas variáveis independetes e suas estimativas.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Vale notar que temos uma constante chamada (Intercept), não associada a qualquer variável.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Quando você tem variáveis explicativas categóricas, um dos valores é descartado. Em nosso caso o valor escolhido foi o blue.&lt;/p&gt;

&lt;p&gt;Para fazer uma previsão usando o modelo, é necessário calcular a soma linear dos valores das estimativas multiplicados pelos valores correspondentes em relação as variáveis independentes. Em nosso caso a equação seria:&lt;/p&gt;

&lt;pre style=&quot;font-size: 1.2em !important&quot;&gt;
    &lt;code class=&quot;r&quot;&gt;
  -0.14758 + (0.35672 * 0) + (-0.49083 * 1) + (0.04159 * 4.7) + (0.45200 * 1.9)
    &lt;/code&gt;
&lt;/pre&gt;

&lt;p&gt;Vamos entender como chegar neste resultado. Com base nos quadro abaixo fica mais simples compreender:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;NA&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;yellow&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;green&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Length&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Width&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;-0.14758&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.35672&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;-0.49083&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.04159&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.45200&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;div style=&quot;margin-bottom: 5em;&quot;&gt;&lt;/div&gt;

&lt;p&gt;Primeiro listamos os valores da coluna Estimate. Depois para cada valor, multiplicamos a variável correspondente. No caso do primeiro valor estamos falando da constante Intercept, logo não existe valor a ser multiplicado. Para o segundo valor, temos como resultado &lt;u&gt;(0.35672 * 0)&lt;/u&gt;. É o sugundo valor multiplicado por 0, já que nossa previsão não inclui a variável green. Multiplicamos o valor de data$Length, 0.04159 por 4.7 e temos (0.04159 * 4.7). A mesma lógica para data$Width e temos (0.45200 * 1.9).&lt;/p&gt;

&lt;p&gt;O resultado será 0.415863, um valor muito próximo de 0.40, que é o valor real descrito no arquivo.&lt;/p&gt;

&lt;p&gt;Na saída acima temos uma sessão, iniciada com &lt;u&gt;Residual standard error&lt;/u&gt;. Aqui temos a relação entre as variáveis independentes e a variável dependente.&lt;/p&gt;

&lt;pre style=&quot;font-size: 1.2em !important&quot;&gt;
    &lt;code class=&quot;r&quot;&gt;
  Residual standard error: 0.05179 on 3 degrees of freedom
  Multiple R-squared:  0.9927,	Adjusted R-squared:  0.9829
  F-statistic: 101.6 on 4 and 3 DF,  p-value: 0.00156
    &lt;/code&gt;
&lt;/pre&gt;

&lt;p&gt;O valor de &lt;u&gt;Multiple R-squared (0,9927)&lt;/u&gt; é a porcentagem de variação na variável dependente explicada pela combinação linear das variáveis independentes. Neste caso os valores de R-squared são valores entre 0 e 1, onde os valores mais altos significam um modelo de previsão melhor. Em nosso caso, R-squared tem um valor extremamente alto, indicando que Color, Length e Width podem prever o resultado com boa precisão. F-statistic, Adjusted R-squared e p-value são outras medidas de ajuste do modelo.&lt;/p&gt;

&lt;h2 id=&quot;referências&quot;&gt;Referências&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.rdocumentation.org/&quot;&gt;rdocumentation.org&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Linear_regression&quot;&gt;Linear Regression&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;style type=&quot;text/css&quot;&gt;
table {
	color:#333333;
	border-width: 1px;
	border-collapse: collapse;
}
table th {
	border-width: 1px;
	padding: 12px;
	border-style: solid;
	background-color: #dedede;
}
table td {
	border-width: 1px;
	padding: 8px;
	border-style: solid;
	background-color: #ffffff;
}
&lt;/style&gt;

</description>
        <pubDate>Fri, 14 Apr 2017 00:00:00 -0300</pubDate>
        <link>/2017/04/14/hello-world-r/</link>
        <guid isPermaLink="true">/2017/04/14/hello-world-r/</guid>
        
        
        <category>R</category>
        
        <category>Data Science</category>
        
      </item>
    
      <item>
        <title>Devops Summit Brasil 2017 - Minha palestra sobre Azure Cognitive Services</title>
        <description>&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://meriatblob.blob.core.windows.net/images/2017/04/01/palestra-0.jpg&quot; class=&quot;absolute-bg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Como o prometido, vou fazer um compliado do que vimos na minha apresentação sobre Azure Cognitive Services no DevOpsSummit Brasil 2017.&lt;/p&gt;

&lt;p&gt;A ideia era apresentar a plataforma, entendendo o que são serviços cognitivos, sua importância e como eles foram incorporados e distribuídos no ecossistema da Microsoft.&lt;/p&gt;

&lt;h2 id=&quot;cognitive-services--ai&quot;&gt;Cognitive Services &amp;amp; AI&lt;/h2&gt;
&lt;p&gt;Como vimos, intligência artificial não é um assunto novo, pelo contrário, estamos falando de um assunto que vem assombrando o imaginário humano nos últimos 100 anos, e pesquisado academicamente hà mais de 5 décadas.&lt;/p&gt;

&lt;p&gt;Neste mundo de AI, os serviços cognitivos estão ligados as aplicações voltadas a proximidade da linguagem natural. Temos de analise de sentimento a visão computacional, tudo de forma simples e fácil, como uma API deve ser.&lt;/p&gt;

&lt;h2 id=&quot;o-evento&quot;&gt;O evento&lt;/h2&gt;
&lt;p&gt;O evento ocorreu na sede da Microsoft em São Paulo, e foi dividido em 4 trilhas:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;TECNOLOGIAS NA NUVEM&lt;/li&gt;
  &lt;li&gt;DESENVOLVIMENTO MODERNO&lt;/li&gt;
  &lt;li&gt;MELHORIA CONTÍNUA&lt;/li&gt;
  &lt;li&gt;PRÁTICAS E PROCESSOS&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Tive a honra de palestrar na trilha de &lt;strong&gt;Desenvolvimento Moderno&lt;/strong&gt; explorando um tema que tem gerado muito interesse nos últimos tempos: Computação Cognitiva.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://meriatblob.blob.core.windows.net/images/2017/04/01/palestra-1.jpg&quot; class=&quot;absolute-bg&quot; /&gt;&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://meriatblob.blob.core.windows.net/images/2017/04/01/palestra-2.jpg&quot; class=&quot;absolute-bg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Vale lembrar que mesmo não tendo tempo para todas as demonstrações, conseguimos rodar a API de &lt;strong&gt;Face Detect&lt;/strong&gt;, o resultado foi o seguinte:&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://meriatblob.blob.core.windows.net/images/2017/04/01/demo-final.png&quot; class=&quot;absolute-bg&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;os-materiais&quot;&gt;Os materiais&lt;/h2&gt;

&lt;p&gt;Todas as demos utilizadas na apresentação foram consumindo apenas a &lt;strong&gt;API REST&lt;/strong&gt;, cuja a documentação está disponível em: &lt;a href=&quot;https://www.microsoft.com/cognitive-services/en-us/documentation&quot;&gt;Cognitive Services Documentation&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;O código apresentado já está disponível no meu GitHub no repositório &lt;a href=&quot;https://github.com/vitormeriat/cognitive-services&quot;&gt;Cognitive Services&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Vale lembrar que neste repositório vou colocar vários testes incluindo outras plataformas de Cloud.&lt;/p&gt;

&lt;p&gt;Abaixo é só clicar na imagem para baixar ou visualizar os slides da apresentação.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;a href=&quot;//www.slideshare.net/VitorMeriat/devopssummit-2017-azure-cognitive-services&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://meriatblob.blob.core.windows.net/images/2017/04/01/devops-summit-brasil-ppt.jpg&quot; class=&quot;absolute-bg&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;No próximo post&lt;/p&gt;

&lt;div style=&quot;margin-bottom: 5em;&quot;&gt;&lt;/div&gt;

&lt;h3 id=&quot;até-a-próxima-pessoal-&quot;&gt;Até a próxima pessoal ;)&lt;/h3&gt;
</description>
        <pubDate>Sat, 01 Apr 2017 00:00:00 -0300</pubDate>
        <link>/2017/04/01/devopssummitbrasil-azure-cognitive-services/</link>
        <guid isPermaLink="true">/2017/04/01/devopssummitbrasil-azure-cognitive-services/</guid>
        
        
        <category>IA</category>
        
        <category>Cognitive Computing</category>
        
        <category>Microsoft Azure</category>
        
        <category>Python</category>
        
        <category>Palestras</category>
        
        <category>Comunidade</category>
        
      </item>
    
      <item>
        <title>Kaggle Competition - Titanic: Machine Learning from Disaster</title>
        <description>&lt;p&gt;&lt;img style=&quot;width: 100%;&quot; src=&quot;http://blob.vitormeriat.com.br/images/2017/03/18/capa.jpg&quot; class=&quot;absolute-bg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;O &lt;strong&gt;Projeto Titanic&lt;/strong&gt; é uma competição de &lt;strong&gt;Data Science&lt;/strong&gt; promovida pelo &lt;a href=&quot;kaggle.com&quot;&gt;Kaggle.com&lt;/a&gt;. O objetivo deste desafio é deduzir os índices de sobrevivência dos passageiros do Titanic.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Embora os &lt;a href=&quot;https://www.youtube.com/watch?v=JVgkvaDHmto&quot;&gt;Mythbusters&lt;/a&gt; em seu programa tenham provado completamente que era possível Jack e Rose ter sobrevivido utilizando a porta flutuante, o interesse aqui é medir a chance real de sobrevivência dos passageiros a bordo do Titanic em 14 de abril de 1912.&lt;/p&gt;

&lt;p&gt;A história do Titanic é muito conhecida, tendo originado diversos livros, filmes, HQs e afins. É válido lembrar que a história narrada de forma célebre por James Cameron em seu filme de 1997, ilustra perfeitamente o motivo deste desafio. Vamos começar com uma breve perspectiva sobre o tema: Em Abril de 1912 o Titanic zarpou rumo a New York com 2224 passageiros, dos quais estima-se que apenas 710 tenham sobrevivido.&lt;/p&gt;

&lt;p&gt;É aqui que entra nosso desafio: Desenvolver um padrão simples para identificar o perfil dos sobreviventes deste desastre.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Nota: Muitos dos barcos salva-vidas não estavam com a sua capacidade máxima de pessoas a bordo. Se estivessem, seria possível salvar 53,4% dos passageiros, mas apenas 31,6% deles sobreviveram.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Neste caso não temos complicação com elementos aleatórios de sorte. A maioria dos sobreviventes eram mulheres, crianças e pessoas da alta sociedade.&lt;/p&gt;

&lt;h1 id=&quot;start&quot;&gt;Start&lt;/h1&gt;

&lt;p&gt;A lista de sobreviventes e não sobreviventes já foi transformada em dois datasets, &lt;strong&gt;train.csv&lt;/strong&gt; e &lt;strong&gt;test.csv&lt;/strong&gt;. Existe apenas uma diferença entre os dois arquivos, a lista de status de sobrevivência que está presente apenas nos dados de &lt;strong&gt;treino&lt;/strong&gt;. Nos dados de teste este valor precisa ser deduzido.&lt;/p&gt;

&lt;p&gt;Neste desafio vamos utilizar os dados do site Kaggle para desenvolver três modelos (regressão logística, árvore de probabilidade condicional e florestas aleatórias), a fim de prever as taxas de sobrevivência para os passageiros do Titanic.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;http://blob.vitormeriat.com.br/images/2017/03/18/decision-tree.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;O conjunto de teste conta com 418 passageiros e o conjunto de treinamento é composto por 891 passageiros. O conjunto de dados é composto por:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Class&lt;/li&gt;
  &lt;li&gt;Name&lt;/li&gt;
  &lt;li&gt;Sex&lt;/li&gt;
  &lt;li&gt;Age&lt;/li&gt;
  &lt;li&gt;Sibling/Spouse&lt;/li&gt;
  &lt;li&gt;Parents/Children&lt;/li&gt;
  &lt;li&gt;Ticket (*)&lt;/li&gt;
  &lt;li&gt;Fare&lt;/li&gt;
  &lt;li&gt;Cabin (*)&lt;/li&gt;
  &lt;li&gt;Port of Embarkment.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Como na maioria das competições Kaggle, você recebe dois conjuntos de dados:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Um conjunto de treino completo com o resultado (outcome ou target variable), para um grupo de passageiros, bem como uma coleção de outros parâmetros, como sua idade, sexo, etc. Este é o conjunto de dados em que você deve treinar seu modelo preditivo.&lt;/li&gt;
  &lt;li&gt;Um conjunto de teste, para o qual você deve prever a variável de destino agora desconhecida com base nos outros atributos de passageiros que são fornecidos para ambos os conjuntos de dados.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Este é um ótimo ponto de entrada para aprender machine learning com um conjunto de dados pequeno, gerenciável, interessante e com variáveis ​​de fácil compreensão.&lt;/p&gt;

&lt;h1 id=&quot;passo-1&quot;&gt;Passo 1&lt;/h1&gt;
&lt;p&gt;O colapso do “Titanic” está associada com a regra não escrita do salvamento no mar: “mulheres e crianças primeiro”.&lt;/p&gt;

&lt;p&gt;Nesta tarefa, os competidores precisam analisar a probabilidade de sobrevivência das diferentes categorias de passageiros.&lt;/p&gt;

&lt;p&gt;Para determinar se o passageiro sobreviveu ao “Titanic”, vamos usar uma árvore de decisão. Uma árvore de decisão é gerada automaticamente com base no parâmetro de entrada. A imagem abaixo mostra um exemplo de uma árvore de decisão é criada.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;http://blob.vitormeriat.com.br/images/2017/03/18/decision-tree02.jpg&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;o-repositório&quot;&gt;O repositório&lt;/h1&gt;
&lt;p&gt;Você pode olhar o código completo acessando o mesmo no repositório &lt;strong&gt;Meriat Machine Learning Notes&lt;/strong&gt; no meu Github.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/vitormeriat/meriat-ml-notes/blob/master/Titanic%20-%20Machine%20Learning%20from%20Disaster.ipynb&quot;&gt;Titanic: Machine Learning from Disaster&lt;/a&gt;&lt;/p&gt;

&lt;div style=&quot;margin-bottom: 5em;&quot;&gt;&lt;/div&gt;

&lt;h3 id=&quot;até-a-próxima-pessoal-&quot;&gt;Até a próxima pessoal ;)&lt;/h3&gt;
</description>
        <pubDate>Sat, 18 Mar 2017 00:00:00 -0300</pubDate>
        <link>/2017/03/18/titanic-machine-learning-from-disaster/</link>
        <guid isPermaLink="true">/2017/03/18/titanic-machine-learning-from-disaster/</guid>
        
        
        <category>IA</category>
        
        <category>Machine Learning</category>
        
        <category>Data Science</category>
        
        <category>Deep Learning</category>
        
        <category>Jupyter Notebook</category>
        
        <category>Python</category>
        
      </item>
    
      <item>
        <title>Apresentando o Meriat Machine Learning Notes</title>
        <description>&lt;p&gt;&lt;img style=&quot;width: 100%;&quot; src=&quot;http://blob.vitormeriat.com.br/images/2017/02/15/capa.jpg&quot; class=&quot;absolute-bg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;No último ano tive a oportunidade de trabalhar em projetos envolvendo IoT e Machine Learning. No processo entre aplicação, estudos e desenvolvimento, acabei separando algum material e exemplos que me ajudaram a inicar nesta carreira, bem como no processo de aprendizagem.&lt;/p&gt;

&lt;p&gt;O Meriat Machine Learning Notes nada mais é que um compendio destes estudos que resolvi compartilhar no github utilizando o Jupyter Notebook.&lt;/p&gt;

&lt;p&gt;Minha opção pelo &lt;strong&gt;Jupyter Notebook&lt;/strong&gt;, dentre tantos motivos, se dá pelo fato de conseguir de forma simples documentar e visualizar todo o código e anotações de forma simples. Vale dizer que o código que estou utilizando pode ser facilmente utilizado em outra IDE, conforme sua preferência.&lt;/p&gt;

&lt;p&gt;Algumas implementações são reprodução de exercícios dos quais eu irei apontar o material base.&lt;/p&gt;

&lt;p&gt;O material ainda está em formação, visto que ainda tenho um longo caminho a percorrer. É possível que futuramente eu altere o repositório, já que alguns estudos podem gerar um repositório separado.&lt;/p&gt;

&lt;p&gt;Por hora vou concentrando meus esforços por aqui ;)&lt;/p&gt;

&lt;h3 id=&quot;github&quot;&gt;Github&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;Study Notes on machine learning, data analysis, algorithms and best practices using Python and Jupyter Notebook.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/vitormeriat/meriat-ml-notes&quot;&gt;Meriat Machine Learning Note&lt;/a&gt;&lt;/p&gt;

&lt;div style=&quot;margin-bottom: 8em;&quot;&gt;&lt;/div&gt;

&lt;h2 id=&quot;meriat-machine-learning-note&quot;&gt;Meriat Machine Learning Note&lt;/h2&gt;

&lt;p&gt;A estrutura atual está descrita logo abaixo. Vou me esforçar para manter atualizada.&lt;/p&gt;

&lt;h4 id=&quot;file-handling&quot;&gt;File Handling&lt;/h4&gt;
&lt;p&gt;TBA&lt;/p&gt;

&lt;h4 id=&quot;sms-spam-filtering&quot;&gt;SMS Spam Filtering&lt;/h4&gt;
&lt;p&gt;TBA&lt;/p&gt;

&lt;h4 id=&quot;song-recommender&quot;&gt;Song Recommender&lt;/h4&gt;
&lt;p&gt;TBA&lt;/p&gt;

&lt;h4 id=&quot;basic-math&quot;&gt;Basic Math&lt;/h4&gt;
&lt;p&gt;Basic math notions with python&lt;/p&gt;

&lt;h4 id=&quot;basic-statistic-in-python&quot;&gt;Basic Statistic in Python&lt;/h4&gt;
&lt;p&gt;Basic math statistics with python&lt;/p&gt;

&lt;h4 id=&quot;basic-natural-language-processing&quot;&gt;Basic Natural Language Processing&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;Tokenization&lt;/li&gt;
  &lt;li&gt;Stopword Removal&lt;/li&gt;
  &lt;li&gt;N-Grams&lt;/li&gt;
  &lt;li&gt;WordSense Disambiguation&lt;/li&gt;
  &lt;li&gt;Parts-of-Speech&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;em&gt;This module uses NLTK for the text processing processes. It is important to note that you will need to download nltk_data.&lt;/em&gt;&lt;/p&gt;

&lt;h4 id=&quot;simple-probability-model&quot;&gt;Simple Probability Model&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;Common Ground&lt;/li&gt;
  &lt;li&gt;Limit Theorems&lt;/li&gt;
  &lt;li&gt;Derived Distributions
    &lt;ul&gt;
      &lt;li&gt;Covariance&lt;/li&gt;
      &lt;li&gt;Correlation&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;imbalanced-learning-with-gaussians&quot;&gt;Imbalanced Learning with Gaussians&lt;/h4&gt;

&lt;div style=&quot;margin-bottom: 5em;&quot;&gt;&lt;/div&gt;

&lt;h3 id=&quot;até-a-próxima-pessoal-&quot;&gt;Até a próxima pessoal ;)&lt;/h3&gt;
</description>
        <pubDate>Wed, 15 Feb 2017 00:00:00 -0200</pubDate>
        <link>/2017/02/15/apresentando-meriat-ml-notes/</link>
        <guid isPermaLink="true">/2017/02/15/apresentando-meriat-ml-notes/</guid>
        
        
        <category>IA</category>
        
        <category>Machine Learning</category>
        
        <category>Data Science</category>
        
        <category>Deep Learning</category>
        
        <category>Jupyter Notebook</category>
        
        <category>Python</category>
        
      </item>
    
      <item>
        <title>Machine Learning e sua literatura clássica</title>
        <description>&lt;p&gt;A listagem a seguir pode ser categorizada como, &lt;strong&gt;Popular Science Machine Learning Books&lt;/strong&gt; ou &lt;strong&gt;Beginner Machine Learning Books&lt;/strong&gt;. É possível ainda encontrar vários livros desta listagem em categorias como &lt;strong&gt;Introductory Machine Learning Books&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img style=&quot;width: 100%;&quot; src=&quot;http://blob.vitormeriat.com.br/images/2017/02/07/capa.jpg&quot; class=&quot;absolute-bg&quot; /&gt;&lt;/p&gt;

&lt;div style=&quot;margin-bottom: 5em;&quot;&gt;&lt;/div&gt;

&lt;h3 id=&quot;machine-learning-books-selection&quot;&gt;Machine Learning Books Selection&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/0465065708&quot;&gt;The Master Algorithm: How the Quest for the Ultimate Learning Machine Will Remake Our World&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/1119145678&quot;&gt;Predictive Analytics: The Power to Predict Who Will Click, Buy, Lie, or Die&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/0143125087&quot;&gt;The Signal and the Noise: Why So Many Predictions Fail–but Some Don’t&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/039334777X&quot;&gt;Naked Statistics: Stripping the Dread from the Data&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/0307275175&quot;&gt;The Drunkard’s Walk: How Randomness Rules Our Lives&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/1449361323&quot;&gt;Data Science for Business: What You Need to Know about Data Mining and Data-Analytic Thinking&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/111866146X&quot;&gt;Data Smart: Using Data Science to Transform Information into Insight&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/0128042915&quot;&gt;Data Mining, Fourth Edition: Practical Machine Learning Tools and Techniques&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/1449358659&quot;&gt;Doing Data Science: Straight Talk from the Frontline&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/B007A0BNP4&quot;&gt;Machine Learning for Hackers: Case Studies and Algorithms to Get You Started&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/1617290181&quot;&gt;Machine Learning in Action&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/0596529325&quot;&gt;Programming Collective Intelligence: Building Smart Web 2.0 Applications&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/1461471370&quot;&gt;An Introduction to Statistical Learning: with Applications in R (Springer Texts in Statistics)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/1461468485&quot;&gt;Applied Predictive Modeling&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/0387848576&quot;&gt;The Elements of Statistical Learning: Data Mining, Inference, and Prediction&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/0387310738&quot;&gt;Pattern Recognition and Machine Learning&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/0262018020&quot;&gt;Machine Learning: A Probabilistic Perspective&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/B00YDJC98K&quot;&gt;Learning From Data by Yaser S. Abu-Mostafa, Malik Magdon-Ismail, Hsuan-Tien Lin&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/0070428077&quot;&gt;Machine Learning 1st Edition&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/1107422221&quot;&gt;Machine Learning: The Art and Science of Algorithms that Make Sense of Data&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/026201825X&quot;&gt;Foundations of Machine Learning (Adaptive Computation and Machine Learning series)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/0596529325&quot;&gt;Programming Collective Intelligence: Building Smart Web 2.0 Applications&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/1118675029&quot;&gt;Time Series Analysis: Forecasting and Control&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/0997847913&quot;&gt;Practical Time Series Forecasting with R: A Hands-On Guide&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/3319298526&quot;&gt;Introduction to Time Series and Forecasting&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/0987507109&quot;&gt;Forecasting: principles and practice&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;div style=&quot;margin-bottom: 5em;&quot;&gt;&lt;/div&gt;

&lt;h3 id=&quot;com-foco-em-python&quot;&gt;Com foco em Python&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/1783555130&quot;&gt;Python Machine Learning&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/149190142X&quot;&gt;Data Science from Scratch: First Principles with Python&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/1491962291&quot;&gt;Hands-On Machine Learning with Scikit-Learn and TensorFlow: Concepts, Tools, and Techniques for Building Intelligent Systems&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/1449369413&quot;&gt;Introduction to Machine Learning with Python: A Guide for Data Scientists&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/B01N4FUDSE&quot;&gt;Vital Introduction to Machine Learning with Python: Best Practices to Improve and Optimize Machine Learning Systems and Algorithms&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/1118961749&quot;&gt;Machine Learning in Python: Essential Techniques for Predictive Analysis&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/1491912057&quot;&gt;Python Data Science Handbook: Essential Tools for Working with Data&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/1633430030&quot;&gt;Introducing Data Science: Big Data, Machine Learning, and more, using Python tools&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/1617291927&quot;&gt;Real-World Machine Learning&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;div style=&quot;margin-bottom: 5em;&quot;&gt;&lt;/div&gt;

&lt;h3 id=&quot;com-foco-em-r&quot;&gt;Com foco em R&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/1491910399&quot;&gt;R for Data Science: Import, Tidy, Transform, Visualize, and Model Data&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/1784393908&quot;&gt;Machine Learning with R&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/1783982047&quot;&gt;Machine Learning With R Cookbook – 110 Recipes for Building Powerful Predictive Models with R&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/1784390844&quot;&gt;R Machine Learning By Example&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/178398774X&quot;&gt;R Machine Learning Essentials&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/178398452X&quot;&gt;Mastering Machine Learning with R&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/1461471370&quot;&gt;An Introduction to Statistical Learning: with Applications in R&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/1617291560&quot;&gt;Practical Data Science with R&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/1461468485&quot;&gt;Applied Predictive Modeling&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/0123969638&quot;&gt;R and Data Mining: Examples and Case Studies&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Aqui vale fazer uma consideração: Temos a seguir uma listagem separada sobre Deep Learning. Isso se deve por essa ser uma técnica de Machine Learning que diz respeito a oportunidade de aprendizagem profunda com o uso de redes neurais.&lt;/p&gt;

&lt;p&gt;Em momento oportuno devo vou compartilhar aqui mais informações sobre Deep Learning, como meus estudos, códigos e referências. Por hora, segue a bibliografia melhor avaliada sobre o tema.&lt;/p&gt;

&lt;div style=&quot;margin-bottom: 5em;&quot;&gt;&lt;/div&gt;

&lt;h3 id=&quot;deep-learning&quot;&gt;Deep Learning&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/0262035618&quot;&gt;Deep Learning&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/1491914254&quot;&gt;Deep Learning: A Practitioner’s Approach&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/1491925612&quot;&gt;Fundamentals of Deep Learning: Designing Next-Generation Machine Intelligence Algorithms&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/1491978511&quot;&gt;Learning TensorFlow: A guide to building deep learning systems&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/1617293873&quot;&gt;Machine Learning with TensorFlow&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/1786462168&quot;&gt;TensorFlow Machine Learning Cookbook&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/1786468573&quot;&gt;Getting Started with TensorFlow&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/1939902452&quot;&gt;TensorFlow for Machine Intelligence: A Hands-On Introduction to Learning Algorithms&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;div style=&quot;margin-bottom: 5em;&quot;&gt;&lt;/div&gt;

&lt;h3 id=&quot;É-isso-ai-valeu-pessoal-&quot;&gt;É isso ai… valeu pessoal ;)&lt;/h3&gt;
</description>
        <pubDate>Tue, 07 Feb 2017 00:00:00 -0200</pubDate>
        <link>/2017/02/07/literatura-classica-machine-learning/</link>
        <guid isPermaLink="true">/2017/02/07/literatura-classica-machine-learning/</guid>
        
        
        <category>IA</category>
        
        <category>Machine Learning</category>
        
        <category>Data Science</category>
        
        <category>Deep Learning</category>
        
      </item>
    
      <item>
        <title>Workshop de Machine Learning na CPBR10</title>
        <description>&lt;div style=&quot;width: 100%; -ms-align-items: center; -webkit-align-items: center; align-items: center;&quot;&gt;
    &lt;img style=&quot;width: 100%;&quot; src=&quot;http://blob.vitormeriat.com.br/images/2017/02/05/campus-ia.jpg&quot; class=&quot;absolute-bg&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;Este ano tive a honra de mais uma vez palestrar na Campus Party. Como de costume minha participação foi em conjunto com a comunidade CrazyTechGuys.&lt;/p&gt;

&lt;p&gt;Nesta oportunidade dividi as ações com o mestre Jorge Maia, no workshop de &lt;a href=&quot;http://campuse.ro/events/campus-party-brasil-2017/workshop/sensores-internet-das-coisas-e-inteligencia-artificial-de-perto-e-sem-mitos/&quot;&gt;IoT e Machine Learning&lt;/a&gt;. Nesta atividade trabalhamos além dos conceitos básicos de IoT e Machine Learning, novidade de mercado, protocolos, linguagens e plataformas.&lt;/p&gt;

&lt;p&gt;Na minha deixa pude demonstrar como iniciar um projeto de Machine Learning do zero utilizando como ferramentas o Jupyter Notebook, Python e o famoso dataset Pima Indians Diabetes Database que é normalmente utilizando para tarefas de classificação e, é largamente utilizado para prever o início de diabetes com base em diagnósticos já realizados.&lt;/p&gt;

&lt;p&gt;É possível encontrar diversos exemplos de utilização do dataset, bem como uma ampla gama de exemplos de diferentes explorações e tratamentos dos dados.&lt;/p&gt;

&lt;p&gt;Neste workshop demonstrei como utilizar o Jupyter Notebook bem como os principais módulos para se trabalhar com Data Science e Python. Vimos os principais conceitos envolvidos nesta atividade e como aplicar em exercício prático.&lt;/p&gt;

&lt;h1 id=&quot;resumindo&quot;&gt;Resumindo&lt;/h1&gt;

&lt;p&gt;Quando falamos de ML, temos duas pricipais tecnicas para trabalhar:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Aprendizagem supervisionada&lt;/li&gt;
  &lt;li&gt;Aprendizagem Nao supervisionada&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Quando falamos de aprendizagem supervisionada e não supervisionada, tendemos a pensar que a diferença está na predição com ou sem a supervisão humana, mas na realidade tudo está ligado aos dados.&lt;/p&gt;

&lt;p&gt;Quando se trata de Aprendizagem supervisionada, cada linha possui diversos atributos, que serão os inputs e os possíveis outputs, ou seja, o valor que esperamos para o conjunto de atributos da linha.&lt;/p&gt;

&lt;p&gt;Se usamos como exemplo determinar o valor de casas em uma determinada região, podemos pegar como atributos o tamanho, quantidade de quartos, área da casa, localidade e claro, o preço.&lt;/p&gt;

&lt;p&gt;Logo após passamos esses dados em um algorítimo de ML, com todos os dados de entrada e os possíveis dados de saída, que neste caso será o valor da casa. O algorítimo determina a relação entre os atributos da casa e seu valor final.&lt;/p&gt;

&lt;p&gt;Depois o resultante do algorítimo será um Modelo, que nada mais é que uma função matemática. Este Modelo será o cara que vai receber os novos dados e ser capaz de prever o preço final.&lt;/p&gt;

&lt;p&gt;O modelo é capaz de prever o preço, pq ele aplica a função matemática que ele aprendeu durante o processo no novo conjunto de dados. A medida que temos novos dados, podemos melhorar nosso modelo e realizar o tão famoso aprendizado de máquina…&lt;/p&gt;

&lt;p&gt;No processo de aprendizagem não supervisionada, o algorítimo busca em seu conjunto de dados, clusters, ou agrupamentos de dados com características semelhantes.&lt;/p&gt;

&lt;p&gt;Sendo assim, o algorítimo identifica a partir dos dados de entrada grupos de dados que compartilhem as mesmas características. Neste caso, não precisamos apresentar os possíveis dados de saída.&lt;/p&gt;

&lt;p&gt;Imagine um conjunto de gravações com pessoas falando. Podemos gerar um dataset com os atributos das vozes das pessoas como entonação, inflexção, altura e etc. Passamos estes dados em um algorítimo de aprendizagem não supervisionado.&lt;/p&gt;

&lt;p&gt;O algorítimo analisa os dados e cria um modelo que classifica clusters de dados que compartilham os mesmos padrões de voz. Com isso o algorítimo será capaz de isolar uma única voz a partir dos dados aprendidos.&lt;/p&gt;

&lt;p&gt;Podemos rezumir de forma simples da segunte maneira:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Aprendizagem supervisionada&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Previsão de valores&lt;/li&gt;
  &lt;li&gt;Nossos dados de treino devem ter valores de entrada e saída, para que o mesmo possa aprender a partir dos novos dados de entrada, a gerar uma saída correta.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Aprendizagem não supervisionada&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Idendificação de grupos de dados&lt;/li&gt;
  &lt;li&gt;Nossos dados precisam apenas possuir entradas&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;source&quot;&gt;Source&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/vitormeriat/workshop-cpbr10&quot;&gt;Github&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;dataset&quot;&gt;Dataset&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes&quot;&gt;UCI&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.kaggle.com/uciml/pima-indians-diabetes-database&quot;&gt;Kaggle&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Sun, 05 Feb 2017 00:00:00 -0200</pubDate>
        <link>/2017/02/05/cpbr10-workshop-machine-learning/</link>
        <guid isPermaLink="true">/2017/02/05/cpbr10-workshop-machine-learning/</guid>
        
        
        <category>IA</category>
        
        <category>Machine Learning</category>
        
        <category>Jupyter Notebook</category>
        
        <category>Python</category>
        
      </item>
    
      <item>
        <title>Inteligência Artificial, história indústria e economia</title>
        <description>&lt;p&gt;A importância científica, industrial e econômica da &lt;span style=&quot;font-size: 1.6em;&quot;&gt;I&lt;/span&gt;nteligência &lt;span style=&quot;font-size: 1.6em;&quot;&gt;A&lt;/span&gt;rtificial, bem como o seu previsível impacto social têm crescido muito nos últimos anos, estimando-se que cresça muito mais, apoiada quer na banalização da potência de cálculo (necessária à complexidade das suas operações), quer nos progressos reais verificados na investigação fundamental, cujos resultados saem agora dos laboratórios para a indústria. Na sua vertente tecnológica, a IA comporta uma importante faceta de engenharia. Na verdade, pretende em última análise programar computadores (a que poderão estar acoplados sensores e actuadores) de forma que desempenhem com êxito e eficiência tarefas que requerem inteligência.&lt;/p&gt;

&lt;p&gt;Tal desempenho tem como suporte a combinação racional de métodos gerais e automatizados de abordagem à formulação e resolução lógica de problemas. É pela generalidade, computabilidade, e combinabilidade lógica desses métodos que a IA se distingue como disciplina científica. Em contraste, outras disciplinas científicas usam técnicas inteligentes mas específicas do seu domínio; técnicas gerais mas sem explicitação do raciocínio; técnicas múltiplas mas não articuladas num todo automatizado.&lt;/p&gt;

&lt;p&gt;As técnicas da IA encontram-se em evolução rápida, e algumas vão-se consubstanciando em instrumentos de “software” comercialmente disponíveis, de utilização acessível àqueles com um mínimo de inclinação informática. Outras dessas técnicas, não existindo sob a forma de instrumento acabado acessível ao leigo, necessitam de um especialista para a sua aplicação casuística.&lt;/p&gt;

&lt;p&gt;A utilização da IA começa a generalizar-se com muitos êxitos de aplicação. Ocorrem anualmente inúmeros colóquios internacionais expressamente dedicados a essas aplicações. Em Portugal verifica-se um potencial considerável em IA, já consolidado em grande parte a nível do ensino e da investigação.&lt;/p&gt;

&lt;div style=&quot;margin-bottom: 5em;&quot;&gt;&lt;/div&gt;

&lt;h4 id=&quot;É-isso-ai-pessoal-em-breve-continuamos-esse-bate-papo-&quot;&gt;É isso ai pessoal, em breve continuamos esse bate papo ;)&lt;/h4&gt;
</description>
        <pubDate>Thu, 19 Jan 2017 00:00:00 -0200</pubDate>
        <link>/2017/01/19/inteligencia-artificial-historia-industria/</link>
        <guid isPermaLink="true">/2017/01/19/inteligencia-artificial-historia-industria/</guid>
        
        
        <category>IA</category>
        
      </item>
    
      <item>
        <title>Microsoft Azure Notebooks–Jupyter Notebooks as a Service</title>
        <description>&lt;p&gt;Essa é uma dica para a galera (que como eu), utiliza o Jupyter Notebooks como ferramenta de estudo ou trabalho.&lt;/p&gt;

&lt;p style=&quot;background-color: #35424a&quot;&gt;&lt;img title=&quot;capa&quot; style=&quot;border-left-width: 0px; border-right-width: 0px; background-image: none; border-bottom-width: 0px; float: none; padding-top: 0px; padding-left: 0px; margin-left: auto; display: block; padding-right: 0px; border-top-width: 0px; margin-right: auto&quot; alt=&quot;capa&quot; src=&quot;http://blob.vitormeriat.com.br/images/2016/10/capa.jpg&quot; width=&quot;752&quot; height=&quot;412&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Provavelmente se você está lendo isto, é por que já conhece o Jupyter Notebooks ou antigo IPython, e tem interesse em usar ou entender esta oferta. Caso você não conheça esta ferramenta, basta saber que o Jupyter Notebooks oferece um environment com suporte a várias linguagens de programação, incluindo Python, R, MATLAB e etc. Esta é uma ferramenta que caiu nas graças dos programadores por proporcionar um meio simples de programar, visualizar e documentar de maneira eficientes seus experimentos. Em breve escrevo algo específico sobre essa ferramenta aqui no blog.&lt;/p&gt;

&lt;p&gt;Por hora vamos analisar este serviço, que no momento em que escrevo este texto, está em PREVIEW.&lt;/p&gt;

&lt;p&gt;Creio que o primeiro passo é entregar algumas informações sobre o serviço. Até este momento os Notebooks estão rodando sobre environment Anaconda para o Python e Microsoft R Open para R. Sendo assim temos suporte aos pacotes já conhecidos no Anaconda. Algo muito importante de ressaltar é que temos a possibilidade de instalar pacotes de maneira normal (pip install), ou usando Conda (conda install). O mesmo vale para R.&lt;/p&gt;

&lt;h2 id=&quot;environments&quot;&gt;Environments&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Anaconda 4.1.0 para Python 2.7.11&lt;/li&gt;
  &lt;li&gt;Anaconda 4.1 para Python 3.5.1&lt;/li&gt;
  &lt;li&gt;MRO 3.3.0 para R&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;restrictions&quot;&gt;Restrictions&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;É possível acessar o github, PyPI, CRAN, OneDrive, DropBox, Google Drive e é claro, o Azure;&lt;/li&gt;
  &lt;li&gt;A memória é limitado a 4 GB;&lt;/li&gt;
  &lt;li&gt;Seus dados pode ter removido após 60 dias de inatividade;&lt;/li&gt;
  &lt;li&gt;Uso deve ser limitado a aprendizagem, investigação, computação em geral e etc. O que é meio lógico, já que o serviço (por hora gratuito), tem algumas limitações de processamento e privacidade.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;start&quot;&gt;Start&lt;/h2&gt;
&lt;p&gt;Para utilizar o serviço é algo tão simples quanto acessar o serviço e se autenticar no serviço.&lt;/p&gt;

&lt;p style=&quot;background-color: #35424a&quot;&gt;&lt;img title=&quot;azure-notebook-1&quot; style=&quot;border-top: 0px; border-right: 0px; background-image: none; border-bottom: 0px; float: none; padding-top: 0px; padding-left: 0px; margin-left: auto; border-left: 0px; display: block; padding-right: 0px; margin-right: auto&quot; alt=&quot;azure-notebook-1&quot; src=&quot;http://blob.vitormeriat.com.br/images/2016/10/azure-notebook-1.jpg&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Assim que você informar sua credencial, o serviço vai te solicitar a permissão para criar uma ID para sua conta no serviço. Diga sim e siga em frente…&lt;/p&gt;

&lt;p&gt;Assim que tudo estiver pronto, você deve ver uma tela como abaixo:&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;azure-notebook-2&quot; style=&quot;border-top: 0px; border-right: 0px; background-image: none; border-bottom: 0px; float: none; padding-top: 0px; padding-left: 0px; margin-left: auto; border-left: 0px; display: block; padding-right: 0px; margin-right: auto&quot; alt=&quot;azure-notebook-2&quot; src=&quot;http://blob.vitormeriat.com.br/images/2016/10/azure-notebook-2.jpg&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Done. Você já um ambiente pronto, e inclusive alguns exemplos para testar. De cara, uma coisa interessante notar é que podemos importar notebooks direto de nosso computador ou de uma URL.&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;azure-notebook-3&quot; style=&quot;border-top: 0px; border-right: 0px; background-image: none; border-bottom: 0px; float: none; padding-top: 0px; padding-left: 0px; margin-left: auto; border-left: 0px; display: block; padding-right: 0px; margin-right: auto&quot; alt=&quot;azure-notebook-3&quot; src=&quot;http://blob.vitormeriat.com.br/images/2016/10/azure-notebook-3.jpg&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Agora perceba que todos os nossos cadernos estão vinculados a uma biblioteca chamada &lt;strong&gt;Sample notebooks&lt;/strong&gt;. Sendo assim vamos criar uma biblioteca.&lt;/p&gt;

&lt;p&gt;Clique em &lt;strong&gt;My libraries&lt;/strong&gt;. Na página que se segue clique em &lt;strong&gt;New Library&lt;/strong&gt; e informe o nome, descrição e url personalizada.&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;azure-notebook-4&quot; style=&quot;border-top: 0px; border-right: 0px; background-image: none; border-bottom: 0px; float: none; padding-top: 0px; padding-left: 0px; margin-left: auto; border-left: 0px; display: block; padding-right: 0px; margin-right: auto&quot; alt=&quot;azure-notebook-4&quot; src=&quot;http://blob.vitormeriat.com.br/images/2016/10/azure-notebook-4.jpg&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Assim que sua biblioteca estiver criada você pode optar por importar um caderno ou abrir seu Jupyter Notebooks.&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;azure-notebook-5&quot; style=&quot;border-top: 0px; border-right: 0px; background-image: none; border-bottom: 0px; float: none; padding-top: 0px; padding-left: 0px; margin-left: auto; border-left: 0px; display: block; padding-right: 0px; margin-right: auto&quot; alt=&quot;azure-notebook-5&quot; src=&quot;http://blob.vitormeriat.com.br/images/2016/10/azure-notebook-5.jpg&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Agora estamos em terreno conhecido. É só criar um novo Notebook usando Py2, Py3 ou R.&lt;/p&gt;

&lt;p&gt;No próximo post vou mostrar como instalar pacotes de Python, R e como compartilhar sua biblioteca de forma pública.&lt;/p&gt;

&lt;div style=&quot;margin-bottom: 5em;&quot;&gt;&lt;/div&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;A princípio vale notar que esta é uma ferramenta em preview. Sendo assim está em desenvolvimento ativo. Acho que hoje é uma maneira muito válida de compartilhar seus cadernos em um ambiente pronto para execução. Vejo uma ótima oportunidade para ensino aqui. Creio que em breve o serviço deve evoluir para ofertas com alto poder de processamento e armazenamento. Digo isso por que hoje já conseguimos utilizar e integrar nossos cadernos com o Azure Machine Learning, logo, creio que a intenção da Microsoft seja mais que apenas oferecer um local para treinar e repositar experimentos na nuvem… espero ;)&lt;/p&gt;
</description>
        <pubDate>Thu, 20 Oct 2016 00:00:00 -0200</pubDate>
        <link>/2016/10/20/microsoft-azure-notebooksjupyter-notebooks-as-a-service/</link>
        <guid isPermaLink="true">/2016/10/20/microsoft-azure-notebooksjupyter-notebooks-as-a-service/</guid>
        
        
        <category>Data Science</category>
        
        <category>Machine Learning</category>
        
        <category>Python</category>
        
      </item>
    
      <item>
        <title>IoT Weekend Recife 2016 - Como a Inteligência Artificial vai mudar a Internet das Coisas</title>
        <description>&lt;p&gt;Olá pessoal, hoje, dia 06 de agosto de 2016 tive mais uma vez o privilégio de palestrar no IoT Weekend edição Recife. Esta é segunda vez em Recife e quarta edição geral do evento, que é inteiramente dedicado a Internet of Things, abrangendo do ponto de vista dos negócios aos famoso under the hood dos detalhes técnicos.&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;capa&quot; alt=&quot;capa&quot; src=&quot;http://blob.vitormeriat.com.br/images/2016/08/capa.png&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Esta edição vez estive falando novamente sobre Inteligência, dessa vez abordando como inteligência artificial está mudando a maneira como fazemos e pensamos na internet das coisas, com uma visão mais abrangente sobre o tema.&lt;/p&gt;

&lt;p&gt;Em suma nessa sessão tentei mostrar como os players atuais do mercado moldaram suas ferramentas e principalmente como isto pode lhe auxiliar no desenvolvimento de dispositivos cada vez mais inteligentes ou por que não dizer, cognitivos ou que aprendem.&lt;/p&gt;

&lt;p&gt;Alguns termos como a própria cognição parecem ser algo místico, porém fazendo um resumo rápido da história da computação, as máquinas mais antigas eram capazes de fazer cálculos. Anos depois, surgiram os sistemas programáveis, que são aqueles utilizados até hoje em nossos celulares, por exemplo. Os próximos passos, como por exemplo a computação cognitiva, trazem uma tecnologia capaz de processar informações e de aprender com elas de forma muito semelhante ao cérebro humano, sem que precisem ser programadas para tal.&lt;/p&gt;

&lt;p&gt;Existem uma série de outros temas a respeito, coisas que pretendo compartilhar em breve aqui no blog.&lt;/p&gt;

&lt;h3 id=&quot;ref&quot;&gt;Ref&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;http://www.iotweekend.com.br/&quot; target=&quot;_blank&quot;&gt;IoT Weekend&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Sat, 06 Aug 2016 00:00:00 -0300</pubDate>
        <link>/2016/08/06/iot-weekend-recife-2016-como-a-inteligncia-artificial-vai-mudar-a-internet-das-coisas/</link>
        <guid isPermaLink="true">/2016/08/06/iot-weekend-recife-2016-como-a-inteligncia-artificial-vai-mudar-a-internet-das-coisas/</guid>
        
        
        <category>Comunidade</category>
        
      </item>
    
      <item>
        <title>Meetups, Internet of Things Expo, MVP Open Day e dias de aprendizado em NYC</title>
        <description>&lt;p align=&quot;justify&quot;&gt;Durante o mês de junho tive a oportunidade de participar de alguns eventos de tecnologia em New York, e é claro, de aproveitar essa cidade maravilhosa.&lt;/p&gt;

&lt;p&gt;
  &lt;img alt=&quot;Cmcc5mYVIAAoB5V&quot; style=&quot;width: 100%;&quot; src=&quot;http://blob.vitormeriat.com.br/images/2016/10/Cmcc5mYVIAAoB5V.jpg&quot; /&gt;
&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;Este evento ocorreu nos dias 7, 8 e 9 de junho no famoso &lt;a href=&quot;http://www.javitscenter.com/&quot; target=&quot;_blank&quot;&gt;Javits Center&lt;/a&gt;. Este é um evento onde conseguimos ver as tendências do mercado de IoT, por meio das empresas, cases e profissionais que estão atuando no topo do mercado.&lt;/p&gt;

&lt;p&gt;
&lt;img alt=&quot;IMG_0232&quot; style=&quot;width: 100%;&quot; src=&quot;http://blob.vitormeriat.com.br/images/2016/10/IMG_0232.jpg&quot; /&gt;
&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;Entre os assuntos disseminados nesta edição, tivemos temas como: &lt;u&gt;IoT: It’s Evolution and Connection to the Cloud&lt;/u&gt;, &lt;u&gt;Continuous Delivery of Microservices: Patterns and Processes&lt;/u&gt;, &lt;u&gt;The Internet of [Broken] Things: The Big Data Challenges of Keeping IoT Reliable&lt;/u&gt;, &lt;u&gt;The Science Behind Generating Big Data&lt;/u&gt;, &lt;u&gt;Secure Communications in P2P and Social IoT Networks&lt;/u&gt;… &lt;/p&gt;
&lt;p align=&quot;justify&quot;&gt;É interessante notar a variedade de assuntos que permeiam essa área de conhecimento. O mais importante foi notar o quanto o mercado está focado em “onde está o dinheiro”, ou onde IoT está sendo utilizado como ferramenta de mercado e não apenas como assunto para se brincar com hardware. &lt;/p&gt;

&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;h2&gt;Meetup&lt;/h2&gt;

&lt;p align=&quot;justify&quot;&gt;Outro ponto alto em NYC são os meetups. Tive a oportunidade de participar do &lt;a href=&quot;https://nytm.org/&quot; target=&quot;_blank&quot;&gt;NY TECH MEETUP&lt;/a&gt;, e do maravilhos afterparty. &lt;/p&gt;

&lt;p&gt;
  &lt;img alt=&quot;IMG_0318&quot; style=&quot;width: 100%;&quot; src=&quot;http://blob.vitormeriat.com.br/images/2016/10/IMG_0318.jpg&quot; /&gt;
&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;Outro ponto interessante é que geralmente os &lt;strong&gt;meetups&lt;/strong&gt; são utilizados como meio de network. Os apresentadores montam seus “&lt;strong&gt;stands&lt;/strong&gt;”, colocam seus cartões, as bebidas são postas na mesa, e galera circula com seus copos em uma mão, e os cartões na outra. Agora é hora de partilhar ideias, aprendizados e mostrar os seu trabalho.&lt;/p&gt;

&lt;p&gt;
  &lt;img alt=&quot;IMG_0329&quot; style=&quot;width: 100%;&quot; src=&quot;http://blob.vitormeriat.com.br/images/2016/10/IMG_0329.jpg&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;h2&gt;MVP Open Days 2016&lt;/h2&gt;

&lt;p align=&quot;justify&quot;&gt;Uma grata surpresa foi a oportunidade de participar do primeiro MVP Open Days na Ámerica do Norte, que também foi meu primeiro evento na Microsoft como MVP. &lt;/p&gt;

&lt;p&gt;
  &lt;img alt=&quot;IMG_0512&quot; style=&quot;width: 100%;&quot; src=&quot;http://blob.vitormeriat.com.br/images/2016/10/IMG_0512.jpg&quot; /&gt;
&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;Tive o grande prazer de conhecer a Microsoft NYC, na famosa Times Square 11. Para quem não conhece, o MVP Open Day é uma conferência com objetivo de reunir MVPs de uma determinado país a fim de interagir, aprender e trocar experiências.&lt;/p&gt;

&lt;p&gt;
  &lt;img alt=&quot;IMG_0622&quot; style=&quot;width: 100%;&quot; src=&quot;http://blob.vitormeriat.com.br/images/2016/10/IMG_0622.jpg&quot; /&gt;
&lt;/p&gt;

&lt;h3 id=&quot;valeu-galera-&quot;&gt;Valeu galera ;)&lt;/h3&gt;
</description>
        <pubDate>Thu, 28 Jul 2016 00:00:00 -0300</pubDate>
        <link>/2016/07/28/meetups-internet-of-things-expo-mvp-open-day-e-dias-de-aprendizado-em-nyc/</link>
        <guid isPermaLink="true">/2016/07/28/meetups-internet-of-things-expo-mvp-open-day-e-dias-de-aprendizado-em-nyc/</guid>
        
        
        <category>Comunidade</category>
        
      </item>
    
  </channel>
</rss>
