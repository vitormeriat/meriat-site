<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Vitor Meriat</title>
    <description></description>
    <link>/</link>
    <atom:link href="/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Thu, 01 Jun 2017 21:38:10 -0300</pubDate>
    <lastBuildDate>Thu, 01 Jun 2017 21:38:10 -0300</lastBuildDate>
    <generator>Jekyll v3.4.0</generator>
    
      <item>
        <title>Microsoft and Artificial Intelligence for the future</title>
        <description>&lt;p&gt;Aproveitando o famoso &lt;a href=&quot;https://build.microsoft.com/&quot;&gt;Microsoft Build&lt;/a&gt; que em 2017 ocorreu em Seattle, e juntando ao convite para resumir o que foi apresentando durante esta conferência em relação a AI no &lt;a href=&quot;https://www.meetup.com/DeliveringSoftware/events/239680578/&quot;&gt;Delivering Software meetup&lt;/a&gt;, vou expor um pouco do histórico da Microsoft e conjecturar sobre sua visão de futuro no quesito Artificial Intelligence.&lt;/p&gt;

&lt;p&gt;Segundo Harry Shum (Executive Vice President, Microsoft AI and Research), durante seu discurso no Build:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Alguns anos atrás, era difícil pensar em uma ferramenta de tecnologia popularmente usada que fazia uso do poder da AI. Em poucos anos, será difícil imaginar qualquer tecnologia que não aproveite o poder da AI.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Isso nos mostra como as grandes companias como Microsoft, Google, Amazon e etc, estão focando em produtos que explorem o poder na inteligência artificial.&lt;/p&gt;

&lt;h2 id=&quot;sobre-o-build-2017&quot;&gt;Sobre o Build 2017&lt;/h2&gt;

&lt;p&gt;Sobre o que foi apresentado no Build 2017, temos algumas novidades interessantes. Se comparado com o Build passado (2016), podemos dizer que a Microsoft trouxe bastante coisa nova ao cenário.&lt;/p&gt;

&lt;h4 id=&quot;cognitive-services&quot;&gt;Cognitive Services&lt;/h4&gt;
&lt;p&gt;E relação aos cognitive services, foram acrescentados 4 novos serviços aos 25 já existentes:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://azure.microsoft.com/pt-br/services/cognitive-services/bing-custom-search/&quot;&gt;Bing Custom Search&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://azure.microsoft.com/en-us/services/cognitive-services/custom-vision-service/&quot;&gt;Custom Vision Service&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://azure.microsoft.com/en-us/services/cognitive-services/custom-decision-service/&quot;&gt;Custom Decision Service&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://azure.microsoft.com/en-us/services/cognitive-services/video-indexer/&quot;&gt;Video Indexer&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;O que vale salientar aqui é que agora temos outros 3 serviços customizáveis, o que traz uma outra linha de atuação aqui. Tirando o LUIS (Language Understanding Intelligent Service) e o Custom Speech Service, todos os demais serviços se tratam de aprendizado prévio e consumível via API. Como LUIS é possível haver uma customização e aprendizagem da intenção com base no que foi estipulado. Podemos utilizar o Custom Speech Service para aprender com um determinado conjunto de linguagem, seja técnica ou não, e adaptar esse vocabulário para seu usuário final. Na prática os novos serviços customizáveis dão mais poder aos usuários, permitindo aos mesmos realizar aprendizados e experiências direcionadas aos seus problemas específicos.&lt;/p&gt;

&lt;h4 id=&quot;cognitive-services-labs&quot;&gt;Cognitive Services Labs&lt;/h4&gt;
&lt;p&gt;O Cognitive Services Labs é um ambiente para testar e dar feedback sobre as novas tecnologias sobre serviços cognitivos que estão sendo desenvolvidos pela Microsoft. Sendo assim você pode se inscrever para testar o que provavelmente serão os novos serviços a serem disponibilizados na plataforma Azure.&lt;/p&gt;

&lt;p&gt;A Microsoft já havia feio o mesmo por meio do projeto Oxford, que é precessor do Cognitive Services.&lt;/p&gt;

&lt;p&gt;Vale dar uma olhada nesse cara, aqui temos alguns serviços disruptivos na área, como por exemplo o Gesture API, doravante chamado de Project Prague, que cria experiências mais intuitivas e naturais, permitindo aos utilizadores controlar e interagir através de gestos.&lt;/p&gt;

&lt;p&gt;Você pode acessar o &lt;a href=&quot;https://labs.cognitive.microsoft.com/&quot;&gt;Cognitive Services Labs aqui!&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&quot;azure-batch-ai-training&quot;&gt;Azure Batch AI Training&lt;/h4&gt;
&lt;p&gt;O &lt;a href=&quot;https://batchaitraining.azure.com/&quot;&gt;Azure Batch AI Training&lt;/a&gt; é fenomenal. Este serviço possibilita que os desenvolvedores possam treinar suas próprias redes neurais profundas, utilizando as principais plataformas, incluindo o Microsoft Cognitive Toolkit, TensorFlow e etc. Outro ponto aqui é que você pode simplesmente enviar seu código em um container Docker e deixar a Microsoft lidar com isso.&lt;/p&gt;

&lt;p&gt;O grande ganho aqui é poder utilizar a mesma infra-estrutura que a Microsoft usa para o seu desenvolvimento de AI por demanda. Na prática agora temos GPUs NVIDIA de ponta que serão utilizadas para o processamento. Agora não vamos mais ter que nos preocupar com a distribuição e paralelização deste processamento, jogando a responsabilidade para a nuvem.&lt;/p&gt;

&lt;p&gt;Vale notar que no Build, foi exibido que será bem simples levar esses modelos de aprendizagem profunda para onde estão os dados, usando o analytics integration fornecido pelo Azure Data Lake, Azure Cosmos DB ou SQL Server.&lt;/p&gt;

&lt;h4 id=&quot;bots&quot;&gt;Bots&lt;/h4&gt;
&lt;p&gt;Usando os novos Adaptive Cards ​​suportados pelo Microsoft Bot Framework, os desenvolvedores podem gravar cartões que ficam ótimos em vários aplicativos e plataformas. Outra novidade foi a possibilidade de publicar em novos canais, incluindo Bing, Cortana e Skype for Business, fora o poder de implementar a API de solicitação de pagamento da Microsoft para verificação rápida e fácil em seus bots.&lt;/p&gt;

&lt;p&gt;A Microsoft também atualizou o LUIS (Language Understanding Intelligent Service),a fim de oferecer um reconhecimento de fala mais preciso, sem falar no número crescente de entidades e intenções que o sistema pode reconhecer.&lt;/p&gt;

&lt;h4 id=&quot;cortana-skills-kit&quot;&gt;Cortana Skills Kit&lt;/h4&gt;
&lt;p&gt;O Cortana Skills Kit foi lançado em preview, e em suma oferece o poder de desenvolver habilidades para Cortana criando um bot e publicando-o no novo canal da Cortana Bot Framework. Isso está disponível no Windows 10, Android, iOS e no novo alto-falante Harman Kardon Invoke,que é powered by Cortana.&lt;/p&gt;

&lt;h4 id=&quot;presentation-translator&quot;&gt;Presentation Translator&lt;/h4&gt;
&lt;p&gt;Certamente outro recurso que chamou atenção: A tradução em “em tempo real” de uma apresentação realizada no PowerPoint. Certamente temos aqui a utilização de um serviço cognitivo, porém já é possível notar o movimento da Microsoft integrando AI em seu famoso pacote Office.&lt;/p&gt;

&lt;p&gt;Este serviço já está disponível para teste, basta apenas você se inscrever &lt;a href=&quot;https://www.aka.ms/PresentationTranslator&quot;&gt;neste formulário&lt;/a&gt; para ter a oportunidade de avaliar.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;http://meriatblob.blob.core.windows.net/images/2017/05/17/ppt-translator.png&quot; class=&quot;absolute-bg&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;cortana-speaker&quot;&gt;Cortana speaker&lt;/h4&gt;

&lt;p align=&quot;center&quot; style=&quot;background-color: black;&quot;&gt;&lt;img src=&quot;http://meriatblob.blob.core.windows.net/images/2017/05/17/cortana.png&quot; width=&quot;200&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Em relação a Cortana o que vimos neste Build é sobre adoção. Foi anunciado oficialmente o uso da Cortana como assistente para o controle por voz do &lt;a href=&quot;http://www.harmankardon.com/invoke.html&quot;&gt;Invoke&lt;/a&gt;, que até então iria utilizar o Alexa da Amazon. Este produto será lançado no quarto trimestre nos EUA, e por hora não tem nenhum detalhe em relação ao preço.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;http://meriatblob.blob.core.windows.net/images/2017/05/17/invoke.png&quot; class=&quot;absolute-bg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Também tivemos o anúncio da parceria fechada com a HP para a construção do seu &lt;strong&gt;smart speaker&lt;/strong&gt; utilizando a Cortana.&lt;/p&gt;

&lt;p&gt;Apesar de a Microsoft já ter ficado bem próxima de Apple e Google no desenvolvimento de assistentes digitais, as iniciativas recentes da Amazon e do Google para extender sua participação para as casas de seus usuários deixaram a Microsoft um pouco para trás. Mesmo agora, o Invoke será lançado apenas no final do ano, bem depois de seus concorrentes.&lt;/p&gt;

&lt;h4 id=&quot;new-ai-mvp-award-category&quot;&gt;New AI MVP Award Category&lt;/h4&gt;

&lt;p&gt;Firmando o compromisso da Microsoft com essas ações em AI, tivemos também o anúncio da nova categoria para o &lt;a href=&quot;https://mvp.microsoft.com/&quot;&gt;programa MVP&lt;/a&gt;, a categoria de AI.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;http://meriatblob.blob.core.windows.net/images/2017/05/17/award-mvp-ai.png&quot; class=&quot;absolute-bg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Como podemos ver acima essa área envolve do aprendizado de máquinas ao serviços cognitivos, ou seja, AI em toda a sua Glória ;)&lt;/p&gt;

&lt;div style=&quot;margin-bottom: 3em;&quot;&gt;&lt;/div&gt;
&lt;hr /&gt;

&lt;p&gt;Parte da estratégia da Microsoft é dar um “empurrão” a fim de trazer inteligência artificial para a computação mainstream. Em resumo, sobre o que vimos no Build, na visão da Microsoft é certo dizer:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Artificial Intelligence está saindo do Research &amp;amp; Development para ficar mais próximo dos desenvolvedores&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Resumindo o motivo de estamos ouvindo falar tanto sobre AI, podemos dizer que chegamos a esse ponto graças à convergência de três forças principais: O aumento da potência computacional que hoje está exponencial na nuvem, poderosos algoritmos que funcionam em redes neurais profundas e acesso a enormes quantidades de dados.&lt;/p&gt;

&lt;h2 id=&quot;project-oxford&quot;&gt;Project Oxford&lt;/h2&gt;
&lt;p&gt;O investimento da Microsoft em AI não é novo. Como citado por Harry Shum, o departamento de Research &amp;amp; Development tem realizados pesquisas voltadas para AI nos últimos 20 anos, o que pode ser bem notado se olharmos para o histórico.&lt;/p&gt;

&lt;p&gt;O projeto Oxford é a coleção da Microsoft de APIs para serviços de aprendizado de máquina. Antes de seu lançamento oficial, a Microsoft laçou o (que na época se tornou um viral) sua aplicação para “adivinhação de idade”, o How-Old.net. Poucas horas depois de ser lançado, o site reuniu centenas de milhares de submissões de imagens em que os usuários brincaram com as tentativas do site de descobrir as idades e os gêneros das pessoas nas fotos submetidas. É claro que isso ajudou a treinar o modelo de reconhecimento e analise de sentimento, tornando o serviço mais confiável.&lt;/p&gt;

&lt;p&gt;O projeto Oxfor iniciou com os seguintes serviços:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Face recognition&lt;/li&gt;
  &lt;li&gt;Speech processing&lt;/li&gt;
  &lt;li&gt;Visual tools&lt;/li&gt;
  &lt;li&gt;Language Understanding Intelligent Service (LUIS)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;deep-learning&quot;&gt;Deep Learning&lt;/h2&gt;
&lt;p&gt;Apesar do termo datar como recente para a maioria das pessoas, as pesquisas envolvendo redes neurais de N camadas para problemas complexos está no campo de pesquisa da Microsoft há decadas, e mais especificamente no área do reconhecimento de fala, como podemos ver neste paper da IEEE, datado de 2013: &lt;a href=&quot;http://ieeexplore.ieee.org/abstract/document/6639345/&quot;&gt;Recent advances in deep learning for speech research at Microsoft&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;microsoft-research&quot;&gt;Microsoft Research&lt;/h2&gt;

&lt;p&gt;Quando Bill Gates criou a Microsoft Research, em 1991, ele previa que os computadores um dia veriam, ouviriam e entenderiam os seres humanos – e essa perspectiva atraiu algumas das melhores mentes para os seus laboratórios, segundo a Microsoft.&lt;/p&gt;

&lt;p&gt;Vários projetos desenvolvidos no Microsoft Resarch serviram de inovação e base para novas tendências que viraram projetos de grande sucesso para a empresa. O sucesso dos bots, serviços cognitivos, cortana, HoloLens e compania sevem como base para novos projetos que hoje já sabemos ser bem aguardados como por exemplo, o Skype Translator.&lt;/p&gt;

&lt;p&gt;Em outubro de 2016, a Microsoft se tornou a primeira empresa do setor a chegar à paridade com humanos em reconhecimento de voz, segundo o anunciado por Harry Shum.&lt;/p&gt;

&lt;p&gt;A visão da Microsoft é realmente expandir, tanto que vemos anuncios como o da colaboração entre a Microsoft Research e o grupo OpenAI, que é uma empresa de pesquisa de AI sem fins lucrativos, e que é destaque por sua atuação e produção.&lt;/p&gt;

&lt;h2 id=&quot;referências&quot;&gt;Referências&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://blogs.microsoft.com/blog/2017/05/10/microsoft-build-2017-microsoft-ai-amplify-human-ingenuity/&quot;&gt;Resumo do anúncio realizado por Harry Shum&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.projectoxford.ai/&quot;&gt;Project Oxford&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://blogs.microsoft.com/blog/2016/11/15/advancing-ambition-democratize-artificial-intelligence/&quot;&gt;Advancing our ambition to democratize artificial intelligence&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Wed, 17 May 2017 00:00:00 -0300</pubDate>
        <link>/2017/05/17/microsoft-and-ai-for-the-future/</link>
        <guid isPermaLink="true">/2017/05/17/microsoft-and-ai-for-the-future/</guid>
        
        
        <category>IA</category>
        
        <category>Cognitive Computing</category>
        
        <category>Microsoft Azure</category>
        
        <category>Deep Learning</category>
        
      </item>
    
      <item>
        <title>Global Azure Bootcamp Campinas 2017 - Cognitive Services no Azure</title>
        <description>&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://meriatblob.blob.core.windows.net/images/2017/04/22/capa.jpg&quot; class=&quot;absolute-bg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Mais um ano tive a honra de palestrar no &lt;strong&gt;Global Azure Bootcamp&lt;/strong&gt;, evento que participo como palestrante desde a primeira edição. Depois de passar por Brasília, Recife e Sampa, tive a oportunidade de palestrar em Campinas ;)&lt;/p&gt;

&lt;h2 id=&quot;o-evento&quot;&gt;O evento&lt;/h2&gt;

&lt;p&gt;O &lt;a href=&quot;https://global.azurebootcamp.net/&quot;&gt;Global Azure Bootcamp&lt;/a&gt; dispensa comentários. O evento chega em mais uma edição em nível global, e cada edição mais cidades vão se engajando.&lt;/p&gt;

&lt;p&gt;O evento fo realizado no polo tecnológico da &lt;strong&gt;CI&amp;amp;T&lt;/strong&gt; em campinas. O site oficial do evento para Campinas é: &lt;a href=&quot;http://campinas.azurewebsites.net/&quot;&gt;campinas.azurewebsites.net&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;a-palestra&quot;&gt;A palestra&lt;/h2&gt;

&lt;p&gt;Como vimos, intligência artificial não é um assunto novo, pelo contrário, estamos falando de um assunto que vem assombrando o imaginário humano nos últimos 100 anos, e pesquisado academicamente hà mais de 5 décadas.&lt;/p&gt;

&lt;p&gt;Neste mundo de AI, os serviços cognitivos estão ligados as aplicações voltadas a proximidade da linguagem natural. Temos de analise de sentimento a visão computacional, tudo de forma simples e fácil, como uma API deve ser.&lt;/p&gt;

&lt;p&gt;Durante o evento consumimos várias APIs do &lt;strong&gt;Cognitive Services&lt;/strong&gt;, em destaque a API de &lt;strong&gt;face/detect&lt;/strong&gt;. Na imagem abaixo temos como resultado a identifiação de faces, onde a API me retorna a localização do rosto e de seus elementos. Assim consigo “desenhar” no python o um quadrado para identificar o rosto, e circulos para identificar os olhos, nariz e boca.&lt;/p&gt;

&lt;p&gt;Notem que também temos a idade sugerida pelo serviço cognitivo. No meu caso, logo no meu caso, ganhei uns vários anos de presente. Preciso dormir mais… Muahaha…&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://meriatblob.blob.core.windows.net/images/2017/04/22/gab1.png&quot; class=&quot;absolute-bg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;O mister &lt;strong&gt;Nicolas Cage&lt;/strong&gt; foi pedido do pessoal.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://meriatblob.blob.core.windows.net/images/2017/04/22/gab2.png&quot; class=&quot;absolute-bg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Muito interessante como a galera está interessada em aprender, discutir e testar os serviços cognitivos. Segunda vez que o tempo fica curto quando chega a hora das demos…&lt;/p&gt;

&lt;h2 id=&quot;o-código&quot;&gt;O código&lt;/h2&gt;

&lt;p&gt;Todas as demos utilizadas na apresentação foram consumindo apenas a &lt;strong&gt;API REST&lt;/strong&gt;, cuja a documentação está disponível em: &lt;a href=&quot;https://www.microsoft.com/cognitive-services/en-us/documentation&quot;&gt;Cognitive Services Documentation&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;O código apresentado já está disponível no meu GitHub no repositório &lt;a href=&quot;https://github.com/vitormeriat/cognitive-services&quot;&gt;Cognitive Services&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Vale lembrar que neste repositório vou colocar vários testes incluindo outras plataformas de Cloud.&lt;/p&gt;

&lt;div style=&quot;margin-bottom: 5em;&quot;&gt;&lt;/div&gt;

&lt;h3 id=&quot;até-a-próxima-pessoal-&quot;&gt;Até a próxima pessoal ;)&lt;/h3&gt;
</description>
        <pubDate>Sat, 22 Apr 2017 00:00:00 -0300</pubDate>
        <link>/2017/04/22/gab-azure-ml-cognitive/</link>
        <guid isPermaLink="true">/2017/04/22/gab-azure-ml-cognitive/</guid>
        
        
        <category>IA</category>
        
        <category>Cognitive Computing</category>
        
        <category>Microsoft Azure</category>
        
        <category>Python</category>
        
        <category>Palestras</category>
        
        <category>Comunidade</category>
        
      </item>
    
      <item>
        <title>Variáveis, Estatística e Macnhine Learning</title>
        <description>&lt;p&gt;A grosso modo podemos dividir a Estatística em três áreas:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Estatística Descritiva&lt;/li&gt;
  &lt;li&gt;Probabilidade&lt;/li&gt;
  &lt;li&gt;Inferência Estatística&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Estatística Descritiva é, em geral, utilizada na etapa inicial da análise, quando tomamos contato com os dados pela primeira vez.&lt;/p&gt;

&lt;p&gt;Probabilidade pode ser pensada como a teoria matemática utilizada para se estudar a incerteza oriunda de fenômenos de caráter aleatório.&lt;/p&gt;

&lt;p&gt;Inferência Estatística é o estudo de técnicas que possibilitam a extrapolação, a um grande conjunto de dados, das informações e conclusões obtidas a partir de subconjuntos de valores, usualmente de dimensão muito menor. [1]&lt;/p&gt;

&lt;p&gt;Falando em Machine Learning, sabemos que em algum determinado momento o pesquisador vai ser deparar com problemas para analisar e entender um determinado conjunto de dados que possa ser relevante aos seu objeto de estudo. Ele necessita trabalhar os dados a fim de transformá-los em informações que possam ser comparadas com outros resultados, ou ainda para julgar sua adequação a alguma teoria estipulada para o problema.&lt;/p&gt;

&lt;p&gt;Resumindo, a essência da Ciência é a observação e seu objetivo básico é a inferência que pode ser dedutiva ou indutiva. Quando falamos em estatística, a inferência estatística se trata da metodologia que objetiva a coleta, redução, análise e modelagem dos dados, a partir dos quais é possível fazer a inferência para uma população que nos permite chegar as &lt;strong&gt;previsões&lt;/strong&gt; e assim tomar &lt;strong&gt;decisões&lt;/strong&gt;. [2]&lt;/p&gt;

&lt;p&gt;Ao falar Machine Lerning falamos em estática, e para ambos existe um elemento fundamental (você já deve ter notado na descrição acima): Os &lt;strong&gt;&lt;u&gt;dados&lt;/u&gt;&lt;/strong&gt;. Quando olhamos para os dados precisamos notar o que há de mais especial, e geralmente conseguimos isso identificando nossas variáveis. Descobrir o porquê de uma determinada variação é um bom início para qualquer problema estatístico.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Uma variável é como uma pergunta que pode ter várias respostas possíveis.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Neste sentido vamos observar a tabela abaixo, que servirá de base para expressar os conceitos básicos que pretendo apresentar neste post:&lt;/p&gt;

&lt;table class=&quot;table-fill&quot;&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;Nome&lt;/th&gt;
      &lt;th&gt;Idade&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Machado de Assis&lt;/td&gt;
      &lt;td&gt;69&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Carlos Drummond de Andrade&lt;/td&gt;
      &lt;td&gt;85&lt;/td&gt;
    &lt;/tr&gt;
     &lt;tr&gt;
      &lt;td&gt;Graciliano Ramos&lt;/td&gt;
      &lt;td&gt;61&lt;/td&gt;
    &lt;/tr&gt;
     &lt;tr&gt;
      &lt;td&gt;Mário Quintana&lt;/td&gt;
      &lt;td&gt;38&lt;/td&gt;
    &lt;/tr&gt;
     &lt;tr&gt;
      &lt;td&gt;Guimarães Rosa&lt;/td&gt;
      &lt;td&gt;59&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;!-- &lt;div style=&quot;margin-bottom: 3em;&quot;&gt;&lt;/div&gt; --&gt;

&lt;p&gt;Em nosso contexto, vamos considerar as linhas como observações/recursos, e as colunas vamos chamar de variáveis. As perguntas que nossas variáveis respondem são: “Qual o seu nome?” e “Qual a sua idade?”.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Primeira dica: Apenas o título da variável não representa toda sua história.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Como assim? O que você quer dizer com isso?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Se olharmos para a variável idade, não sabemos se ela se refere a idade do escritor hoje, a idade no momento de algum escrito famoso ou se foi a idade que ele tinha na época de seu falecimento.&lt;/p&gt;

&lt;p&gt;Uma de nossas tarefas é investigar nossa fonte de dados em busca de compreender o verdadeiro significado de cada variável.&lt;/p&gt;

&lt;p&gt;Outro ponto importante é saber identificar uma variável. Se neste contexto você me perguntar meu nome, vou te responder &lt;strong&gt;Vitor&lt;/strong&gt;. Não importa quantas pessoas diferentes me perguntarem eu vou continuar respondendo Vitor. Neste caso meu nome não é uma variável, e sim uma constante.&lt;/p&gt;

&lt;p&gt;Seguindo essa linha vamos ver que uma variável depende da pergunta que está sendo feita. A resposta para &lt;u&gt;&quot;Qual a ordem em que os dias da semana ocorrem&quot;&lt;/u&gt; será uma constante. Sempre teremos a mesma ordem, terça sempre virá após a segunda e etc. Agora se pergunto &lt;u&gt;&quot;Que dia é hoje&quot;&lt;/u&gt;, vamos ter como resposta uma variável, já que a resposta tem relação direta com o dia em que a pergunta é feita. &lt;u&gt;&quot;Que dia hoje&quot;&lt;/u&gt; pode ser, segunda, terça, quarta… ou seja, teremos &lt;strong&gt;várias&lt;/strong&gt; possíveis respostas corretas.&lt;/p&gt;

&lt;h2 id=&quot;variáveis-numéricas-e-categóricas&quot;&gt;Variáveis numéricas e categóricas&lt;/h2&gt;

&lt;p&gt;Podemos diferenciar variáveis pelo tipo de dado. Em estatística consideramos dois tipos de variáveis: &lt;strong&gt;Númericas&lt;/strong&gt; e &lt;strong&gt;Categóricas&lt;/strong&gt;.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;http://meriatblob.blob.core.windows.net/images/2017/04/20/variables.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Variáveis podem ser classificadas da seguinte forma:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Variáveis Numéricas&lt;/strong&gt;: são as características que podem ser medidas em uma escala quantitativa, ou seja, apresentam valores numéricos que fazem sentido. Podem ser contínuas ou discretas.
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;Variáveis discretas&lt;/strong&gt;: características mensuráveis que podem assumir apenas um número finito ou infinito contável de valores e, assim, somente fazem sentido valores inteiros. Geralmente são o resultado de contagens. Exemplos: número de filhos, número de bactérias por litro de leite, número de cigarros fumados por dia.&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Variáveis contínuas&lt;/strong&gt;, características mensuráveis que assumem valores em uma escala contínua (na reta real), para as quais valores fracionais fazem sentido. Usualmente devem ser medidas através de algum instrumento. Exemplos: peso (balança), altura (régua), tempo (relógio), pressão arterial, idade.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Variáveis Categóricas&lt;/strong&gt;: são as características que não possuem valores quantitativos, mas, ao contrário, são definidas por várias categorias, ou seja, representam uma classificação dos indivíduos. Podem ser nominais ou ordinais.
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;Variáveis nominais&lt;/strong&gt;: não existe ordenação dentre as categorias. Exemplos: sexo, cor dos olhos, fumante/não fumante, doente/sadio.&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Variáveis ordinais&lt;/strong&gt;: existe uma ordenação entre as categorias. Exemplos: escolaridade (1o, 2o, 3o graus), estágio da doença (inicial, intermediário, terminal), mês de observação (janeiro, fevereiro,…, dezembro).&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;p&gt;As distinções são menos rígidas do que a descrição acima nos apresenta.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Sendo assim, podemos definir que se o resultado a pergunta for numérica &lt;u&gt;(&quot;Qual a sua idade?&quot;)&lt;/u&gt;, então temos uma variável numérica. Se a reposta não pode ser representada de forma númerica &lt;u&gt;(&quot;Qual a raça do seu cachorro?&quot;)&lt;/u&gt;, então temos uma variável categórica.&lt;/p&gt;

&lt;p&gt;Uma variável originalmente numérica pode ser coletada de forma categórica.
Por exemplo, a variável idade, medida em anos completos, é quantitativa (contínua); mas, se for informada apenas a faixa etária (0 a 5 anos, 6 a 10 anos, etc…), é qualitativa (ordinal). Outro exemplo é o peso dos lutadores de boxe, uma variável quantitativa (contínua) se trabalhamos com o valor obtido na balança, mas qualitativa (ordinal) se o classificarmos nas categorias do boxe (peso-pena, peso-leve, peso-pesado, etc.).&lt;/p&gt;

&lt;p&gt;Outro ponto importante é que nem sempre uma variável representada por números é quantitativa/numérica.&lt;/p&gt;

&lt;p&gt;O número do telefone de uma pessoa, o número da casa, o número de sua identidade. Às vezes o sexo do indivíduo é registrado na planilha de dados como 1 se macho e 2 se fêmea, por exemplo. Isto não significa que a variável sexo passou a ser quantitativa!&lt;/p&gt;

&lt;h3 id=&quot;variáveis-ordinais&quot;&gt;Variáveis Ordinais&lt;/h3&gt;
&lt;p&gt;Geralmente vemos isso nos formulários e questionários que muitas vezes somos obrigados a responder. Geralmente essas pesquisar vem com opções como “Discordo Fortemente”, “Discordo”, “Neutro”, “Concordo” ou “Concordo Plenamente”. Estes dados têm uma estrutura especial, uma vez que refletem uma hierarquia, onde 0 representa o item de valor mais baixo, e 4 representa o item de valor mais alto.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;0 = Discordo Totalmente&lt;/li&gt;
  &lt;li&gt;1 = Discordo&lt;/li&gt;
  &lt;li&gt;2 = Neutro&lt;/li&gt;
  &lt;li&gt;3 = Concordo&lt;/li&gt;
  &lt;li&gt;4 = Concordo Totalmente&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Um primeiro cuidado em relação a codificação numérica é nunca destuir a hierarquia real dos dados. Se fizermos como está abaixo, nosso trabalho estará destruído.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;0 = Discordo Totalmente&lt;/li&gt;
  &lt;li&gt;2 = Discordo&lt;/li&gt;
  &lt;li&gt;1 = Neutro&lt;/li&gt;
  &lt;li&gt;4 = Concordo&lt;/li&gt;
  &lt;li&gt;5 = Concordo Totalmente&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;variáveis-nominais&quot;&gt;Variáveis Nominais&lt;/h3&gt;
&lt;p&gt;Às vezes não há hierarquia em dados categóricos. Se a cor dos olhos foi codificada 0 “Azul” 1 “Verde” 2 “Castanhos”, temos que escolher aleatoriamente qual opção recebe qual número. Não importa se os olhos azuis são zero, ou um, ou dois, porque não há hierarquia na cor dos olhos.&lt;/p&gt;

&lt;h3 id=&quot;variáveis-discretas&quot;&gt;Variáveis Discretas&lt;/h3&gt;
&lt;p&gt;Todas as variáveis ​​contínuas são numéricas, mas  nem todas as variáveis ​​numéricas são contínuas.&lt;/p&gt;

&lt;p&gt;“Quantas crianças você tem?” Não tem um número infinito de respostas, tem um número finito ou “discreto”. Você não pode ter 2,7 filhos, é 2 ou 3. Você pode estar pensando “Ok - números inteiros significa variável discreta”, mas isso é uma armadilha. E quanto à variável “tamanho do sapato”? Este é muitas vezes um número como 6,5 ou 10,5, mas não há um número infinito de tamanhos de sapato que existem, que seria o fim da fabricação de calçados como sabemos!&lt;/p&gt;

&lt;p&gt;As variáveis ​​discretas não precisam de codificação porque são numéricas&lt;/p&gt;

&lt;h3 id=&quot;variáveis-contínuas&quot;&gt;Variáveis Contínuas&lt;/h3&gt;
&lt;p&gt;Este conceito é difícil, mas você vai ficar bem porque já definimos o conceito de uma variável como resposta a uma pergunta .&lt;/p&gt;

&lt;p&gt;Algumas perguntas têm um monte de respostas  . Se você perguntar a 100 pessoas “Qual é o número da rua de sua casa?”, Você pode obter perto de 100 respostas diferentes. Isso é um pouco irritante, mas não vai quebrar seu software estatístico.&lt;/p&gt;

&lt;p&gt;Algumas perguntas têm um número infinito de  respostas . Literalmente, não existem números suficientes para capturar todas as possibilidades. Pode surpreender você saber quais variáveis ​​se enquadram nesta categoria; Como altura, peso e idade.&lt;/p&gt;

&lt;p&gt;Isto é porque 1,543 metros não é o mesmo que 1,5429 metros. Estes são números diferentes. 1.54299 é diferente novamente. Assim é 1.542999 metros. Acho que você vê o que estou dizendo, há um número ilimitado de números disponíveis para nós para representar a altura de alguém. O mesmo é verdade para peso e idade (e pressão arterial, e um monte de outras medições médicas). Na prática, estamos presos com um número mais limitado de opções, mas isso não muda o fato de que a própria variável tem possibilidades infinitas. Por favor, faça uma pergunta sobre isso nos comentários se você está confuso. Uma boa regra é que quase todas as medições são contínuas.&lt;/p&gt;

&lt;p&gt;Quem se importa se uma variável é contínua? Você não precisa se importar muito frequentemente. Mas quando começamos a falar sobre a probabilidade de pesos e alturas particulares, esse detalhe teórico se torna extremamente importante.&lt;/p&gt;

&lt;p&gt;As variáveis ​​contínuas não exigem codificação, pois elas são sempre numéricas.&lt;/p&gt;

&lt;h2 id=&quot;codificando-variáveis&quot;&gt;Codificando Variáveis&lt;/h2&gt;

&lt;p&gt;Eu não posso analisar diretamente uma sentença como &lt;u&gt;&quot;Hoje é terça-feira&quot;&lt;/u&gt; em termos estatísticos. Quando nossa variável não é númerica, precisamos transformar cada resposta à nossa pergunta em um número, para que o mesmo possa ser analisado. Este processo de conversão é chamado de “codificação”. Como codificar uma variável vai depender do seu tipo de dado.&lt;/p&gt;

&lt;p&gt;Vou escrever um post específico sobre este conteúdo.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;referências&quot;&gt;Referências&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;[1]&lt;/strong&gt; Noções de Probabilidade e Estatística - 6ª Edição Revista e Ampliada - Magalhães,Marcos Nascimento / Lima,Antonio Carlos Pedroso de Edusp&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;[2]&lt;/strong&gt; Estatística Básica - 8ª Edição Bussab,Wilton de Oliveira / Morettin,Pedro Alberto&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Por hoje é só galera. Em breve devo soltar mais conteúdo direcionado as bases do Machine Learning.&lt;/p&gt;
</description>
        <pubDate>Thu, 20 Apr 2017 00:00:00 -0300</pubDate>
        <link>/2017/04/20/variables-in-statistic/</link>
        <guid isPermaLink="true">/2017/04/20/variables-in-statistic/</guid>
        
        
        <category>Statistics</category>
        
        <category>Data Science</category>
        
      </item>
    
      <item>
        <title>Hello World R - Da base à Regressão Linear</title>
        <description>&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://meriatblob.blob.core.windows.net/images/2017/04/14/capa-logo-r.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Antes de iniciar vale notar que além da minha impressão com a linguagem, documentei aqui alguns pontos que me fizeram atentar ao R, bem como alguns pontos de atenção que devem ser levados em consideração principalmente se você estiver pensando em realizar algum projeto com R.&lt;/p&gt;

&lt;p&gt;A linguagem R é um projeto GNU de software livre. O &lt;strong&gt;R&lt;/strong&gt; derivou de uma linguagem chamada &lt;strong&gt;S&lt;/strong&gt; (de “statistics”), criada na &lt;strong&gt;Bell Laboratories&lt;/strong&gt; nos anos 70. Esta é uma linguagem usada por programadores e cientistas de dados para computação estatística.&lt;/p&gt;

&lt;p&gt;R foi desenvolvida por estatísticos para estatística, dado seu foco na resolução de problemas matemáticos, ele possui um estrutura simples o que facilita a implementação e traz ganhos na otimização no tempo de desenvolvimento. Você pode obter todas as referncias na documentação oficial em &lt;a href=&quot;https://www.rdocumentation.org/&quot;&gt;rdocumentation.org&lt;/a&gt;, fora que é possível contar com um riquíssimo ecossistema de pacotes para diferentes áreas de aplicação.&lt;/p&gt;

&lt;h2 id=&quot;por-quê-eu-devo-considerar-o-r&quot;&gt;Por quê eu devo considerar o R?&lt;/h2&gt;

&lt;p&gt;Se trata de uma linguagem free (cran.r-project.org), altamente extensível e hoje já conta com mais de 10.000 pacotes na &lt;a href=&quot;http://crantastic.org/packages&quot;&gt;CRAN&lt;/a&gt;, e o melhor, todos orientados a estatística, aprendizado de máquina e suas técnicas.&lt;/p&gt;

&lt;p&gt;R tem crescido como linguagem e na preferência de utilização. Abaixo segue o ranking da &lt;a href=&quot;http://www.ieee.org&quot;&gt;IEEE&lt;/a&gt; de 2016 para “Top Programming Languages”.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;http://meriatblob.blob.core.windows.net/images/2017/04/14/spectrum-ieee.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Se tomarmos como o &lt;a href=&quot;https://www.kaggle.com&quot;&gt;Kaggle&lt;/a&gt; como referência, vemos que a maioria dos competidores preferem usar R para a criação dos modelos.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;http://meriatblob.blob.core.windows.net/images/2017/04/14/kaggle-tools.png&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Para começar vamos criar um simples exemplo de regressão linear, que neste caso serve como uma espécie de &lt;strong&gt;“Hello World”&lt;/strong&gt; da computação estatística. Então, mãos a obra…&lt;/p&gt;

&lt;h2 id=&quot;regressão-linear&quot;&gt;Regressão Linear&lt;/h2&gt;

&lt;p&gt;A regressão linear é uma técnica estatística usada para descrever a relação entre uma variável numérica (na estatística, chamada de variável dependente) e uma ou mais variáveis explicativas (chamadas de variáveis independentes) que podem ser numéricas ou categóricas. Quando há apenas uma única variável explicativa/de previsão, a técnica é chamada de regressão linear simples. Quando houver duas ou mais variáveis independentes, a técnica é chamada de regressão linear múltipla.&lt;/p&gt;

&lt;p&gt;Para iniciar vamos começar importando o arquivo de texto que será utilizado no exemplo.&lt;/p&gt;

&lt;pre style=&quot;font-size: 1.6em !important&quot;&gt;
    &lt;code class=&quot;r&quot;&gt;
  data &amp;lt;- read.table(&quot;sementes.txt&quot;, header=TRUE, sep=&quot;,&quot;)
    &lt;/code&gt;
&lt;/pre&gt;

&lt;p&gt;No trecho de código acima estamos utilizando a importação de um &lt;strong&gt;TXT&lt;/strong&gt; como DataSet. Na operação que estamos utilizando, podemos observar que a linguagem &lt;strong&gt;R&lt;/strong&gt; usa parâmetros nomeados. O parâmetro de cabeçalho informa se a primeira linha é de cabeçalho ou não. O parâmetro &lt;strong&gt;sep&lt;/strong&gt; (separador) indica como os valores em cada linha são separados. Por exemplo, (\t) indica valores delimitados por tabulação, e (“ “) indica valores delimitados por espaço.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;O R diferencia maiúsculas de minúsculas e você geralmente pode usar o operador (&amp;lt;-) para atribuir valores, ou o operador (=). Essa escolha é uma questão de preferência pessoal, já que ambos exercem a mesma função. Tipicamente, a boa prática aponta para o uso do operador (&amp;lt;-) na atribuição de objetos e (=) para atribuição de valores de parâmetro.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Para se trabalhar com o &lt;strong&gt;CSV&lt;/strong&gt;, formato mais comun nestes casos, seria tão simples quanto passar o caminho do arquivo.&lt;/p&gt;

&lt;pre style=&quot;font-size: 1.6em !important&quot;&gt;
    &lt;code class=&quot;r&quot;&gt;
  data &amp;lt;- read.csv(&quot;sementes.csv&quot;)
    &lt;/code&gt;
&lt;/pre&gt;

&lt;p&gt;Vamos olhar a estrutura de nosso arquivo. Se trata de uma listagem de sementes classificada por cor, comprimento, largura e índice de nutrientes. Nosso objetivo aqui é prever os valores da coluna nutrientes com base nos dados anteriores da semente.&lt;/p&gt;

&lt;p&gt;Uma vez que temos nosso arquivo carregado, podemos utilizar alguns comandos a fim de vizualizar o nosso conjunto de dados.&lt;/p&gt;

&lt;pre style=&quot;font-size: 1.6em !important&quot;&gt;
    &lt;code class=&quot;r&quot;&gt;
  # Exibe o shape dos dados
  dim(data)

  # Concatena duas strings
  paste(&quot;Linhas: &quot;, dim(data)[1], sep=&quot; &quot;)
  paste(&quot;Colunas: &quot;, dim(data)[2], sep=&quot; &quot;)

  # Exibe o dados
  print(data)
    &lt;/code&gt;
&lt;/pre&gt;

&lt;p&gt;A primeira função exibe a estrutura básica dos dados, retornando a quantidade de linhas e colunas do dataset. Notem que estou utilizando a função &lt;strong&gt;paste()&lt;/strong&gt; para concatenar duas strings. Aqui podemos ver que o resultado pode ser lido como um &lt;strong&gt;array&lt;/strong&gt;, onde tenho na posição 1 o primeiro item, e na posição 2 o segundo item. Depois apenas nomeio qual é a coluna e qual é a linha. A próxima função irá exibir os dados como extraído do arquivo. Usamos a função &lt;strong&gt;print()&lt;/strong&gt; para exibir qualquer saída para o nosso programa.&lt;/p&gt;

&lt;p&gt;Nossa saída seria algo como o que se segue abaixo:&lt;/p&gt;

&lt;pre style=&quot;font-size: 1.2em !important&quot;&gt;
    &lt;code class=&quot;prolog&quot;&gt;
  #OUTPUT
  
  8 4

  'Linhas:  8'
  'Colunas:  4'

     Color Length Width Nutrients
  1   blue    5.4   1.8       0.9
  2   blue    4.8   1.5       0.7
  3   blue    4.9   1.6       0.8
  4 yellow    5.0   1.9       0.4
  5 yellow    5.2   1.5       0.3
  6 yellow    4.7   1.9       0.4
  7  green    3.7   2.2       1.4
  8  green    4.2   1.9       1.2
    &lt;/code&gt;
&lt;/pre&gt;

&lt;blockquote&gt;
  &lt;p&gt;Observe que a saída acima exibe os índices do &lt;strong&gt;array de dados, começando em 1&lt;/strong&gt;. Este é um ponto importante a se notar, já que na maioria das linguagens estamos acostumados com os índices de &lt;strong&gt;base 0&lt;/strong&gt;, como em C# ou Python.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Agora vamos executar a análise da função de &lt;strong&gt;Modelo Linear&lt;/strong&gt;. Para isso execute os comandos abaixo:&lt;/p&gt;

&lt;pre style=&quot;font-size: 1.4em !important&quot;&gt;
    &lt;code class=&quot;r&quot;&gt;
  model &amp;lt;- lm(data$Nutrients ~ (data$Color + data$Length + data$Width))

  summary(model)
    &lt;/code&gt;
&lt;/pre&gt;

&lt;p&gt;Neste trecho de código temos a variável &lt;strong&gt;model&lt;/strong&gt; que é o resultado da nossa análise de regressão linear. Aqui estamos usando a função &lt;strong&gt;lm()&lt;/strong&gt; &lt;strong&gt;(linear model)&lt;/strong&gt;, na qual temos a &lt;strong&gt;variável dependente&lt;/strong&gt; a ser prevista (data$Nutrients), e as variáveis independentes, a saber: &lt;strong&gt;data$Color, data$Length, data$Width&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;O próximo commando &lt;strong&gt;(summary(model))&lt;/strong&gt;, vai exibir o resultádo básico formatado da análise que foi armazenda no objeto model. Teremos a seguinte saída para o código acima:&lt;/p&gt;

&lt;pre style=&quot;font-size: 1.2em !important&quot;&gt;
    &lt;code class=&quot;r&quot;&gt;
  Call:
  lm(formula = data$Nutrients ~ (data$Color + data$Length + data$Width))

  Residuals:
          1         2         3         4         5         6         7         8
   0.009418 -0.030030  0.020611 -0.028320  0.044164 -0.015844  0.042596 -0.042596

  Coefficients:
                   Estimate Std. Error t value Pr(&amp;gt;|t|)   
  (Intercept)      -0.14758    0.48286  -0.306  0.77986   
  data$Colorgreen   0.35672    0.09990   3.571  0.03754 *
  data$Coloryellow -0.49083    0.04507 -10.891  0.00166 **
  data$Length       0.04159    0.07876   0.528  0.63406   
  data$Width        0.45200    0.11973   3.775  0.03255 *
  ---
  Signif. codes:  0 ‘\***\’ 0.001 ‘\**\’ 0.01 ‘\*\’ 0.05 ‘.’ 0.1 ‘ ’ 1

  Residual standard error: 0.05179 on 3 degrees of freedom
  Multiple R-squared:  0.9927,	Adjusted R-squared:  0.9829
  F-statistic: 101.6 on 4 and 3 DF,  p-value: 0.00156
    &lt;/code&gt;
&lt;/pre&gt;

&lt;p&gt;Olhando para o nosso conjunto de dados responda a seguinte pergunta: Qual seria o valor de &lt;u&gt;Nutrientes&lt;/u&gt; para uma determinada semente se a &lt;u&gt;cor&lt;/u&gt; da mesma fosse &lt;u&gt;yellow&lt;/u&gt; e suas &lt;u&gt;largura&lt;/u&gt; e &lt;u&gt;altura&lt;/u&gt; fossem &lt;u&gt;1.9&lt;/u&gt; e &lt;u&gt;4.7&lt;/u&gt; respectivamente?&lt;/p&gt;

&lt;p&gt;E ai? Já sabe a resposta?&lt;/p&gt;

&lt;p&gt;Olhando para o nosso dataset é fácil de responder esta pergunta. Estamos falando do item &lt;u&gt;[6]&lt;/u&gt; de nossa lista. Sendo assim sabemos que o valor de nutrientes será &lt;u&gt;0.4&lt;/u&gt;.&lt;/p&gt;

&lt;p&gt;Agora queremos &lt;u&gt;prever&lt;/u&gt; este valor usando nosso modelo. Como faremos isso?&lt;/p&gt;

&lt;p&gt;Vamos olhar para o resultado da análse que fizemos anteriormente. Em Coefficients vamos utilizar apenas a primeira e segunda colunas. Temos aqui nossas variáveis independetes e suas estimativas.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Vale notar que temos uma constante chamada (Intercept), não associada a qualquer variável.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Quando você tem variáveis explicativas categóricas, um dos valores é descartado. Em nosso caso o valor escolhido foi o blue.&lt;/p&gt;

&lt;p&gt;Para fazer uma previsão usando o modelo, é necessário calcular a soma linear dos valores das estimativas multiplicados pelos valores correspondentes em relação as variáveis independentes. Em nosso caso a equação seria:&lt;/p&gt;

&lt;pre style=&quot;font-size: 1.2em !important&quot;&gt;
    &lt;code class=&quot;r&quot;&gt;
  -0.14758 + (0.35672 * 0) + (-0.49083 * 1) + (0.04159 * 4.7) + (0.45200 * 1.9)
    &lt;/code&gt;
&lt;/pre&gt;

&lt;p&gt;Vamos entender como chegar neste resultado. Com base nos quadro abaixo fica mais simples compreender:&lt;/p&gt;

&lt;table class=&quot;table-fill&quot;&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;NA&lt;/th&gt;
      &lt;th&gt;yellow&lt;/th&gt;
      &lt;th&gt;green&lt;/th&gt;
      &lt;th&gt;Length&lt;/th&gt;
      &lt;th&gt;Width&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;-0.14758&lt;/td&gt;
      &lt;td&gt;0.35672&lt;/td&gt;
      &lt;td&gt;-0.49083&lt;/td&gt;
      &lt;td&gt;0.04159&lt;/td&gt;
      &lt;td&gt;0.45200&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;!-- &lt;div style=&quot;margin-bottom: 3em;&quot;&gt;&lt;/div&gt; --&gt;

&lt;p&gt;Primeiro listamos os valores da coluna Estimate. Depois para cada valor, multiplicamos a variável correspondente. No caso do primeiro valor estamos falando da constante Intercept, logo não existe valor a ser multiplicado. Para o segundo valor, temos como resultado &lt;u&gt;(0.35672 * 0)&lt;/u&gt;. É o sugundo valor multiplicado por 0, já que nossa previsão não inclui a variável green. Multiplicamos o valor de data$Length, 0.04159 por 4.7 e temos (0.04159 * 4.7). A mesma lógica para data$Width e temos (0.45200 * 1.9).&lt;/p&gt;

&lt;p&gt;O resultado será 0.415863, um valor muito próximo de 0.40, que é o valor real descrito no arquivo.&lt;/p&gt;

&lt;p&gt;Na saída acima temos uma sessão, iniciada com &lt;u&gt;Residual standard error&lt;/u&gt;. Aqui temos a relação entre as variáveis independentes e a variável dependente.&lt;/p&gt;

&lt;pre style=&quot;font-size: 1.2em !important&quot;&gt;
    &lt;code class=&quot;r&quot;&gt;
  Residual standard error: 0.05179 on 3 degrees of freedom
  Multiple R-squared:  0.9927,	Adjusted R-squared:  0.9829
  F-statistic: 101.6 on 4 and 3 DF,  p-value: 0.00156
    &lt;/code&gt;
&lt;/pre&gt;

&lt;p&gt;O valor de &lt;u&gt;Multiple R-squared (0,9927)&lt;/u&gt; é a porcentagem de variação na variável dependente explicada pela combinação linear das variáveis independentes. Neste caso os valores de R-squared são valores entre 0 e 1, onde os valores mais altos significam um modelo de previsão melhor. Em nosso caso, R-squared tem um valor extremamente alto, indicando que Color, Length e Width podem prever o resultado com boa precisão. F-statistic, Adjusted R-squared e p-value são outras medidas de ajuste do modelo.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Bom, nem tudo é céu azul e arco-íris… Existem alguns pontos que devem ser levantados em relação a utilização do R.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;r-é-single-threaded&quot;&gt;R é single-threaded&lt;/h2&gt;
&lt;p&gt;Temos aqui um ponto interessante. R por padrão é single-threaded, ou seja, é executado apenas por um único segmento na CPU. Isso pode ser limitante já que mesmo usando R em uma VM na nuvem com 64 núcleos de CPU, o R só usará um deles.&lt;/p&gt;

&lt;p&gt;Para ilustrar: Você deseja encontrar a soma de um vetor numérico, esta é uma operação que pode ser executada em paralelo na CPU com bastante facilidade. Se houver quatro núcleos de CPU disponíveis, cada núcleo pode receber cerca de um quarto dos dados a serem processados. Cada núcleo calcula o subtotal do pedaço de dados que é dado, e os quatro subtotais são adicionados para cima para encontrar a soma total do conjunto de dados inteiro.&lt;/p&gt;

&lt;p&gt;No entanto, em R, se usarmo a função &lt;strong&gt;sum()&lt;/strong&gt;, ela será executada em série, processando todo o conjunto de dados em um núcleo de CPU. De fato, muitas operações de Big Data são de natureza semelhante a função &lt;strong&gt;sum()&lt;/strong&gt;, com a mesma tarefa executando independentemente em muitos subconjuntos de dados. Sendo assim, realizar tais operações sequencialmente seria uma subutilização das arquiteturas de computação em paralelo, e se falarmos do poder da nuvem seria mais disperdício ainda.&lt;/p&gt;

&lt;p&gt;É possível escrever programas em R para um melhor desempenho com foco em computação paralela, mas seria melhor a linguagem ter essa premissa de forma nativa.&lt;/p&gt;

&lt;h2 id=&quot;data-stored-in-memory&quot;&gt;Data stored in memory&lt;/h2&gt;
&lt;p&gt;Todos os dados processados em R tem de ser &lt;strong&gt;totalmente carregados na RAM&lt;/strong&gt;. Isso significa que uma vez que os dados foram carregados, tudo isso está disponível para processamento pela CPU, o que é ótimo para o desempenho. Por outro lado, isso também significa que o tamanho máximo de dados que você pode processar depende da quantidade de RAM livre disponível em seu sistema. Lembre-se de que nem toda a RAM do seu computador está disponível para o uso do R. O sistema operacional, os processos em segundo plano e quaisquer outros aplicativos que estão sendo executados na CPU também competem pela RAM. O que está disponível para R usar pode ser uma fração da RAM total instalada no sistema.&lt;/p&gt;

&lt;p&gt;Durante o Workshop, &lt;u&gt;Microsoft R for Data Science&lt;/u&gt; no qual eu participei, usamos uma máquina no azure com 468GB de RAM para hospedar o R Server e ser utilizado por 12 pessoas. Fora isso eventualmente era necessário olhar o desempenho da mesma já que algumas execuções se tornaram pesadas.&lt;/p&gt;

&lt;p&gt;Frequentemente usamos comandos como &lt;strong&gt;mem_used()&lt;/strong&gt; ou &lt;strong&gt;object_size(myDF)&lt;/strong&gt; para monitorar nosso uso das capacidades computacionais.&lt;/p&gt;

&lt;p&gt;Além disso, R também requer &lt;strong&gt;RAM livre para armazenar&lt;/strong&gt; os resultados de seus cálculos. Dependendo do tipo de computação que você for executar, talvez seja necessário que a RAM disponível seja duas vezes ou mais vezes maior do que o tamanho de seus dados. Fora isso as versões de &lt;strong&gt;32 bits&lt;/strong&gt; de R também são limitadas pela quantidade de RAM que podem acessar. Dependendo do sistema operacional, eles podem ser limitados a &lt;strong&gt;2GB a 4GB de RAM&lt;/strong&gt;, mesmo quando há realmente mais RAM disponível.&lt;/p&gt;

&lt;div style=&quot;margin-bottom: 3em; margin-top: 2em;&quot;&gt;

Aparentemente tanto o problema de **single-threaded** como a questão do **data stored in memory** já estão na lista do [R Consortium](https://www.r-consortium.org/), então vamos esperar que em um futuro próximo tenhamos melhores estratégias em R.
&lt;/div&gt;

&lt;h2 id=&quot;essential-open-source-packages&quot;&gt;Essential Open Source Packages&lt;/h2&gt;
&lt;p&gt;Alguns dos principais pacotes em R que você deve conhecer:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Data Management: &lt;code&gt;dplyr&lt;/code&gt;, &lt;code&gt;tidyr&lt;/code&gt;, &lt;code&gt;data.table&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Visualization: &lt;code&gt;ggplot2&lt;/code&gt;, &lt;code&gt;ggvis&lt;/code&gt;, &lt;code&gt;htmlwidgets&lt;/code&gt;, &lt;code&gt;shiny&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Data Importing: &lt;code&gt;haven&lt;/code&gt;, &lt;code&gt;RODBC&lt;/code&gt;, &lt;code&gt;readr&lt;/code&gt;, &lt;code&gt;foreign&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Other favorites: &lt;code&gt;magrittr&lt;/code&gt;, &lt;code&gt;rmarkdown&lt;/code&gt;, &lt;code&gt;caret&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;mrs---mircrosoft-r-server&quot;&gt;MRS - Mircrosoft R Server&lt;/h2&gt;
&lt;p&gt;Essa é uma menção honrosa ao &lt;strong&gt;MRS&lt;/strong&gt; ou &lt;strong&gt;Mircrosoft R Server&lt;/strong&gt;. Vou escrever um post específico sobre este cara, mas com o MRS podemos realizar operações Multi-Threading, trabalhar com Parallel Processing e utilizar o recurso para remover limitação de dados apenas na RAM, fazendo uma combinação de RAM e Disco.&lt;/p&gt;

&lt;h2 id=&quot;impressões&quot;&gt;Impressões&lt;/h2&gt;
&lt;p&gt;No geral minha primeira impressão da linguagem &lt;u&gt;&lt;b&gt;R&lt;/b&gt;&lt;/u&gt; foi muito boa. Achei uma sintaxe limpa, fácil e bem direcionada ao seu propósito. Já tinha em mente que esta seria uma linguagem orientada a estatística computacional, mas esperava algo mais rebuscado, diferente da facilidade de compreensão que tive.&lt;/p&gt;

&lt;h2 id=&quot;conclusão&quot;&gt;Conclusão&lt;/h2&gt;
&lt;p&gt;Minha ideia aqui não era fazer um comparativo, ou muito menos explicar os principais comandos da linguagem. A documentação por si só já é eficaz, e ainda existe uma infinidade de materiais sobre este tema. Preferi aqui fazer uma analise da minha impressão ao implementar uma técnica básica como a regressão linear, além de buscar alguns dos benefícios e possíveis problemas ao optar por utilizar R em futuros projetos.&lt;/p&gt;

&lt;h2 id=&quot;referências&quot;&gt;Referências&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.rdocumentation.org/&quot;&gt;rdocumentation.org&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Linear_regression&quot;&gt;Linear Regression&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.r-consortium.org/&quot;&gt;R Consortium&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;R High Performance Programming - Aloysius Lim, William Tjhi&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://spectrum.ieee.org/static/interactive-the-top-programming-languages-2016&quot;&gt;IEEE Ranking 2016&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.kaggle.com/wiki/Software&quot;&gt;Kaggle Tools Used By Competitors&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://blog.revolutionanalytics.com/&quot;&gt;Revolutions Blog&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.rstudio.com/resources/cheatsheets/&quot;&gt;RStudio Cheat Sheets&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.r-bloggers.com/&quot;&gt;R-Bloggers&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://blogs.msdn.microsoft.com/microsoftrservertigerteam/&quot;&gt;Microsoft R Server Tiger Blog&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Fri, 14 Apr 2017 00:00:00 -0300</pubDate>
        <link>/2017/04/14/hello-world-r/</link>
        <guid isPermaLink="true">/2017/04/14/hello-world-r/</guid>
        
        
        <category>R</category>
        
        <category>Data Science</category>
        
      </item>
    
      <item>
        <title>Devops Summit Brasil 2017 - Minha palestra sobre Azure Cognitive Services</title>
        <description>&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://meriatblob.blob.core.windows.net/images/2017/04/01/palestra-0.jpg&quot; class=&quot;absolute-bg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Como o prometido, vou fazer um compliado do que vimos na minha apresentação sobre Azure Cognitive Services no DevOpsSummit Brasil 2017.&lt;/p&gt;

&lt;p&gt;A ideia era apresentar a plataforma, entendendo o que são serviços cognitivos, sua importância e como eles foram incorporados e distribuídos no ecossistema da Microsoft.&lt;/p&gt;

&lt;h2 id=&quot;cognitive-services--ai&quot;&gt;Cognitive Services &amp;amp; AI&lt;/h2&gt;
&lt;p&gt;Como vimos, intligência artificial não é um assunto novo, pelo contrário, estamos falando de um assunto que vem assombrando o imaginário humano nos últimos 100 anos, e pesquisado academicamente hà mais de 5 décadas.&lt;/p&gt;

&lt;p&gt;Neste mundo de AI, os serviços cognitivos estão ligados as aplicações voltadas a proximidade da linguagem natural. Temos de analise de sentimento a visão computacional, tudo de forma simples e fácil, como uma API deve ser.&lt;/p&gt;

&lt;h2 id=&quot;o-evento&quot;&gt;O evento&lt;/h2&gt;
&lt;p&gt;O evento ocorreu na sede da Microsoft em São Paulo, e foi dividido em 4 trilhas:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;TECNOLOGIAS NA NUVEM&lt;/li&gt;
  &lt;li&gt;DESENVOLVIMENTO MODERNO&lt;/li&gt;
  &lt;li&gt;MELHORIA CONTÍNUA&lt;/li&gt;
  &lt;li&gt;PRÁTICAS E PROCESSOS&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Tive a honra de palestrar na trilha de &lt;strong&gt;Desenvolvimento Moderno&lt;/strong&gt; explorando um tema que tem gerado muito interesse nos últimos tempos: Computação Cognitiva.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://meriatblob.blob.core.windows.net/images/2017/04/01/palestra-1.jpg&quot; class=&quot;absolute-bg&quot; /&gt;&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://meriatblob.blob.core.windows.net/images/2017/04/01/palestra-2.jpg&quot; class=&quot;absolute-bg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Vale lembrar que mesmo não tendo tempo para todas as demonstrações, conseguimos rodar a API de &lt;strong&gt;Face Detect&lt;/strong&gt;, o resultado foi o seguinte:&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://meriatblob.blob.core.windows.net/images/2017/04/01/demo-final.png&quot; class=&quot;absolute-bg&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;os-materiais&quot;&gt;Os materiais&lt;/h2&gt;

&lt;p&gt;Todas as demos utilizadas na apresentação foram consumindo apenas a &lt;strong&gt;API REST&lt;/strong&gt;, cuja a documentação está disponível em: &lt;a href=&quot;https://www.microsoft.com/cognitive-services/en-us/documentation&quot;&gt;Cognitive Services Documentation&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;O código apresentado já está disponível no meu GitHub no repositório &lt;a href=&quot;https://github.com/vitormeriat/cognitive-services&quot;&gt;Cognitive Services&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Vale lembrar que neste repositório vou colocar vários testes incluindo outras plataformas de Cloud.&lt;/p&gt;

&lt;p&gt;Abaixo é só clicar na imagem para baixar ou visualizar os slides da apresentação.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;a href=&quot;//www.slideshare.net/VitorMeriat/devopssummit-2017-azure-cognitive-services&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://meriatblob.blob.core.windows.net/images/2017/04/01/devops-summit-brasil-ppt.jpg&quot; class=&quot;absolute-bg&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;No próximo post&lt;/p&gt;

&lt;div style=&quot;margin-bottom: 5em;&quot;&gt;&lt;/div&gt;

&lt;h3 id=&quot;até-a-próxima-pessoal-&quot;&gt;Até a próxima pessoal ;)&lt;/h3&gt;
</description>
        <pubDate>Sat, 01 Apr 2017 00:00:00 -0300</pubDate>
        <link>/2017/04/01/devopssummitbrasil-azure-cognitive-services/</link>
        <guid isPermaLink="true">/2017/04/01/devopssummitbrasil-azure-cognitive-services/</guid>
        
        
        <category>IA</category>
        
        <category>Cognitive Computing</category>
        
        <category>Microsoft Azure</category>
        
        <category>Python</category>
        
        <category>Palestras</category>
        
        <category>Comunidade</category>
        
      </item>
    
      <item>
        <title>Kaggle Competition - Titanic: Machine Learning from Disaster</title>
        <description>&lt;p&gt;&lt;img style=&quot;width: 100%;&quot; src=&quot;http://blob.vitormeriat.com.br/images/2017/03/18/capa.jpg&quot; class=&quot;absolute-bg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;O &lt;strong&gt;Projeto Titanic&lt;/strong&gt; é uma competição de &lt;strong&gt;Data Science&lt;/strong&gt; promovida pelo &lt;a href=&quot;kaggle.com&quot;&gt;Kaggle.com&lt;/a&gt;. O objetivo deste desafio é deduzir os índices de sobrevivência dos passageiros do Titanic.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Embora os &lt;a href=&quot;https://www.youtube.com/watch?v=JVgkvaDHmto&quot;&gt;Mythbusters&lt;/a&gt; em seu programa tenham provado completamente que era possível Jack e Rose ter sobrevivido utilizando a porta flutuante, o interesse aqui é medir a chance real de sobrevivência dos passageiros a bordo do Titanic em 14 de abril de 1912.&lt;/p&gt;

&lt;p&gt;A história do Titanic é muito conhecida, tendo originado diversos livros, filmes, HQs e afins. É válido lembrar que a história narrada de forma célebre por James Cameron em seu filme de 1997, ilustra perfeitamente o motivo deste desafio. Vamos começar com uma breve perspectiva sobre o tema: Em Abril de 1912 o Titanic zarpou rumo a New York com 2224 passageiros, dos quais estima-se que apenas 710 tenham sobrevivido.&lt;/p&gt;

&lt;p&gt;É aqui que entra nosso desafio: Desenvolver um padrão simples para identificar o perfil dos sobreviventes deste desastre.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Nota: Muitos dos barcos salva-vidas não estavam com a sua capacidade máxima de pessoas a bordo. Se estivessem, seria possível salvar 53,4% dos passageiros, mas apenas 31,6% deles sobreviveram.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Neste caso não temos complicação com elementos aleatórios de sorte. A maioria dos sobreviventes eram mulheres, crianças e pessoas da alta sociedade.&lt;/p&gt;

&lt;h2 id=&quot;start&quot;&gt;Start&lt;/h2&gt;

&lt;p&gt;A lista de sobreviventes e não sobreviventes já foi transformada em dois datasets, &lt;strong&gt;train.csv&lt;/strong&gt; e &lt;strong&gt;test.csv&lt;/strong&gt;. Existe apenas uma diferença entre os dois arquivos, a lista de status de sobrevivência que está presente apenas nos dados de &lt;strong&gt;treino&lt;/strong&gt;. Nos dados de teste este valor precisa ser deduzido.&lt;/p&gt;

&lt;p&gt;Todos os aprendizados começam com uma experiência e são um processo contínuo. Raramente tem um ponto final. Todos os aprendizados são apenas uma aproximação. O conjunto de dados de treino é tipicamente amostrado em 2 unidades, a amostra maior representando aproximadamente 80% dos dados, e uma 2ª amostra com o resto do dados.&lt;/p&gt;

&lt;p&gt;A aprendizagem acontece usando o Conjunto A e a validação acontece usando o conjunto B. Podemos validar como já sabemos os resultados reais de quem Sobreviveu e quem não fez no Conjunto B e depois compará-lo com os resultados previstos. Uma vez que a aprendizagem é aperfeiçoada no Set A e Set B, o conjunto final de padrões é aplicado nos dados do teste. Apenas um rápido lembrete de que não temos o conhecimento do estado de sobrevivência do passageiro nos dados do teste. No contexto de Kaggle, o resultado da aplicação do padrão nos dados de teste é carregado para o ambiente Kaggle, o que nos permite conhecer o sucesso do modelo que desenvolvemos. Kaggle sabe os resultados dos dados de teste, portanto, é capaz de validar contra o nosso arquivo de resultados submetidos. Aqui está uma visão geral do processo de aprendizagem da máquina genérica.&lt;/p&gt;

&lt;p&gt;Neste desafio vamos utilizar os dados do site Kaggle para desenvolver três modelos (regressão logística, árvore de probabilidade condicional e florestas aleatórias), a fim de prever as taxas de sobrevivência para os passageiros do Titanic.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;http://blob.vitormeriat.com.br/images/2017/03/18/decision-tree.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;O conjunto de teste conta com 418 passageiros e o conjunto de treinamento é composto por 891 passageiros. O dataset é composto por:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Class&lt;/li&gt;
  &lt;li&gt;Name&lt;/li&gt;
  &lt;li&gt;Sex&lt;/li&gt;
  &lt;li&gt;Age&lt;/li&gt;
  &lt;li&gt;Sibling/Spouse&lt;/li&gt;
  &lt;li&gt;Parents/Children&lt;/li&gt;
  &lt;li&gt;Ticket (*)&lt;/li&gt;
  &lt;li&gt;Fare&lt;/li&gt;
  &lt;li&gt;Cabin (*)&lt;/li&gt;
  &lt;li&gt;Port of Embarkment.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Como na maioria das competições Kaggle, você recebe dois conjuntos de dados:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Um conjunto de treino completo com o resultado (outcome ou target variable), para um grupo de passageiros, bem como uma coleção de outros parâmetros, como sua idade, sexo, etc. Este é o conjunto de dados em que você deve treinar seu modelo preditivo.&lt;/li&gt;
  &lt;li&gt;Um conjunto de teste, para o qual você deve prever a variável de destino agora desconhecida com base nos outros atributos de passageiros que são fornecidos para ambos os conjuntos de dados.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Este é um ótimo ponto de entrada para aprender machine learning com um conjunto de dados pequeno, gerenciável, interessante e com variáveis ​​de fácil compreensão.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;http://blob.vitormeriat.com.br/images/2017/03/18/ml-pattern.png&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;passo-1&quot;&gt;Passo 1&lt;/h1&gt;
&lt;p&gt;A tragédia do “Titanic” está associada com a regra não escrita do salvamento no mar: “mulheres e crianças primeiro”.&lt;/p&gt;

&lt;p&gt;Nesta tarefa, os competidores precisam analisar a probabilidade de sobrevivência das diferentes categorias de passageiros.&lt;/p&gt;

&lt;p&gt;Para determinar se o passageiro sobreviveu ao “Titanic”, vamos usar uma árvore de decisão. Uma árvore de decisão é gerada automaticamente com base no parâmetro de entrada. A imagem abaixo mostra um exemplo de uma árvore de decisão é criada.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;http://blob.vitormeriat.com.br/images/2017/03/18/decision-tree02.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Vamos estipular o sexo dos passageiros e tripulantes. Este é um  dado importante, uma vez que o sexo do passageiro desempenha um papel crucial para determinar a sobrevivência do mesmo. Um simples count revela que temos 891 passageiros dos quais 65% são homens e 35% são mulheres.&lt;/p&gt;

&lt;table class=&quot;table-fill&quot;&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;Gender&lt;/th&gt;
      &lt;th&gt;Count of Passengers&lt;/th&gt;
      &lt;th&gt; % &lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;female&lt;/td&gt;
      &lt;td&gt;314&lt;/td&gt;
      &lt;td&gt;35%&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;male&lt;/td&gt;
      &lt;td&gt;577&lt;/td&gt;
      &lt;td&gt;65%&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Se adicionarmos a taxa de sobrevivência a equação vamos ver que existe um padrão aqui.&lt;/p&gt;

&lt;table class=&quot;table-fill&quot;&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;Count of Passengers&lt;/th&gt;
      &lt;th&gt;Survived Status&lt;/th&gt;
      &lt;th&gt; &lt;/th&gt;
      &lt;th&gt; &lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;background: #63dd69; color: white;&quot;&gt;Gender&lt;/td&gt;
      &lt;td style=&quot;background: #63dd69; color: white;&quot;&gt;Not Survived&lt;/td&gt;
      &lt;td style=&quot;background: #63dd69; color: white;&quot;&gt;Survived&lt;/td&gt;
      &lt;td style=&quot;background: #63dd69; color: white;&quot;&gt;Total&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;female&lt;/td&gt;
      &lt;td&gt;81&lt;/td&gt;
      &lt;td&gt;233&lt;/td&gt;
      &lt;td&gt;314&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;male&lt;/td&gt;
      &lt;td&gt;468&lt;/td&gt;
      &lt;td&gt;109&lt;/td&gt;
      &lt;td&gt;577&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;background: #777777; color: white;&quot;&gt;Total&lt;/td&gt;
      &lt;td style=&quot;background: #777777; color: white;&quot;&gt;549&lt;/td&gt;
      &lt;td style=&quot;background: #777777; color: white;&quot;&gt;342&lt;/td&gt;
      &lt;td style=&quot;background: #777777; color: white;&quot;&gt;891&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;O seguinte pode ser observado a partir dos dados acima:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;62% (549/891) dos passageiros não sobreviveram&lt;/li&gt;
  &lt;li&gt;38% (342/891) sobreviveram&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Dos 38% que sobreviveram, os passageiros do sexo feminino sobreviveram em maior número maior que os passageiros machos&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;De todos os passageiros do sexo feminino (233/314) 74% sobreviveram&lt;/li&gt;
  &lt;li&gt;De todos os passageiros do sexo masculino (109/577), apenas 19% sobreviveram&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Podemos ilustrar este comportamento usando uma árvore de decisão. Cada nó determina o resultado final com base na maioria. Os votos do nó à direita representam o status de sobrevivência, já que a maioria nesta opção sobreviveu. Os votos do à esquerda representam o status de não sobrevivência, uma vez que a maioria não sobreviveu.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;http://blob.vitormeriat.com.br/images/2017/03/18/ml-pattern-all.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Este é nosso primeiro padrão. Par facilitar vamos conceituar algumas coisas: O dataset de treino é chamado de &lt;strong&gt;labelled dataset&lt;/strong&gt;, onde a coluna &lt;u&gt;Survived&lt;/u&gt; é chamda de “label” ou &lt;strong&gt;response data&lt;/strong&gt;. Esta abordagem é chamada de aprendizagem supervisionada, onde aprendemos com os dados de treino e aplicamos este aprendizado nos dados de teste. O resultado desta abordagem é binária, portanto estamos aplicando uma técnica de classificação, utilizando duas classes, a saber, &lt;strong&gt;survived&lt;/strong&gt; ou &lt;strong&gt;not survived&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Vamos nos referir ao conjunto de dados progressivamente ao longo deste post, começar a descobrir o conceito de aprendizagem da máquina e suas dimensões variadas. Como você pode observar a partir dos dados, os passageiros e seus atributos compõem os dados do Titanic.&lt;/p&gt;

&lt;h1 id=&quot;o-repositório&quot;&gt;O repositório&lt;/h1&gt;
&lt;p&gt;Você pode olhar o código completo acessando o mesmo no repositório &lt;strong&gt;Meriat Machine Learning Notes&lt;/strong&gt; no meu Github.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/vitormeriat/meriat-ml-notes/blob/master/Titanic%20-%20Machine%20Learning%20from%20Disaster.ipynb&quot;&gt;Titanic: Machine Learning from Disaster&lt;/a&gt;&lt;/p&gt;

&lt;div style=&quot;margin-bottom: 5em;&quot;&gt;&lt;/div&gt;

&lt;h3 id=&quot;até-a-próxima-pessoal-&quot;&gt;Até a próxima pessoal ;)&lt;/h3&gt;
</description>
        <pubDate>Sat, 18 Mar 2017 00:00:00 -0300</pubDate>
        <link>/2017/03/18/titanic-machine-learning-from-disaster/</link>
        <guid isPermaLink="true">/2017/03/18/titanic-machine-learning-from-disaster/</guid>
        
        
        <category>IA</category>
        
        <category>Machine Learning</category>
        
        <category>Data Science</category>
        
        <category>Deep Learning</category>
        
        <category>Jupyter Notebook</category>
        
        <category>Python</category>
        
      </item>
    
      <item>
        <title>Apresentando o Meriat Machine Learning Notes</title>
        <description>&lt;p&gt;&lt;img style=&quot;width: 100%;&quot; src=&quot;http://blob.vitormeriat.com.br/images/2017/02/15/capa.jpg&quot; class=&quot;absolute-bg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;No último ano tive a oportunidade de trabalhar em projetos envolvendo IoT e Machine Learning. No processo entre aplicação, estudos e desenvolvimento, acabei separando algum material e exemplos que me ajudaram a inicar nesta carreira, bem como no processo de aprendizagem.&lt;/p&gt;

&lt;p&gt;O Meriat Machine Learning Notes nada mais é que um compendio destes estudos que resolvi compartilhar no github utilizando o Jupyter Notebook.&lt;/p&gt;

&lt;p&gt;Minha opção pelo &lt;strong&gt;Jupyter Notebook&lt;/strong&gt;, dentre tantos motivos, se dá pelo fato de conseguir de forma simples documentar e visualizar todo o código e anotações de forma simples. Vale dizer que o código que estou utilizando pode ser facilmente utilizado em outra IDE, conforme sua preferência.&lt;/p&gt;

&lt;p&gt;Algumas implementações são reprodução de exercícios dos quais eu irei apontar o material base.&lt;/p&gt;

&lt;p&gt;O material ainda está em formação, visto que ainda tenho um longo caminho a percorrer. É possível que futuramente eu altere o repositório, já que alguns estudos podem gerar um repositório separado.&lt;/p&gt;

&lt;p&gt;Por hora vou concentrando meus esforços por aqui ;)&lt;/p&gt;

&lt;h3 id=&quot;github&quot;&gt;Github&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;Study Notes on machine learning, data analysis, algorithms and best practices using Python and Jupyter Notebook.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/vitormeriat/meriat-ml-notes&quot;&gt;Meriat Machine Learning Note&lt;/a&gt;&lt;/p&gt;

&lt;div style=&quot;margin-bottom: 8em;&quot;&gt;&lt;/div&gt;

&lt;h3 id=&quot;meriat-machine-learning-note&quot;&gt;Meriat Machine Learning Note&lt;/h3&gt;

&lt;p&gt;A estrutura atual está descrita logo abaixo. Vou me esforçar para manter atualizada.&lt;/p&gt;

&lt;h5 id=&quot;file-handling&quot;&gt;File Handling&lt;/h5&gt;
&lt;p&gt;&lt;code&gt;TBA&lt;/code&gt;&lt;/p&gt;

&lt;h5 id=&quot;sms-spam-filtering&quot;&gt;SMS Spam Filtering&lt;/h5&gt;
&lt;p&gt;&lt;code&gt;TBA&lt;/code&gt;&lt;/p&gt;

&lt;h5 id=&quot;song-recommender&quot;&gt;Song Recommender&lt;/h5&gt;
&lt;p&gt;&lt;code&gt;TBA&lt;/code&gt;&lt;/p&gt;

&lt;h5 id=&quot;basic-math&quot;&gt;Basic Math&lt;/h5&gt;
&lt;p&gt;Basic math notions with python&lt;/p&gt;

&lt;h5 id=&quot;basic-statistic-in-python&quot;&gt;Basic Statistic in Python&lt;/h5&gt;
&lt;p&gt;Basic math statistics with python&lt;/p&gt;

&lt;h5 id=&quot;basic-natural-language-processing&quot;&gt;Basic Natural Language Processing&lt;/h5&gt;
&lt;ol&gt;
  &lt;li&gt;Tokenization&lt;/li&gt;
  &lt;li&gt;Stopword Removal&lt;/li&gt;
  &lt;li&gt;N-Grams&lt;/li&gt;
  &lt;li&gt;WordSense Disambiguation&lt;/li&gt;
  &lt;li&gt;Parts-of-Speech&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;em&gt;This module uses NLTK for the text processing processes. It is important to note that you will need to download nltk_data.&lt;/em&gt;&lt;/p&gt;

&lt;h5 id=&quot;simple-probability-model&quot;&gt;Simple Probability Model&lt;/h5&gt;
&lt;ol&gt;
  &lt;li&gt;Common Ground&lt;/li&gt;
  &lt;li&gt;Limit Theorems&lt;/li&gt;
  &lt;li&gt;Derived Distributions
    &lt;ul&gt;
      &lt;li&gt;Covariance&lt;/li&gt;
      &lt;li&gt;Correlation&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h5 id=&quot;imbalanced-learning-with-gaussians&quot;&gt;Imbalanced Learning with Gaussians&lt;/h5&gt;
&lt;p&gt;&lt;code&gt;TBA&lt;/code&gt;&lt;/p&gt;

&lt;h5 id=&quot;neural-network&quot;&gt;Neural Network&lt;/h5&gt;
&lt;ol&gt;
  &lt;li&gt;Adaline&lt;/li&gt;
  &lt;li&gt;Perceptron&lt;/li&gt;
  &lt;li&gt;Simple Neural Network&lt;/li&gt;
  &lt;li&gt;Train a Linear Classifier&lt;/li&gt;
  &lt;li&gt;A simple implementation of convolutional neural networks&lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Wed, 15 Feb 2017 00:00:00 -0200</pubDate>
        <link>/2017/02/15/apresentando-meriat-ml-notes/</link>
        <guid isPermaLink="true">/2017/02/15/apresentando-meriat-ml-notes/</guid>
        
        
        <category>IA</category>
        
        <category>Machine Learning</category>
        
        <category>Data Science</category>
        
        <category>Deep Learning</category>
        
        <category>Jupyter Notebook</category>
        
        <category>Python</category>
        
      </item>
    
      <item>
        <title>Machine Learning e sua literatura clássica</title>
        <description>&lt;p&gt;A listagem a seguir pode ser categorizada como, &lt;strong&gt;Popular Science Machine Learning Books&lt;/strong&gt; ou &lt;strong&gt;Beginner Machine Learning Books&lt;/strong&gt;. É possível ainda encontrar vários livros desta listagem em categorias como &lt;strong&gt;Introductory Machine Learning Books&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img style=&quot;width: 100%;&quot; src=&quot;http://blob.vitormeriat.com.br/images/2017/02/07/capa.jpg&quot; class=&quot;absolute-bg&quot; /&gt;&lt;/p&gt;

&lt;div style=&quot;margin-bottom: 5em;&quot;&gt;&lt;/div&gt;

&lt;h3 id=&quot;machine-learning-books-selection&quot;&gt;Machine Learning Books Selection&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/0465065708&quot;&gt;The Master Algorithm: How the Quest for the Ultimate Learning Machine Will Remake Our World&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/1119145678&quot;&gt;Predictive Analytics: The Power to Predict Who Will Click, Buy, Lie, or Die&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/0143125087&quot;&gt;The Signal and the Noise: Why So Many Predictions Fail–but Some Don’t&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/039334777X&quot;&gt;Naked Statistics: Stripping the Dread from the Data&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/0307275175&quot;&gt;The Drunkard’s Walk: How Randomness Rules Our Lives&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/1449361323&quot;&gt;Data Science for Business: What You Need to Know about Data Mining and Data-Analytic Thinking&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/111866146X&quot;&gt;Data Smart: Using Data Science to Transform Information into Insight&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/0128042915&quot;&gt;Data Mining, Fourth Edition: Practical Machine Learning Tools and Techniques&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/1449358659&quot;&gt;Doing Data Science: Straight Talk from the Frontline&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/B007A0BNP4&quot;&gt;Machine Learning for Hackers: Case Studies and Algorithms to Get You Started&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/1617290181&quot;&gt;Machine Learning in Action&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/0596529325&quot;&gt;Programming Collective Intelligence: Building Smart Web 2.0 Applications&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/1461471370&quot;&gt;An Introduction to Statistical Learning: with Applications in R (Springer Texts in Statistics)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/1461468485&quot;&gt;Applied Predictive Modeling&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/0387848576&quot;&gt;The Elements of Statistical Learning: Data Mining, Inference, and Prediction&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/0387310738&quot;&gt;Pattern Recognition and Machine Learning&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/0262018020&quot;&gt;Machine Learning: A Probabilistic Perspective&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/B00YDJC98K&quot;&gt;Learning From Data by Yaser S. Abu-Mostafa, Malik Magdon-Ismail, Hsuan-Tien Lin&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/0070428077&quot;&gt;Machine Learning 1st Edition&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/1107422221&quot;&gt;Machine Learning: The Art and Science of Algorithms that Make Sense of Data&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/026201825X&quot;&gt;Foundations of Machine Learning (Adaptive Computation and Machine Learning series)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/0596529325&quot;&gt;Programming Collective Intelligence: Building Smart Web 2.0 Applications&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/1118675029&quot;&gt;Time Series Analysis: Forecasting and Control&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/0997847913&quot;&gt;Practical Time Series Forecasting with R: A Hands-On Guide&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/3319298526&quot;&gt;Introduction to Time Series and Forecasting&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/0987507109&quot;&gt;Forecasting: principles and practice&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;div style=&quot;margin-bottom: 5em;&quot;&gt;&lt;/div&gt;

&lt;h3 id=&quot;com-foco-em-python&quot;&gt;Com foco em Python&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/1783555130&quot;&gt;Python Machine Learning&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/149190142X&quot;&gt;Data Science from Scratch: First Principles with Python&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/1491962291&quot;&gt;Hands-On Machine Learning with Scikit-Learn and TensorFlow: Concepts, Tools, and Techniques for Building Intelligent Systems&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/1449369413&quot;&gt;Introduction to Machine Learning with Python: A Guide for Data Scientists&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/B01N4FUDSE&quot;&gt;Vital Introduction to Machine Learning with Python: Best Practices to Improve and Optimize Machine Learning Systems and Algorithms&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/1118961749&quot;&gt;Machine Learning in Python: Essential Techniques for Predictive Analysis&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/1491912057&quot;&gt;Python Data Science Handbook: Essential Tools for Working with Data&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/1633430030&quot;&gt;Introducing Data Science: Big Data, Machine Learning, and more, using Python tools&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/1617291927&quot;&gt;Real-World Machine Learning&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;div style=&quot;margin-bottom: 5em;&quot;&gt;&lt;/div&gt;

&lt;h3 id=&quot;com-foco-em-r&quot;&gt;Com foco em R&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/1491910399&quot;&gt;R for Data Science: Import, Tidy, Transform, Visualize, and Model Data&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/1784393908&quot;&gt;Machine Learning with R&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/1783982047&quot;&gt;Machine Learning With R Cookbook – 110 Recipes for Building Powerful Predictive Models with R&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/1784390844&quot;&gt;R Machine Learning By Example&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/178398774X&quot;&gt;R Machine Learning Essentials&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/178398452X&quot;&gt;Mastering Machine Learning with R&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/1461471370&quot;&gt;An Introduction to Statistical Learning: with Applications in R&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/1617291560&quot;&gt;Practical Data Science with R&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/1461468485&quot;&gt;Applied Predictive Modeling&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/0123969638&quot;&gt;R and Data Mining: Examples and Case Studies&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Aqui vale fazer uma consideração: Temos a seguir uma listagem separada sobre Deep Learning. Isso se deve por essa ser uma técnica de Machine Learning que diz respeito a oportunidade de aprendizagem profunda com o uso de redes neurais.&lt;/p&gt;

&lt;p&gt;Em momento oportuno devo vou compartilhar aqui mais informações sobre Deep Learning, como meus estudos, códigos e referências. Por hora, segue a bibliografia melhor avaliada sobre o tema.&lt;/p&gt;

&lt;div style=&quot;margin-bottom: 5em;&quot;&gt;&lt;/div&gt;

&lt;h3 id=&quot;deep-learning&quot;&gt;Deep Learning&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/0262035618&quot;&gt;Deep Learning&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/1491914254&quot;&gt;Deep Learning: A Practitioner’s Approach&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/1491925612&quot;&gt;Fundamentals of Deep Learning: Designing Next-Generation Machine Intelligence Algorithms&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/1491978511&quot;&gt;Learning TensorFlow: A guide to building deep learning systems&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/1617293873&quot;&gt;Machine Learning with TensorFlow&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/1786462168&quot;&gt;TensorFlow Machine Learning Cookbook&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/1786468573&quot;&gt;Getting Started with TensorFlow&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/1939902452&quot;&gt;TensorFlow for Machine Intelligence: A Hands-On Introduction to Learning Algorithms&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;div style=&quot;margin-bottom: 5em;&quot;&gt;&lt;/div&gt;

&lt;h3 id=&quot;É-isso-ai-valeu-pessoal-&quot;&gt;É isso ai… valeu pessoal ;)&lt;/h3&gt;
</description>
        <pubDate>Tue, 07 Feb 2017 00:00:00 -0200</pubDate>
        <link>/2017/02/07/literatura-classica-machine-learning/</link>
        <guid isPermaLink="true">/2017/02/07/literatura-classica-machine-learning/</guid>
        
        
        <category>IA</category>
        
        <category>Machine Learning</category>
        
        <category>Data Science</category>
        
        <category>Deep Learning</category>
        
      </item>
    
      <item>
        <title>Workshop de Machine Learning na CPBR10</title>
        <description>&lt;div style=&quot;width: 100%; -ms-align-items: center; -webkit-align-items: center; align-items: center;&quot;&gt;
    &lt;img style=&quot;width: 100%;&quot; src=&quot;http://blob.vitormeriat.com.br/images/2017/02/05/campus-ia.jpg&quot; class=&quot;absolute-bg&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;Este ano tive a honra de mais uma vez palestrar na Campus Party. Como de costume minha participação foi em conjunto com a comunidade CrazyTechGuys.&lt;/p&gt;

&lt;p&gt;Nesta oportunidade dividi as ações com o mestre Jorge Maia, no workshop de &lt;a href=&quot;http://campuse.ro/events/campus-party-brasil-2017/workshop/sensores-internet-das-coisas-e-inteligencia-artificial-de-perto-e-sem-mitos/&quot;&gt;IoT e Machine Learning&lt;/a&gt;. Nesta atividade trabalhamos além dos conceitos básicos de IoT e Machine Learning, novidade de mercado, protocolos, linguagens e plataformas.&lt;/p&gt;

&lt;p&gt;Na minha deixa pude demonstrar como iniciar um projeto de Machine Learning do zero utilizando como ferramentas o Jupyter Notebook, Python e o famoso dataset Pima Indians Diabetes Database que é normalmente utilizando para tarefas de classificação e, é largamente utilizado para prever o início de diabetes com base em diagnósticos já realizados.&lt;/p&gt;

&lt;p&gt;É possível encontrar diversos exemplos de utilização do dataset, bem como uma ampla gama de exemplos de diferentes explorações e tratamentos dos dados.&lt;/p&gt;

&lt;p&gt;Neste workshop demonstrei como utilizar o Jupyter Notebook bem como os principais módulos para se trabalhar com Data Science e Python. Vimos os principais conceitos envolvidos nesta atividade e como aplicar em exercício prático.&lt;/p&gt;

&lt;h1 id=&quot;resumindo&quot;&gt;Resumindo&lt;/h1&gt;

&lt;p&gt;Quando falamos de ML, temos duas pricipais tecnicas para trabalhar:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Aprendizagem supervisionada&lt;/li&gt;
  &lt;li&gt;Aprendizagem Nao supervisionada&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Quando falamos de aprendizagem supervisionada e não supervisionada, tendemos a pensar que a diferença está na predição com ou sem a supervisão humana, mas na realidade tudo está ligado aos dados.&lt;/p&gt;

&lt;p&gt;Quando se trata de Aprendizagem supervisionada, cada linha possui diversos atributos, que serão os inputs e os possíveis outputs, ou seja, o valor que esperamos para o conjunto de atributos da linha.&lt;/p&gt;

&lt;p&gt;Se usamos como exemplo determinar o valor de casas em uma determinada região, podemos pegar como atributos o tamanho, quantidade de quartos, área da casa, localidade e claro, o preço.&lt;/p&gt;

&lt;p&gt;Logo após passamos esses dados em um algorítimo de ML, com todos os dados de entrada e os possíveis dados de saída, que neste caso será o valor da casa. O algorítimo determina a relação entre os atributos da casa e seu valor final.&lt;/p&gt;

&lt;p&gt;Depois o resultante do algorítimo será um Modelo, que nada mais é que uma função matemática. Este Modelo será o cara que vai receber os novos dados e ser capaz de prever o preço final.&lt;/p&gt;

&lt;p&gt;O modelo é capaz de prever o preço, pq ele aplica a função matemática que ele aprendeu durante o processo no novo conjunto de dados. A medida que temos novos dados, podemos melhorar nosso modelo e realizar o tão famoso aprendizado de máquina…&lt;/p&gt;

&lt;p&gt;No processo de aprendizagem não supervisionada, o algorítimo busca em seu conjunto de dados, clusters, ou agrupamentos de dados com características semelhantes.&lt;/p&gt;

&lt;p&gt;Sendo assim, o algorítimo identifica a partir dos dados de entrada grupos de dados que compartilhem as mesmas características. Neste caso, não precisamos apresentar os possíveis dados de saída.&lt;/p&gt;

&lt;p&gt;Imagine um conjunto de gravações com pessoas falando. Podemos gerar um dataset com os atributos das vozes das pessoas como entonação, inflexção, altura e etc. Passamos estes dados em um algorítimo de aprendizagem não supervisionado.&lt;/p&gt;

&lt;p&gt;O algorítimo analisa os dados e cria um modelo que classifica clusters de dados que compartilham os mesmos padrões de voz. Com isso o algorítimo será capaz de isolar uma única voz a partir dos dados aprendidos.&lt;/p&gt;

&lt;p&gt;Podemos rezumir de forma simples da segunte maneira:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Aprendizagem supervisionada&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Previsão de valores&lt;/li&gt;
  &lt;li&gt;Nossos dados de treino devem ter valores de entrada e saída, para que o mesmo possa aprender a partir dos novos dados de entrada, a gerar uma saída correta.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Aprendizagem não supervisionada&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Idendificação de grupos de dados&lt;/li&gt;
  &lt;li&gt;Nossos dados precisam apenas possuir entradas&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;source&quot;&gt;Source&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/vitormeriat/workshop-cpbr10&quot;&gt;Github&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;dataset&quot;&gt;Dataset&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes&quot;&gt;UCI&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.kaggle.com/uciml/pima-indians-diabetes-database&quot;&gt;Kaggle&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Sun, 05 Feb 2017 00:00:00 -0200</pubDate>
        <link>/2017/02/05/cpbr10-workshop-machine-learning/</link>
        <guid isPermaLink="true">/2017/02/05/cpbr10-workshop-machine-learning/</guid>
        
        
        <category>IA</category>
        
        <category>Machine Learning</category>
        
        <category>Jupyter Notebook</category>
        
        <category>Python</category>
        
      </item>
    
      <item>
        <title>Inteligência Artificial, história indústria e economia</title>
        <description>&lt;p&gt;A importância científica, industrial e econômica da &lt;span style=&quot;font-size: 1.6em;&quot;&gt;I&lt;/span&gt;nteligência &lt;span style=&quot;font-size: 1.6em;&quot;&gt;A&lt;/span&gt;rtificial, bem como o seu previsível impacto social têm crescido muito nos últimos anos, estimando-se que cresça muito mais, apoiada quer na banalização da potência de cálculo (necessária à complexidade das suas operações), quer nos progressos reais verificados na investigação fundamental, cujos resultados saem agora dos laboratórios para a indústria. Na sua vertente tecnológica, a IA comporta uma importante faceta de engenharia. Na verdade, pretende em última análise programar computadores (a que poderão estar acoplados sensores e actuadores) de forma que desempenhem com êxito e eficiência tarefas que requerem inteligência.&lt;/p&gt;

&lt;p&gt;Tal desempenho tem como suporte a combinação racional de métodos gerais e automatizados de abordagem à formulação e resolução lógica de problemas. É pela generalidade, computabilidade, e combinabilidade lógica desses métodos que a IA se distingue como disciplina científica. Em contraste, outras disciplinas científicas usam técnicas inteligentes mas específicas do seu domínio; técnicas gerais mas sem explicitação do raciocínio; técnicas múltiplas mas não articuladas num todo automatizado.&lt;/p&gt;

&lt;p&gt;As técnicas da IA encontram-se em evolução rápida, e algumas vão-se consubstanciando em instrumentos de “software” comercialmente disponíveis, de utilização acessível àqueles com um mínimo de inclinação informática. Outras dessas técnicas, não existindo sob a forma de instrumento acabado acessível ao leigo, necessitam de um especialista para a sua aplicação casuística.&lt;/p&gt;

&lt;p&gt;A utilização da IA começa a generalizar-se com muitos êxitos de aplicação. Ocorrem anualmente inúmeros colóquios internacionais expressamente dedicados a essas aplicações. Em Portugal verifica-se um potencial considerável em IA, já consolidado em grande parte a nível do ensino e da investigação.&lt;/p&gt;

&lt;div style=&quot;margin-bottom: 5em;&quot;&gt;&lt;/div&gt;

&lt;h4 id=&quot;É-isso-ai-pessoal-em-breve-continuamos-esse-bate-papo-&quot;&gt;É isso ai pessoal, em breve continuamos esse bate papo ;)&lt;/h4&gt;
</description>
        <pubDate>Thu, 19 Jan 2017 00:00:00 -0200</pubDate>
        <link>/2017/01/19/inteligencia-artificial-historia-industria/</link>
        <guid isPermaLink="true">/2017/01/19/inteligencia-artificial-historia-industria/</guid>
        
        
        <category>IA</category>
        
      </item>
    
  </channel>
</rss>
