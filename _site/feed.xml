<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Vitor Meriat</title>
    <description></description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Fri, 21 Apr 2017 14:20:25 -0300</pubDate>
    <lastBuildDate>Fri, 21 Apr 2017 14:20:25 -0300</lastBuildDate>
    <generator>Jekyll v3.4.0</generator>
    
      <item>
        <title>Variáveis, Estatística e Macnhine Learning</title>
        <description>&lt;p&gt;Em Machine Lerning falamos em estática, e para ambos existe um elemento fundamental: dados. Quando olhamos para os dados precisamos notar o que há de mais especial, e geralmente conseguimos isso identificando nossas variáveis. Descobrir o porquê de uma determinada variação é um bom início para qualquer problema estatístico.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Uma variável é como uma pergunta que pode ter várias respostas possíveis.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Observe a tabela abaixo:&lt;/p&gt;

&lt;table class=&quot;table-fill&quot;&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;Nome&lt;/th&gt;
      &lt;th&gt;Idade&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Machado de Assis&lt;/td&gt;
      &lt;td&gt;69&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Carlos Drummond de Andrade&lt;/td&gt;
      &lt;td&gt;85&lt;/td&gt;
    &lt;/tr&gt;
     &lt;tr&gt;
      &lt;td&gt;Graciliano Ramos&lt;/td&gt;
      &lt;td&gt;61&lt;/td&gt;
    &lt;/tr&gt;
     &lt;tr&gt;
      &lt;td&gt;Mário Quintana&lt;/td&gt;
      &lt;td&gt;38&lt;/td&gt;
    &lt;/tr&gt;
     &lt;tr&gt;
      &lt;td&gt;Guimarães Rosa&lt;/td&gt;
      &lt;td&gt;59&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;!-- &lt;div style=&quot;margin-bottom: 3em;&quot;&gt;&lt;/div&gt; --&gt;

&lt;p&gt;Em nosso contexto, vamos considerar as linhas como observações/recursos, e as colunas vamos chamar de variáveis. As perguntas que nossas variáveis respondem são: “Qual o seu nome?” e “Qual a sua idade?”.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Primeira dica: Apenas o título da variável não representa toda sua história.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Como assim? O que você quer dizer com isso?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Se olharmos para a variável idade, não sabemos se ela se refere a idade do escritor hoje, a idade no momento de algum escrito famoso ou se foi a idade que ele tinha na época de seu falecimento.&lt;/p&gt;

&lt;p&gt;Uma de nossas tarefas é investigar nossa fonte de dados em busca de compreender o verdadeiro significado de cada variável.&lt;/p&gt;

&lt;p&gt;Outro ponto importante é saber identificar uma variável. Se neste contexto você me perguntar meu nome, vou te responder &lt;strong&gt;Vitor&lt;/strong&gt;. Não importa quantas pessoas diferentes me perguntarem eu vou continuar respondendo Vitor. Neste caso meu nome não é uma variável, e sim uma constante.&lt;/p&gt;

&lt;p&gt;Seguindo essa linha vamos ver que uma variável depende da pergunta que está sendo feita. A resposta para &lt;u&gt;&quot;Qual a ordem em que os dias da semana ocorrem&quot;&lt;/u&gt; será uma constante. Sempre teremos a mesma ordem, terça sempre virá após a segunda e etc. Agora se pergunto &lt;u&gt;&quot;Que dia é hoje&quot;&lt;/u&gt;, vamos ter como resposta uma variável, já que a resposta tem relação direta com o dia em que a pergunta é feita. &lt;u&gt;&quot;Que dia hoje&quot;&lt;/u&gt; pode ser, segunda, terça, quarta… ou seja, teremos &lt;strong&gt;várias&lt;/strong&gt; possíveis respostas corretas.&lt;/p&gt;

&lt;h2 id=&quot;variáveis-numéricas-e-categóricas&quot;&gt;Variáveis numéricas e categóricas&lt;/h2&gt;

&lt;p&gt;Podemos diferenciar variáveis pelo tipo de dado. Em estatística consideramos dois tipos de variáveis: &lt;strong&gt;Númericas&lt;/strong&gt; e &lt;strong&gt;Categóricas&lt;/strong&gt;.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;http://meriatblob.blob.core.windows.net/images/2017/04/20/variables.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Variáveis podem ser classificadas da seguinte forma:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Variáveis Numéricas&lt;/strong&gt;: são as características que podem ser medidas em uma escala quantitativa, ou seja, apresentam valores numéricos que fazem sentido. Podem ser contínuas ou discretas.
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;Variáveis discretas&lt;/strong&gt;: características mensuráveis que podem assumir apenas um número finito ou infinito contável de valores e, assim, somente fazem sentido valores inteiros. Geralmente são o resultado de contagens. Exemplos: número de filhos, número de bactérias por litro de leite, número de cigarros fumados por dia.&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Variáveis contínuas&lt;/strong&gt;, características mensuráveis que assumem valores em uma escala contínua (na reta real), para as quais valores fracionais fazem sentido. Usualmente devem ser medidas através de algum instrumento. Exemplos: peso (balança), altura (régua), tempo (relógio), pressão arterial, idade.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Variáveis Categóricas&lt;/strong&gt;: são as características que não possuem valores quantitativos, mas, ao contrário, são definidas por várias categorias, ou seja, representam uma classificação dos indivíduos. Podem ser nominais ou ordinais.
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;Variáveis nominais&lt;/strong&gt;: não existe ordenação dentre as categorias. Exemplos: sexo, cor dos olhos, fumante/não fumante, doente/sadio.&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Variáveis ordinais&lt;/strong&gt;: existe uma ordenação entre as categorias. Exemplos: escolaridade (1o, 2o, 3o graus), estágio da doença (inicial, intermediário, terminal), mês de observação (janeiro, fevereiro,…, dezembro).&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;p&gt;As distinções são menos rígidas do que a descrição acima nos apresenta.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Sendo assim, podemos definir que se o resultado a pergunta for numérica &lt;u&gt;(&quot;Qual a sua idade?&quot;)&lt;/u&gt;, então temos uma variável numérica. Se a reposta não pode ser representada de forma númerica &lt;u&gt;(&quot;Qual a raça do seu cachorro?&quot;)&lt;/u&gt;, então temos uma variável categórica.&lt;/p&gt;

&lt;p&gt;Uma variável originalmente numérica pode ser coletada de forma categórica.
Por exemplo, a variável idade, medida em anos completos, é quantitativa (contínua); mas, se for informada apenas a faixa etária (0 a 5 anos, 6 a 10 anos, etc…), é qualitativa (ordinal). Outro exemplo é o peso dos lutadores de boxe, uma variável quantitativa (contínua) se trabalhamos com o valor obtido na balança, mas qualitativa (ordinal) se o classificarmos nas categorias do boxe (peso-pena, peso-leve, peso-pesado, etc.).&lt;/p&gt;

&lt;p&gt;Outro ponto importante é que nem sempre uma variável representada por números é quantitativa/numérica.&lt;/p&gt;

&lt;p&gt;O número do telefone de uma pessoa, o número da casa, o número de sua identidade. Às vezes o sexo do indivíduo é registrado na planilha de dados como 1 se macho e 2 se fêmea, por exemplo. Isto não significa que a variável sexo passou a ser quantitativa!&lt;/p&gt;

&lt;h3 id=&quot;variáveis-ordinais&quot;&gt;Variáveis Ordinais&lt;/h3&gt;
&lt;p&gt;Geralmente vemos isso nos formulários e questionários que muitas vezes somos obrigados a responder. Geralmente essas pesquisar vem com opções como “Discordo Fortemente”, “Discordo”, “Neutro”, “Concordo” ou “Concordo Plenamente”. Estes dados têm uma estrutura especial, uma vez que refletem uma hierarquia, onde 0 representa o item de valor mais baixo, e 4 representa o item de valor mais alto.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;0 = Discordo Totalmente&lt;/li&gt;
  &lt;li&gt;1 = Discordo&lt;/li&gt;
  &lt;li&gt;2 = Neutro&lt;/li&gt;
  &lt;li&gt;3 = Concordo&lt;/li&gt;
  &lt;li&gt;4 = Concordo Totalmente&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Um primeiro cuidado em relação a codificação numérica é nunca destuir a hierarquia real dos dados. Se fizermos como está abaixo, nosso trabalho estará destruído.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;0 = Discordo Totalmente&lt;/li&gt;
  &lt;li&gt;2 = Discordo&lt;/li&gt;
  &lt;li&gt;1 = Neutro&lt;/li&gt;
  &lt;li&gt;4 = Concordo&lt;/li&gt;
  &lt;li&gt;5 = Concordo Totalmente&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;variáveis-nominais&quot;&gt;Variáveis Nominais&lt;/h3&gt;
&lt;p&gt;Às vezes não há hierarquia em dados categóricos. Se a cor dos olhos foi codificada 0 “Azul” 1 “Verde” 2 “Castanhos”, temos que escolher aleatoriamente qual opção recebe qual número. Não importa se os olhos azuis são zero, ou um, ou dois, porque não há hierarquia na cor dos olhos.&lt;/p&gt;

&lt;h3 id=&quot;variáveis-discretas&quot;&gt;Variáveis Discretas&lt;/h3&gt;
&lt;p&gt;Todas as variáveis ​​contínuas são numéricas, mas  nem todas as variáveis ​​numéricas são contínuas.&lt;/p&gt;

&lt;p&gt;“Quantas crianças você tem?” Não tem um número infinito de respostas, tem um número finito ou “discreto”. Você não pode ter 2,7 filhos, é 2 ou 3. Você pode estar pensando “Ok - números inteiros significa variável discreta”, mas isso é uma armadilha. E quanto à variável “tamanho do sapato”? Este é muitas vezes um número como 6,5 ou 10,5, mas não há um número infinito de tamanhos de sapato que existem, que seria o fim da fabricação de calçados como sabemos!&lt;/p&gt;

&lt;p&gt;As variáveis ​​discretas não precisam de codificação porque são numéricas&lt;/p&gt;

&lt;h3 id=&quot;variáveis-contínuas&quot;&gt;Variáveis Contínuas&lt;/h3&gt;
&lt;p&gt;Este conceito é difícil, mas você vai ficar bem porque já definimos o conceito de uma variável como resposta a uma pergunta .&lt;/p&gt;

&lt;p&gt;Algumas perguntas têm um monte de respostas  . Se você perguntar a 100 pessoas “Qual é o número da rua de sua casa?”, Você pode obter perto de 100 respostas diferentes. Isso é um pouco irritante, mas não vai quebrar seu software estatístico.&lt;/p&gt;

&lt;p&gt;Algumas perguntas têm um número infinito de  respostas . Literalmente, não existem números suficientes para capturar todas as possibilidades. Pode surpreender você saber quais variáveis ​​se enquadram nesta categoria; Como altura, peso e idade.&lt;/p&gt;

&lt;p&gt;Isto é porque 1,543 metros não é o mesmo que 1,5429 metros. Estes são números diferentes. 1.54299 é diferente novamente. Assim é 1.542999 metros. Acho que você vê o que estou dizendo, há um número ilimitado de números disponíveis para nós para representar a altura de alguém. O mesmo é verdade para peso e idade (e pressão arterial, e um monte de outras medições médicas). Na prática, estamos presos com um número mais limitado de opções, mas isso não muda o fato de que a própria variável tem possibilidades infinitas. Por favor, faça uma pergunta sobre isso nos comentários se você está confuso. Uma boa regra é que quase todas as medições são contínuas.&lt;/p&gt;

&lt;p&gt;Quem se importa se uma variável é contínua? Você não precisa se importar muito frequentemente. Mas quando começamos a falar sobre a probabilidade de pesos e alturas particulares, esse detalhe teórico se torna extremamente importante.&lt;/p&gt;

&lt;p&gt;As variáveis ​​contínuas não exigem codificação, pois elas são sempre numéricas.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;variáveis-codificadas&quot;&gt;Variáveis Codificadas&lt;/h2&gt;

&lt;p&gt;Eu não posso analisar diretamente uma sentença como &lt;u&gt;&quot;Hoje é terça-feira&quot;&lt;/u&gt; em termos estatísticos. Quando nossa variável não é númerica, precisamos transformar cada resposta à nossa pergunta em um número, para que o mesmo possa ser analisado. Este processo de conversão é chamado de “codificação”. Como codificar uma variável vai depender do seu tipo de dado.&lt;/p&gt;

&lt;p&gt;Por hoje é só galera. Em breve devo soltar mais conteúdo direcionado as bases do Machine Learning.&lt;/p&gt;
</description>
        <pubDate>Thu, 20 Apr 2017 00:00:00 -0300</pubDate>
        <link>http://localhost:4000/2017/04/20/variables-in-statistic/</link>
        <guid isPermaLink="true">http://localhost:4000/2017/04/20/variables-in-statistic/</guid>
        
        
        <category>Statistics</category>
        
        <category>Data Science</category>
        
      </item>
    
      <item>
        <title>Hello World R - Da base à Regressão Linear</title>
        <description>&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://meriatblob.blob.core.windows.net/images/2017/04/14/capa-logo-r.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;A linguagem R é um projeto GNU de software livre. O &lt;strong&gt;R&lt;/strong&gt; derivou de uma linguagem chamada &lt;strong&gt;S&lt;/strong&gt; (de “statistics”), criada na &lt;strong&gt;Bell Laboratories&lt;/strong&gt; nos anos 70. Esta é uma linguagem usada por programadores e cientistas de dados para computação estatística.&lt;/p&gt;

&lt;p&gt;R foi desenvolvida por estatísticos para estatística, dado seu foco na resolução de problemas matemáticos, ele possui um estrutura simples o que facilita a implementação e traz ganhos na otimização no tempo de desenvolvimento. Você pode obter todas as referncias na documentação oficial em &lt;a href=&quot;https://www.rdocumentation.org/&quot;&gt;rdocumentation.org&lt;/a&gt;, fora que é possível contar com um riquíssimo ecossistema de pacotes para diferentes áreas de aplicação.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Para começar vamos criar um exemplo de regressão linear, uma espécie de &lt;strong&gt;“Hello World”&lt;/strong&gt; da computação estatística. Então, mãos a obra…&lt;/p&gt;

&lt;h2 id=&quot;regressão-linear&quot;&gt;Regressão Linear&lt;/h2&gt;

&lt;p&gt;A regressão linear é uma técnica estatística usada para descrever a relação entre uma variável numérica (na estatística, chamada de variável dependente) e uma ou mais variáveis explicativas (chamadas de variáveis independentes) que podem ser numéricas ou categóricas. Quando há apenas uma única variável explicativa/de previsão, a técnica é chamada de regressão linear simples. Quando houver duas ou mais variáveis independentes, a técnica é chamada de regressão linear múltipla.&lt;/p&gt;

&lt;p&gt;Para iniciar vamos começar importando o arquivo de texto que será utilizado no exemplo.&lt;/p&gt;

&lt;pre style=&quot;font-size: 1.6em !important&quot;&gt;
    &lt;code class=&quot;r&quot;&gt;
  data &amp;lt;- read.table(&quot;sementes.txt&quot;, header=TRUE, sep=&quot;,&quot;)
    &lt;/code&gt;
&lt;/pre&gt;

&lt;p&gt;No trecho de código acima estamos utilizando a importação de um &lt;strong&gt;TXT&lt;/strong&gt; como DataSet. Na operação que estamos utilizando, podemos observar que a linguagem &lt;strong&gt;R&lt;/strong&gt; usa parâmetros nomeados. O parâmetro de cabeçalho informa se a primeira linha é de cabeçalho ou não. O parâmetro &lt;strong&gt;sep&lt;/strong&gt; (separador) indica como os valores em cada linha são separados. Por exemplo, (\t) indica valores delimitados por tabulação, e (“ “) indica valores delimitados por espaço.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;O R diferencia maiúsculas de minúsculas e você geralmente pode usar o operador (&amp;lt;-) para atribuir valores, ou o operador (=). Essa escolha é uma questão de preferência pessoal, já que ambos exercem a mesma função. Tipicamente, a boa prática aponta para o uso do operador (&amp;lt;-) na atribuição de objetos e (=) para atribuição de valores de parâmetro.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Para se trabalhar com o &lt;strong&gt;CSV&lt;/strong&gt;, formato mais comun nestes casos, seria tão simples quanto passar o caminho do arquivo.&lt;/p&gt;

&lt;pre style=&quot;font-size: 1.6em !important&quot;&gt;
    &lt;code class=&quot;r&quot;&gt;
  data &amp;lt;- read.csv(&quot;sementes.csv&quot;)
    &lt;/code&gt;
&lt;/pre&gt;

&lt;p&gt;Vamos olhar a estrutura de nosso arquivo. Se trata de uma listagem de sementes classificada por cor, comprimento, largura e índice de nutrientes. Nosso objetivo aqui é prever os valores da coluna nutrientes com base nos dados anteriores da semente.&lt;/p&gt;

&lt;p&gt;Uma vez que temos nosso arquivo carregado, podemos utilizar alguns comandos a fim de vizualizar o nosso conjunto de dados.&lt;/p&gt;

&lt;pre style=&quot;font-size: 1.6em !important&quot;&gt;
    &lt;code class=&quot;r&quot;&gt;
  # Exibe o shape dos dados
  dim(data)

  # Concatena duas strings
  paste(&quot;Linhas: &quot;, dim(data)[1], sep=&quot; &quot;)
  paste(&quot;Colunas: &quot;, dim(data)[2], sep=&quot; &quot;)

  # Exibe o dados
  print(data)
    &lt;/code&gt;
&lt;/pre&gt;

&lt;p&gt;A primeira função exibe a estrutura básica dos dados, retornando a quantidade de linhas e colunas do dataset. Notem que estou utilizando a função &lt;strong&gt;paste()&lt;/strong&gt; para concatenar duas strings. Aqui podemos ver que o resultado pode ser lido como um &lt;strong&gt;array&lt;/strong&gt;, onde tenho na posição 1 o primeiro item, e na posição 2 o segundo item. Depois apenas nomeio qual é a coluna e qual é a linha. A próxima função irá exibir os dados como extraído do arquivo. Usamos a função &lt;strong&gt;print()&lt;/strong&gt; para exibir qualquer saída para o nosso programa.&lt;/p&gt;

&lt;p&gt;Nossa saída seria algo como o que se segue abaixo:&lt;/p&gt;

&lt;pre style=&quot;font-size: 1.2em !important&quot;&gt;
    &lt;code class=&quot;r&quot;&gt;
  8 4

  'Linhas:  8'
  'Colunas:  4'

     Color Length Width Nutrients
  1   blue    5.4   1.8       0.9
  2   blue    4.8   1.5       0.7
  3   blue    4.9   1.6       0.8
  4 yellow    5.0   1.9       0.4
  5 yellow    5.2   1.5       0.3
  6 yellow    4.7   1.9       0.4
  7  green    3.7   2.2       1.4
  8  green    4.2   1.9       1.2
    &lt;/code&gt;
&lt;/pre&gt;

&lt;blockquote&gt;
  &lt;p&gt;Observe que a saída acima exibe os índices do &lt;strong&gt;array de dados, começando em 1&lt;/strong&gt;. Este é um ponto importante a se notar, já que na maioria das linguagens estamos acostumados com os índices de &lt;strong&gt;base 0&lt;/strong&gt;, como em C# ou Python.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Agora vamos executar a análise da função de &lt;strong&gt;Modelo Linear&lt;/strong&gt;. Para isso execute os comandos abaixo:&lt;/p&gt;

&lt;pre style=&quot;font-size: 1.4em !important&quot;&gt;
    &lt;code class=&quot;r&quot;&gt;
  model &amp;lt;- lm(data$Nutrients ~ (data$Color + data$Length + data$Width))

  summary(model)
    &lt;/code&gt;
&lt;/pre&gt;

&lt;p&gt;Neste trecho de código temos a variável &lt;strong&gt;model&lt;/strong&gt; que é o resultado da nossa análise de regressão linear. Aqui estamos usando a função &lt;strong&gt;lm()&lt;/strong&gt; &lt;strong&gt;(linear model)&lt;/strong&gt;, na qual temos a &lt;strong&gt;variável dependente&lt;/strong&gt; a ser prevista (data$Nutrients), e as variáveis independentes, a saber: &lt;strong&gt;data$Color, data$Length, data$Width&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;O próximo commando &lt;strong&gt;(summary(model))&lt;/strong&gt;, vai exibir o resultádo básico formatado da análise que foi armazenda no objeto model. Teremos a seguinte saída para o código acima:&lt;/p&gt;

&lt;pre style=&quot;font-size: 1.2em !important&quot;&gt;
    &lt;code class=&quot;r&quot;&gt;
  Call:
  lm(formula = data$Nutrients ~ (data$Color + data$Length + data$Width))

  Residuals:
          1         2         3         4         5         6         7         8
   0.009418 -0.030030  0.020611 -0.028320  0.044164 -0.015844  0.042596 -0.042596

  Coefficients:
                   Estimate Std. Error t value Pr(&amp;gt;|t|)   
  (Intercept)      -0.14758    0.48286  -0.306  0.77986   
  data$Colorgreen   0.35672    0.09990   3.571  0.03754 *
  data$Coloryellow -0.49083    0.04507 -10.891  0.00166 **
  data$Length       0.04159    0.07876   0.528  0.63406   
  data$Width        0.45200    0.11973   3.775  0.03255 *
  ---
  Signif. codes:  0 ‘\***\’ 0.001 ‘\**\’ 0.01 ‘\*\’ 0.05 ‘.’ 0.1 ‘ ’ 1

  Residual standard error: 0.05179 on 3 degrees of freedom
  Multiple R-squared:  0.9927,	Adjusted R-squared:  0.9829
  F-statistic: 101.6 on 4 and 3 DF,  p-value: 0.00156
    &lt;/code&gt;
&lt;/pre&gt;

&lt;p&gt;Olhando para o nosso conjunto de dados responda a seguinte pergunta: Qual seria o valor de &lt;u&gt;Nutrientes&lt;/u&gt; para uma determinada semente se a &lt;u&gt;cor&lt;/u&gt; da mesma fosse &lt;u&gt;yellow&lt;/u&gt; e suas &lt;u&gt;largura&lt;/u&gt; e &lt;u&gt;altura&lt;/u&gt; fossem &lt;u&gt;1.9&lt;/u&gt; e &lt;u&gt;4.7&lt;/u&gt; respectivamente?&lt;/p&gt;

&lt;p&gt;E ai? Já sabe a resposta?&lt;/p&gt;

&lt;p&gt;Olhando para o nosso dataset é fácil de responder esta pergunta. Estamos falando do item &lt;u&gt;[6]&lt;/u&gt; de nossa lista. Sendo assim sabemos que o valor de nutrientes será &lt;u&gt;0.4&lt;/u&gt;.&lt;/p&gt;

&lt;p&gt;Agora queremos &lt;u&gt;prever&lt;/u&gt; este valor usando nosso modelo. Como faremos isso?&lt;/p&gt;

&lt;p&gt;Vamos olhar para o resultado da análse que fizemos anteriormente. Em Coefficients vamos utilizar apenas a primeira e segunda colunas. Temos aqui nossas variáveis independetes e suas estimativas.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Vale notar que temos uma constante chamada (Intercept), não associada a qualquer variável.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Quando você tem variáveis explicativas categóricas, um dos valores é descartado. Em nosso caso o valor escolhido foi o blue.&lt;/p&gt;

&lt;p&gt;Para fazer uma previsão usando o modelo, é necessário calcular a soma linear dos valores das estimativas multiplicados pelos valores correspondentes em relação as variáveis independentes. Em nosso caso a equação seria:&lt;/p&gt;

&lt;pre style=&quot;font-size: 1.2em !important&quot;&gt;
    &lt;code class=&quot;r&quot;&gt;
  -0.14758 + (0.35672 * 0) + (-0.49083 * 1) + (0.04159 * 4.7) + (0.45200 * 1.9)
    &lt;/code&gt;
&lt;/pre&gt;

&lt;p&gt;Vamos entender como chegar neste resultado. Com base nos quadro abaixo fica mais simples compreender:&lt;/p&gt;

&lt;table class=&quot;table-fill&quot;&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;NA&lt;/th&gt;
      &lt;th&gt;yellow&lt;/th&gt;
      &lt;th&gt;green&lt;/th&gt;
      &lt;th&gt;Length&lt;/th&gt;
      &lt;th&gt;Width&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;-0.14758&lt;/td&gt;
      &lt;td&gt;0.35672&lt;/td&gt;
      &lt;td&gt;-0.49083&lt;/td&gt;
      &lt;td&gt;0.04159&lt;/td&gt;
      &lt;td&gt;0.45200&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;!-- &lt;div style=&quot;margin-bottom: 3em;&quot;&gt;&lt;/div&gt; --&gt;

&lt;p&gt;Primeiro listamos os valores da coluna Estimate. Depois para cada valor, multiplicamos a variável correspondente. No caso do primeiro valor estamos falando da constante Intercept, logo não existe valor a ser multiplicado. Para o segundo valor, temos como resultado &lt;u&gt;(0.35672 * 0)&lt;/u&gt;. É o sugundo valor multiplicado por 0, já que nossa previsão não inclui a variável green. Multiplicamos o valor de data$Length, 0.04159 por 4.7 e temos (0.04159 * 4.7). A mesma lógica para data$Width e temos (0.45200 * 1.9).&lt;/p&gt;

&lt;p&gt;O resultado será 0.415863, um valor muito próximo de 0.40, que é o valor real descrito no arquivo.&lt;/p&gt;

&lt;p&gt;Na saída acima temos uma sessão, iniciada com &lt;u&gt;Residual standard error&lt;/u&gt;. Aqui temos a relação entre as variáveis independentes e a variável dependente.&lt;/p&gt;

&lt;pre style=&quot;font-size: 1.2em !important&quot;&gt;
    &lt;code class=&quot;r&quot;&gt;
  Residual standard error: 0.05179 on 3 degrees of freedom
  Multiple R-squared:  0.9927,	Adjusted R-squared:  0.9829
  F-statistic: 101.6 on 4 and 3 DF,  p-value: 0.00156
    &lt;/code&gt;
&lt;/pre&gt;

&lt;p&gt;O valor de &lt;u&gt;Multiple R-squared (0,9927)&lt;/u&gt; é a porcentagem de variação na variável dependente explicada pela combinação linear das variáveis independentes. Neste caso os valores de R-squared são valores entre 0 e 1, onde os valores mais altos significam um modelo de previsão melhor. Em nosso caso, R-squared tem um valor extremamente alto, indicando que Color, Length e Width podem prever o resultado com boa precisão. F-statistic, Adjusted R-squared e p-value são outras medidas de ajuste do modelo.&lt;/p&gt;

&lt;h2 id=&quot;impressões&quot;&gt;Impressões&lt;/h2&gt;
&lt;p&gt;No geral minha primeira impressão da linguagem &lt;u&gt;&lt;b&gt;R&lt;/b&gt;&lt;/u&gt; foi muito boa. Achei uma sintaxe limpa, fácil e bem direcionada ao seu propósito. Já tinha em mente que esta seria uma linguagem orientada a estatística computacional, mas esperava algo mais rebuscado, diferente da facilidade de compreensão que tive.&lt;/p&gt;

&lt;h2 id=&quot;conclusão&quot;&gt;Conclusão&lt;/h2&gt;
&lt;p&gt;Minha ideia aqui não era fazer um comparativo, ou muito menos explicar os principais comandos da linguagem. A documentação por si só já é eficaz, e ainda existe uma infinidade de materiais sobre este tema. Preferi aqui fazer uma analise da minha impressão ao implementar uma técnica básica como a regressão linear.&lt;/p&gt;

&lt;h2 id=&quot;referências&quot;&gt;Referências&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.rdocumentation.org/&quot;&gt;rdocumentation.org&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Linear_regression&quot;&gt;Linear Regression&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Fri, 14 Apr 2017 00:00:00 -0300</pubDate>
        <link>http://localhost:4000/2017/04/14/hello-world-r/</link>
        <guid isPermaLink="true">http://localhost:4000/2017/04/14/hello-world-r/</guid>
        
        
        <category>R</category>
        
        <category>Data Science</category>
        
      </item>
    
      <item>
        <title>Devops Summit Brasil 2017 - Minha palestra sobre Azure Cognitive Services</title>
        <description>&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://meriatblob.blob.core.windows.net/images/2017/04/01/palestra-0.jpg&quot; class=&quot;absolute-bg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Como o prometido, vou fazer um compliado do que vimos na minha apresentação sobre Azure Cognitive Services no DevOpsSummit Brasil 2017.&lt;/p&gt;

&lt;p&gt;A ideia era apresentar a plataforma, entendendo o que são serviços cognitivos, sua importância e como eles foram incorporados e distribuídos no ecossistema da Microsoft.&lt;/p&gt;

&lt;h2 id=&quot;cognitive-services--ai&quot;&gt;Cognitive Services &amp;amp; AI&lt;/h2&gt;
&lt;p&gt;Como vimos, intligência artificial não é um assunto novo, pelo contrário, estamos falando de um assunto que vem assombrando o imaginário humano nos últimos 100 anos, e pesquisado academicamente hà mais de 5 décadas.&lt;/p&gt;

&lt;p&gt;Neste mundo de AI, os serviços cognitivos estão ligados as aplicações voltadas a proximidade da linguagem natural. Temos de analise de sentimento a visão computacional, tudo de forma simples e fácil, como uma API deve ser.&lt;/p&gt;

&lt;h2 id=&quot;o-evento&quot;&gt;O evento&lt;/h2&gt;
&lt;p&gt;O evento ocorreu na sede da Microsoft em São Paulo, e foi dividido em 4 trilhas:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;TECNOLOGIAS NA NUVEM&lt;/li&gt;
  &lt;li&gt;DESENVOLVIMENTO MODERNO&lt;/li&gt;
  &lt;li&gt;MELHORIA CONTÍNUA&lt;/li&gt;
  &lt;li&gt;PRÁTICAS E PROCESSOS&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Tive a honra de palestrar na trilha de &lt;strong&gt;Desenvolvimento Moderno&lt;/strong&gt; explorando um tema que tem gerado muito interesse nos últimos tempos: Computação Cognitiva.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://meriatblob.blob.core.windows.net/images/2017/04/01/palestra-1.jpg&quot; class=&quot;absolute-bg&quot; /&gt;&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://meriatblob.blob.core.windows.net/images/2017/04/01/palestra-2.jpg&quot; class=&quot;absolute-bg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Vale lembrar que mesmo não tendo tempo para todas as demonstrações, conseguimos rodar a API de &lt;strong&gt;Face Detect&lt;/strong&gt;, o resultado foi o seguinte:&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://meriatblob.blob.core.windows.net/images/2017/04/01/demo-final.png&quot; class=&quot;absolute-bg&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;os-materiais&quot;&gt;Os materiais&lt;/h2&gt;

&lt;p&gt;Todas as demos utilizadas na apresentação foram consumindo apenas a &lt;strong&gt;API REST&lt;/strong&gt;, cuja a documentação está disponível em: &lt;a href=&quot;https://www.microsoft.com/cognitive-services/en-us/documentation&quot;&gt;Cognitive Services Documentation&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;O código apresentado já está disponível no meu GitHub no repositório &lt;a href=&quot;https://github.com/vitormeriat/cognitive-services&quot;&gt;Cognitive Services&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Vale lembrar que neste repositório vou colocar vários testes incluindo outras plataformas de Cloud.&lt;/p&gt;

&lt;p&gt;Abaixo é só clicar na imagem para baixar ou visualizar os slides da apresentação.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;a href=&quot;//www.slideshare.net/VitorMeriat/devopssummit-2017-azure-cognitive-services&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://meriatblob.blob.core.windows.net/images/2017/04/01/devops-summit-brasil-ppt.jpg&quot; class=&quot;absolute-bg&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;No próximo post&lt;/p&gt;

&lt;div style=&quot;margin-bottom: 5em;&quot;&gt;&lt;/div&gt;

&lt;h3 id=&quot;até-a-próxima-pessoal-&quot;&gt;Até a próxima pessoal ;)&lt;/h3&gt;
</description>
        <pubDate>Sat, 01 Apr 2017 00:00:00 -0300</pubDate>
        <link>http://localhost:4000/2017/04/01/devopssummitbrasil-azure-cognitive-services/</link>
        <guid isPermaLink="true">http://localhost:4000/2017/04/01/devopssummitbrasil-azure-cognitive-services/</guid>
        
        
        <category>IA</category>
        
        <category>Cognitive Computing</category>
        
        <category>Microsoft Azure</category>
        
        <category>Python</category>
        
        <category>Palestras</category>
        
        <category>Comunidade</category>
        
      </item>
    
      <item>
        <title>Kaggle Competition - Titanic: Machine Learning from Disaster</title>
        <description>&lt;p&gt;&lt;img style=&quot;width: 100%;&quot; src=&quot;http://blob.vitormeriat.com.br/images/2017/03/18/capa.jpg&quot; class=&quot;absolute-bg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;O &lt;strong&gt;Projeto Titanic&lt;/strong&gt; é uma competição de &lt;strong&gt;Data Science&lt;/strong&gt; promovida pelo &lt;a href=&quot;kaggle.com&quot;&gt;Kaggle.com&lt;/a&gt;. O objetivo deste desafio é deduzir os índices de sobrevivência dos passageiros do Titanic.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Embora os &lt;a href=&quot;https://www.youtube.com/watch?v=JVgkvaDHmto&quot;&gt;Mythbusters&lt;/a&gt; em seu programa tenham provado completamente que era possível Jack e Rose ter sobrevivido utilizando a porta flutuante, o interesse aqui é medir a chance real de sobrevivência dos passageiros a bordo do Titanic em 14 de abril de 1912.&lt;/p&gt;

&lt;p&gt;A história do Titanic é muito conhecida, tendo originado diversos livros, filmes, HQs e afins. É válido lembrar que a história narrada de forma célebre por James Cameron em seu filme de 1997, ilustra perfeitamente o motivo deste desafio. Vamos começar com uma breve perspectiva sobre o tema: Em Abril de 1912 o Titanic zarpou rumo a New York com 2224 passageiros, dos quais estima-se que apenas 710 tenham sobrevivido.&lt;/p&gt;

&lt;p&gt;É aqui que entra nosso desafio: Desenvolver um padrão simples para identificar o perfil dos sobreviventes deste desastre.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Nota: Muitos dos barcos salva-vidas não estavam com a sua capacidade máxima de pessoas a bordo. Se estivessem, seria possível salvar 53,4% dos passageiros, mas apenas 31,6% deles sobreviveram.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Neste caso não temos complicação com elementos aleatórios de sorte. A maioria dos sobreviventes eram mulheres, crianças e pessoas da alta sociedade.&lt;/p&gt;

&lt;h2 id=&quot;start&quot;&gt;Start&lt;/h2&gt;

&lt;p&gt;A lista de sobreviventes e não sobreviventes já foi transformada em dois datasets, &lt;strong&gt;train.csv&lt;/strong&gt; e &lt;strong&gt;test.csv&lt;/strong&gt;. Existe apenas uma diferença entre os dois arquivos, a lista de status de sobrevivência que está presente apenas nos dados de &lt;strong&gt;treino&lt;/strong&gt;. Nos dados de teste este valor precisa ser deduzido.&lt;/p&gt;

&lt;p&gt;Neste desafio vamos utilizar os dados do site Kaggle para desenvolver três modelos (regressão logística, árvore de probabilidade condicional e florestas aleatórias), a fim de prever as taxas de sobrevivência para os passageiros do Titanic.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;http://blob.vitormeriat.com.br/images/2017/03/18/decision-tree.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;O conjunto de teste conta com 418 passageiros e o conjunto de treinamento é composto por 891 passageiros. O dataset é composto por:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Class&lt;/li&gt;
  &lt;li&gt;Name&lt;/li&gt;
  &lt;li&gt;Sex&lt;/li&gt;
  &lt;li&gt;Age&lt;/li&gt;
  &lt;li&gt;Sibling/Spouse&lt;/li&gt;
  &lt;li&gt;Parents/Children&lt;/li&gt;
  &lt;li&gt;Ticket (*)&lt;/li&gt;
  &lt;li&gt;Fare&lt;/li&gt;
  &lt;li&gt;Cabin (*)&lt;/li&gt;
  &lt;li&gt;Port of Embarkment.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Como na maioria das competições Kaggle, você recebe dois conjuntos de dados:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Um conjunto de treino completo com o resultado (outcome ou target variable), para um grupo de passageiros, bem como uma coleção de outros parâmetros, como sua idade, sexo, etc. Este é o conjunto de dados em que você deve treinar seu modelo preditivo.&lt;/li&gt;
  &lt;li&gt;Um conjunto de teste, para o qual você deve prever a variável de destino agora desconhecida com base nos outros atributos de passageiros que são fornecidos para ambos os conjuntos de dados.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Este é um ótimo ponto de entrada para aprender machine learning com um conjunto de dados pequeno, gerenciável, interessante e com variáveis ​​de fácil compreensão.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;http://blob.vitormeriat.com.br/images/2017/03/18/ml-pattern.png&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;passo-1&quot;&gt;Passo 1&lt;/h1&gt;
&lt;p&gt;A tragédia do “Titanic” está associada com a regra não escrita do salvamento no mar: “mulheres e crianças primeiro”.&lt;/p&gt;

&lt;p&gt;Nesta tarefa, os competidores precisam analisar a probabilidade de sobrevivência das diferentes categorias de passageiros.&lt;/p&gt;

&lt;p&gt;Para determinar se o passageiro sobreviveu ao “Titanic”, vamos usar uma árvore de decisão. Uma árvore de decisão é gerada automaticamente com base no parâmetro de entrada. A imagem abaixo mostra um exemplo de uma árvore de decisão é criada.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;http://blob.vitormeriat.com.br/images/2017/03/18/decision-tree02.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Vamos estipular o sexo dos passageiros e tripulantes. Este é um  dado importante, uma vez que o sexo do passageiro desempenha um papel crucial para determinar a sobrevivência do mesmo. Um simples count revela que temos 891 passageiros dos quais 65% são homens e 35% são mulheres.&lt;/p&gt;

&lt;table class=&quot;table-fill&quot;&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;Gender&lt;/th&gt;
      &lt;th&gt;Count of Passengers&lt;/th&gt;
      &lt;th&gt; % &lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;female&lt;/td&gt;
      &lt;td&gt;314&lt;/td&gt;
      &lt;td&gt;35%&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;male&lt;/td&gt;
      &lt;td&gt;577&lt;/td&gt;
      &lt;td&gt;65%&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Se adicionarmos a taxa de sobrevivência a equação vamos ver que existe um padrão aqui.&lt;/p&gt;

&lt;table class=&quot;table-fill&quot;&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;Count of Passengers&lt;/th&gt;
      &lt;th&gt;Survived Status&lt;/th&gt;
      &lt;th&gt; &lt;/th&gt;
      &lt;th&gt; &lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;background: #63dd69; color: white;&quot;&gt;Gender&lt;/td&gt;
      &lt;td style=&quot;background: #63dd69; color: white;&quot;&gt;Not Survived&lt;/td&gt;
      &lt;td style=&quot;background: #63dd69; color: white;&quot;&gt;Survived&lt;/td&gt;
      &lt;td style=&quot;background: #63dd69; color: white;&quot;&gt;Total&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;female&lt;/td&gt;
      &lt;td&gt;81&lt;/td&gt;
      &lt;td&gt;233&lt;/td&gt;
      &lt;td&gt;314&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;male&lt;/td&gt;
      &lt;td&gt;468&lt;/td&gt;
      &lt;td&gt;109&lt;/td&gt;
      &lt;td&gt;577&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;background: #777777; color: white;&quot;&gt;Total&lt;/td&gt;
      &lt;td style=&quot;background: #777777; color: white;&quot;&gt;549&lt;/td&gt;
      &lt;td style=&quot;background: #777777; color: white;&quot;&gt;342&lt;/td&gt;
      &lt;td style=&quot;background: #777777; color: white;&quot;&gt;891&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;O seguinte pode ser observado a partir dos dados acima:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;62% (549/891) dos passageiros não sobreviveram&lt;/li&gt;
  &lt;li&gt;38% (342/891) sobreviveram&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Dos 38% que sobreviveram, os passageiros do sexo feminino sobreviveram em maior número maior que os passageiros machos&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;De todos os passageiros do sexo feminino (233/314) 74% sobreviveram&lt;/li&gt;
  &lt;li&gt;De todos os passageiros do sexo masculino (109/577), apenas 19% sobreviveram&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Podemos ilustrar este comportamento usando uma árvore de decisão. Cada nó determina o resultado final com base na maioria. Os votos do nó à direita representam o status de sobrevivência, já que a maioria nesta opção sobreviveu. Os votos do à esquerda representam o status de não sobrevivência, uma vez que a maioria não sobreviveu.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;http://blob.vitormeriat.com.br/images/2017/03/18/ml-pattern-all.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Este é nosso primeiro padrão. Par facilitar vamos conceituar algumas coisas: O dataset de treino é chamado de &lt;strong&gt;labelled dataset&lt;/strong&gt;, onde a coluna &lt;u&gt;Survived&lt;/u&gt; é chamda de “label” ou &lt;strong&gt;response data&lt;/strong&gt;. Esta abordagem é chamada de aprendizagem supervisionada, onde aprendemos com os dados de treino e aplicamos este aprendizado nos dados de teste. O resultado desta abordagem é binária, portanto estamos aplicando uma técnica de classificação, utilizando duas classes, a saber, &lt;strong&gt;survived&lt;/strong&gt; ou &lt;strong&gt;not survived&lt;/strong&gt;.&lt;/p&gt;

&lt;h1 id=&quot;o-repositório&quot;&gt;O repositório&lt;/h1&gt;
&lt;p&gt;Você pode olhar o código completo acessando o mesmo no repositório &lt;strong&gt;Meriat Machine Learning Notes&lt;/strong&gt; no meu Github.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/vitormeriat/meriat-ml-notes/blob/master/Titanic%20-%20Machine%20Learning%20from%20Disaster.ipynb&quot;&gt;Titanic: Machine Learning from Disaster&lt;/a&gt;&lt;/p&gt;

&lt;div style=&quot;margin-bottom: 5em;&quot;&gt;&lt;/div&gt;

&lt;h3 id=&quot;até-a-próxima-pessoal-&quot;&gt;Até a próxima pessoal ;)&lt;/h3&gt;
</description>
        <pubDate>Sat, 18 Mar 2017 00:00:00 -0300</pubDate>
        <link>http://localhost:4000/2017/03/18/titanic-machine-learning-from-disaster/</link>
        <guid isPermaLink="true">http://localhost:4000/2017/03/18/titanic-machine-learning-from-disaster/</guid>
        
        
        <category>IA</category>
        
        <category>Machine Learning</category>
        
        <category>Data Science</category>
        
        <category>Deep Learning</category>
        
        <category>Jupyter Notebook</category>
        
        <category>Python</category>
        
      </item>
    
      <item>
        <title>Apresentando o Meriat Machine Learning Notes</title>
        <description>&lt;p&gt;&lt;img style=&quot;width: 100%;&quot; src=&quot;http://blob.vitormeriat.com.br/images/2017/02/15/capa.jpg&quot; class=&quot;absolute-bg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;No último ano tive a oportunidade de trabalhar em projetos envolvendo IoT e Machine Learning. No processo entre aplicação, estudos e desenvolvimento, acabei separando algum material e exemplos que me ajudaram a inicar nesta carreira, bem como no processo de aprendizagem.&lt;/p&gt;

&lt;p&gt;O Meriat Machine Learning Notes nada mais é que um compendio destes estudos que resolvi compartilhar no github utilizando o Jupyter Notebook.&lt;/p&gt;

&lt;p&gt;Minha opção pelo &lt;strong&gt;Jupyter Notebook&lt;/strong&gt;, dentre tantos motivos, se dá pelo fato de conseguir de forma simples documentar e visualizar todo o código e anotações de forma simples. Vale dizer que o código que estou utilizando pode ser facilmente utilizado em outra IDE, conforme sua preferência.&lt;/p&gt;

&lt;p&gt;Algumas implementações são reprodução de exercícios dos quais eu irei apontar o material base.&lt;/p&gt;

&lt;p&gt;O material ainda está em formação, visto que ainda tenho um longo caminho a percorrer. É possível que futuramente eu altere o repositório, já que alguns estudos podem gerar um repositório separado.&lt;/p&gt;

&lt;p&gt;Por hora vou concentrando meus esforços por aqui ;)&lt;/p&gt;

&lt;h3 id=&quot;github&quot;&gt;Github&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;Study Notes on machine learning, data analysis, algorithms and best practices using Python and Jupyter Notebook.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/vitormeriat/meriat-ml-notes&quot;&gt;Meriat Machine Learning Note&lt;/a&gt;&lt;/p&gt;

&lt;div style=&quot;margin-bottom: 8em;&quot;&gt;&lt;/div&gt;

&lt;h2 id=&quot;meriat-machine-learning-note&quot;&gt;Meriat Machine Learning Note&lt;/h2&gt;

&lt;p&gt;A estrutura atual está descrita logo abaixo. Vou me esforçar para manter atualizada.&lt;/p&gt;

&lt;h4 id=&quot;file-handling&quot;&gt;File Handling&lt;/h4&gt;
&lt;p&gt;TBA&lt;/p&gt;

&lt;h4 id=&quot;sms-spam-filtering&quot;&gt;SMS Spam Filtering&lt;/h4&gt;
&lt;p&gt;TBA&lt;/p&gt;

&lt;h4 id=&quot;song-recommender&quot;&gt;Song Recommender&lt;/h4&gt;
&lt;p&gt;TBA&lt;/p&gt;

&lt;h4 id=&quot;basic-math&quot;&gt;Basic Math&lt;/h4&gt;
&lt;p&gt;Basic math notions with python&lt;/p&gt;

&lt;h4 id=&quot;basic-statistic-in-python&quot;&gt;Basic Statistic in Python&lt;/h4&gt;
&lt;p&gt;Basic math statistics with python&lt;/p&gt;

&lt;h4 id=&quot;basic-natural-language-processing&quot;&gt;Basic Natural Language Processing&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;Tokenization&lt;/li&gt;
  &lt;li&gt;Stopword Removal&lt;/li&gt;
  &lt;li&gt;N-Grams&lt;/li&gt;
  &lt;li&gt;WordSense Disambiguation&lt;/li&gt;
  &lt;li&gt;Parts-of-Speech&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;em&gt;This module uses NLTK for the text processing processes. It is important to note that you will need to download nltk_data.&lt;/em&gt;&lt;/p&gt;

&lt;h4 id=&quot;simple-probability-model&quot;&gt;Simple Probability Model&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;Common Ground&lt;/li&gt;
  &lt;li&gt;Limit Theorems&lt;/li&gt;
  &lt;li&gt;Derived Distributions
    &lt;ul&gt;
      &lt;li&gt;Covariance&lt;/li&gt;
      &lt;li&gt;Correlation&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;imbalanced-learning-with-gaussians&quot;&gt;Imbalanced Learning with Gaussians&lt;/h4&gt;

&lt;div style=&quot;margin-bottom: 5em;&quot;&gt;&lt;/div&gt;

&lt;h3 id=&quot;até-a-próxima-pessoal-&quot;&gt;Até a próxima pessoal ;)&lt;/h3&gt;
</description>
        <pubDate>Wed, 15 Feb 2017 00:00:00 -0200</pubDate>
        <link>http://localhost:4000/2017/02/15/apresentando-meriat-ml-notes/</link>
        <guid isPermaLink="true">http://localhost:4000/2017/02/15/apresentando-meriat-ml-notes/</guid>
        
        
        <category>IA</category>
        
        <category>Machine Learning</category>
        
        <category>Data Science</category>
        
        <category>Deep Learning</category>
        
        <category>Jupyter Notebook</category>
        
        <category>Python</category>
        
      </item>
    
      <item>
        <title>Machine Learning e sua literatura clássica</title>
        <description>&lt;p&gt;A listagem a seguir pode ser categorizada como, &lt;strong&gt;Popular Science Machine Learning Books&lt;/strong&gt; ou &lt;strong&gt;Beginner Machine Learning Books&lt;/strong&gt;. É possível ainda encontrar vários livros desta listagem em categorias como &lt;strong&gt;Introductory Machine Learning Books&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img style=&quot;width: 100%;&quot; src=&quot;http://blob.vitormeriat.com.br/images/2017/02/07/capa.jpg&quot; class=&quot;absolute-bg&quot; /&gt;&lt;/p&gt;

&lt;div style=&quot;margin-bottom: 5em;&quot;&gt;&lt;/div&gt;

&lt;h3 id=&quot;machine-learning-books-selection&quot;&gt;Machine Learning Books Selection&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/0465065708&quot;&gt;The Master Algorithm: How the Quest for the Ultimate Learning Machine Will Remake Our World&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/1119145678&quot;&gt;Predictive Analytics: The Power to Predict Who Will Click, Buy, Lie, or Die&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/0143125087&quot;&gt;The Signal and the Noise: Why So Many Predictions Fail–but Some Don’t&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/039334777X&quot;&gt;Naked Statistics: Stripping the Dread from the Data&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/0307275175&quot;&gt;The Drunkard’s Walk: How Randomness Rules Our Lives&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/1449361323&quot;&gt;Data Science for Business: What You Need to Know about Data Mining and Data-Analytic Thinking&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/111866146X&quot;&gt;Data Smart: Using Data Science to Transform Information into Insight&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/0128042915&quot;&gt;Data Mining, Fourth Edition: Practical Machine Learning Tools and Techniques&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/1449358659&quot;&gt;Doing Data Science: Straight Talk from the Frontline&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/B007A0BNP4&quot;&gt;Machine Learning for Hackers: Case Studies and Algorithms to Get You Started&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/1617290181&quot;&gt;Machine Learning in Action&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/0596529325&quot;&gt;Programming Collective Intelligence: Building Smart Web 2.0 Applications&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/1461471370&quot;&gt;An Introduction to Statistical Learning: with Applications in R (Springer Texts in Statistics)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/1461468485&quot;&gt;Applied Predictive Modeling&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/0387848576&quot;&gt;The Elements of Statistical Learning: Data Mining, Inference, and Prediction&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/0387310738&quot;&gt;Pattern Recognition and Machine Learning&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/0262018020&quot;&gt;Machine Learning: A Probabilistic Perspective&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/B00YDJC98K&quot;&gt;Learning From Data by Yaser S. Abu-Mostafa, Malik Magdon-Ismail, Hsuan-Tien Lin&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/0070428077&quot;&gt;Machine Learning 1st Edition&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/1107422221&quot;&gt;Machine Learning: The Art and Science of Algorithms that Make Sense of Data&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/026201825X&quot;&gt;Foundations of Machine Learning (Adaptive Computation and Machine Learning series)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/0596529325&quot;&gt;Programming Collective Intelligence: Building Smart Web 2.0 Applications&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/1118675029&quot;&gt;Time Series Analysis: Forecasting and Control&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/0997847913&quot;&gt;Practical Time Series Forecasting with R: A Hands-On Guide&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/3319298526&quot;&gt;Introduction to Time Series and Forecasting&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/0987507109&quot;&gt;Forecasting: principles and practice&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;div style=&quot;margin-bottom: 5em;&quot;&gt;&lt;/div&gt;

&lt;h3 id=&quot;com-foco-em-python&quot;&gt;Com foco em Python&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/1783555130&quot;&gt;Python Machine Learning&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/149190142X&quot;&gt;Data Science from Scratch: First Principles with Python&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/1491962291&quot;&gt;Hands-On Machine Learning with Scikit-Learn and TensorFlow: Concepts, Tools, and Techniques for Building Intelligent Systems&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/1449369413&quot;&gt;Introduction to Machine Learning with Python: A Guide for Data Scientists&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/B01N4FUDSE&quot;&gt;Vital Introduction to Machine Learning with Python: Best Practices to Improve and Optimize Machine Learning Systems and Algorithms&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/1118961749&quot;&gt;Machine Learning in Python: Essential Techniques for Predictive Analysis&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/1491912057&quot;&gt;Python Data Science Handbook: Essential Tools for Working with Data&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/1633430030&quot;&gt;Introducing Data Science: Big Data, Machine Learning, and more, using Python tools&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/1617291927&quot;&gt;Real-World Machine Learning&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;div style=&quot;margin-bottom: 5em;&quot;&gt;&lt;/div&gt;

&lt;h3 id=&quot;com-foco-em-r&quot;&gt;Com foco em R&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/1491910399&quot;&gt;R for Data Science: Import, Tidy, Transform, Visualize, and Model Data&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/1784393908&quot;&gt;Machine Learning with R&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/1783982047&quot;&gt;Machine Learning With R Cookbook – 110 Recipes for Building Powerful Predictive Models with R&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/1784390844&quot;&gt;R Machine Learning By Example&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/178398774X&quot;&gt;R Machine Learning Essentials&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/178398452X&quot;&gt;Mastering Machine Learning with R&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/1461471370&quot;&gt;An Introduction to Statistical Learning: with Applications in R&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/1617291560&quot;&gt;Practical Data Science with R&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/1461468485&quot;&gt;Applied Predictive Modeling&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/0123969638&quot;&gt;R and Data Mining: Examples and Case Studies&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Aqui vale fazer uma consideração: Temos a seguir uma listagem separada sobre Deep Learning. Isso se deve por essa ser uma técnica de Machine Learning que diz respeito a oportunidade de aprendizagem profunda com o uso de redes neurais.&lt;/p&gt;

&lt;p&gt;Em momento oportuno devo vou compartilhar aqui mais informações sobre Deep Learning, como meus estudos, códigos e referências. Por hora, segue a bibliografia melhor avaliada sobre o tema.&lt;/p&gt;

&lt;div style=&quot;margin-bottom: 5em;&quot;&gt;&lt;/div&gt;

&lt;h3 id=&quot;deep-learning&quot;&gt;Deep Learning&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/0262035618&quot;&gt;Deep Learning&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/1491914254&quot;&gt;Deep Learning: A Practitioner’s Approach&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/1491925612&quot;&gt;Fundamentals of Deep Learning: Designing Next-Generation Machine Intelligence Algorithms&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/1491978511&quot;&gt;Learning TensorFlow: A guide to building deep learning systems&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/1617293873&quot;&gt;Machine Learning with TensorFlow&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/1786462168&quot;&gt;TensorFlow Machine Learning Cookbook&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/1786468573&quot;&gt;Getting Started with TensorFlow&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/dp/1939902452&quot;&gt;TensorFlow for Machine Intelligence: A Hands-On Introduction to Learning Algorithms&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;div style=&quot;margin-bottom: 5em;&quot;&gt;&lt;/div&gt;

&lt;h3 id=&quot;É-isso-ai-valeu-pessoal-&quot;&gt;É isso ai… valeu pessoal ;)&lt;/h3&gt;
</description>
        <pubDate>Tue, 07 Feb 2017 00:00:00 -0200</pubDate>
        <link>http://localhost:4000/2017/02/07/literatura-classica-machine-learning/</link>
        <guid isPermaLink="true">http://localhost:4000/2017/02/07/literatura-classica-machine-learning/</guid>
        
        
        <category>IA</category>
        
        <category>Machine Learning</category>
        
        <category>Data Science</category>
        
        <category>Deep Learning</category>
        
      </item>
    
      <item>
        <title>Workshop de Machine Learning na CPBR10</title>
        <description>&lt;div style=&quot;width: 100%; -ms-align-items: center; -webkit-align-items: center; align-items: center;&quot;&gt;
    &lt;img style=&quot;width: 100%;&quot; src=&quot;http://blob.vitormeriat.com.br/images/2017/02/05/campus-ia.jpg&quot; class=&quot;absolute-bg&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;Este ano tive a honra de mais uma vez palestrar na Campus Party. Como de costume minha participação foi em conjunto com a comunidade CrazyTechGuys.&lt;/p&gt;

&lt;p&gt;Nesta oportunidade dividi as ações com o mestre Jorge Maia, no workshop de &lt;a href=&quot;http://campuse.ro/events/campus-party-brasil-2017/workshop/sensores-internet-das-coisas-e-inteligencia-artificial-de-perto-e-sem-mitos/&quot;&gt;IoT e Machine Learning&lt;/a&gt;. Nesta atividade trabalhamos além dos conceitos básicos de IoT e Machine Learning, novidade de mercado, protocolos, linguagens e plataformas.&lt;/p&gt;

&lt;p&gt;Na minha deixa pude demonstrar como iniciar um projeto de Machine Learning do zero utilizando como ferramentas o Jupyter Notebook, Python e o famoso dataset Pima Indians Diabetes Database que é normalmente utilizando para tarefas de classificação e, é largamente utilizado para prever o início de diabetes com base em diagnósticos já realizados.&lt;/p&gt;

&lt;p&gt;É possível encontrar diversos exemplos de utilização do dataset, bem como uma ampla gama de exemplos de diferentes explorações e tratamentos dos dados.&lt;/p&gt;

&lt;p&gt;Neste workshop demonstrei como utilizar o Jupyter Notebook bem como os principais módulos para se trabalhar com Data Science e Python. Vimos os principais conceitos envolvidos nesta atividade e como aplicar em exercício prático.&lt;/p&gt;

&lt;h1 id=&quot;resumindo&quot;&gt;Resumindo&lt;/h1&gt;

&lt;p&gt;Quando falamos de ML, temos duas pricipais tecnicas para trabalhar:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Aprendizagem supervisionada&lt;/li&gt;
  &lt;li&gt;Aprendizagem Nao supervisionada&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Quando falamos de aprendizagem supervisionada e não supervisionada, tendemos a pensar que a diferença está na predição com ou sem a supervisão humana, mas na realidade tudo está ligado aos dados.&lt;/p&gt;

&lt;p&gt;Quando se trata de Aprendizagem supervisionada, cada linha possui diversos atributos, que serão os inputs e os possíveis outputs, ou seja, o valor que esperamos para o conjunto de atributos da linha.&lt;/p&gt;

&lt;p&gt;Se usamos como exemplo determinar o valor de casas em uma determinada região, podemos pegar como atributos o tamanho, quantidade de quartos, área da casa, localidade e claro, o preço.&lt;/p&gt;

&lt;p&gt;Logo após passamos esses dados em um algorítimo de ML, com todos os dados de entrada e os possíveis dados de saída, que neste caso será o valor da casa. O algorítimo determina a relação entre os atributos da casa e seu valor final.&lt;/p&gt;

&lt;p&gt;Depois o resultante do algorítimo será um Modelo, que nada mais é que uma função matemática. Este Modelo será o cara que vai receber os novos dados e ser capaz de prever o preço final.&lt;/p&gt;

&lt;p&gt;O modelo é capaz de prever o preço, pq ele aplica a função matemática que ele aprendeu durante o processo no novo conjunto de dados. A medida que temos novos dados, podemos melhorar nosso modelo e realizar o tão famoso aprendizado de máquina…&lt;/p&gt;

&lt;p&gt;No processo de aprendizagem não supervisionada, o algorítimo busca em seu conjunto de dados, clusters, ou agrupamentos de dados com características semelhantes.&lt;/p&gt;

&lt;p&gt;Sendo assim, o algorítimo identifica a partir dos dados de entrada grupos de dados que compartilhem as mesmas características. Neste caso, não precisamos apresentar os possíveis dados de saída.&lt;/p&gt;

&lt;p&gt;Imagine um conjunto de gravações com pessoas falando. Podemos gerar um dataset com os atributos das vozes das pessoas como entonação, inflexção, altura e etc. Passamos estes dados em um algorítimo de aprendizagem não supervisionado.&lt;/p&gt;

&lt;p&gt;O algorítimo analisa os dados e cria um modelo que classifica clusters de dados que compartilham os mesmos padrões de voz. Com isso o algorítimo será capaz de isolar uma única voz a partir dos dados aprendidos.&lt;/p&gt;

&lt;p&gt;Podemos rezumir de forma simples da segunte maneira:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Aprendizagem supervisionada&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Previsão de valores&lt;/li&gt;
  &lt;li&gt;Nossos dados de treino devem ter valores de entrada e saída, para que o mesmo possa aprender a partir dos novos dados de entrada, a gerar uma saída correta.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Aprendizagem não supervisionada&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Idendificação de grupos de dados&lt;/li&gt;
  &lt;li&gt;Nossos dados precisam apenas possuir entradas&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;source&quot;&gt;Source&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/vitormeriat/workshop-cpbr10&quot;&gt;Github&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;dataset&quot;&gt;Dataset&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes&quot;&gt;UCI&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.kaggle.com/uciml/pima-indians-diabetes-database&quot;&gt;Kaggle&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Sun, 05 Feb 2017 00:00:00 -0200</pubDate>
        <link>http://localhost:4000/2017/02/05/cpbr10-workshop-machine-learning/</link>
        <guid isPermaLink="true">http://localhost:4000/2017/02/05/cpbr10-workshop-machine-learning/</guid>
        
        
        <category>IA</category>
        
        <category>Machine Learning</category>
        
        <category>Jupyter Notebook</category>
        
        <category>Python</category>
        
      </item>
    
      <item>
        <title>Inteligência Artificial, história indústria e economia</title>
        <description>&lt;p&gt;A importância científica, industrial e econômica da &lt;span style=&quot;font-size: 1.6em;&quot;&gt;I&lt;/span&gt;nteligência &lt;span style=&quot;font-size: 1.6em;&quot;&gt;A&lt;/span&gt;rtificial, bem como o seu previsível impacto social têm crescido muito nos últimos anos, estimando-se que cresça muito mais, apoiada quer na banalização da potência de cálculo (necessária à complexidade das suas operações), quer nos progressos reais verificados na investigação fundamental, cujos resultados saem agora dos laboratórios para a indústria. Na sua vertente tecnológica, a IA comporta uma importante faceta de engenharia. Na verdade, pretende em última análise programar computadores (a que poderão estar acoplados sensores e actuadores) de forma que desempenhem com êxito e eficiência tarefas que requerem inteligência.&lt;/p&gt;

&lt;p&gt;Tal desempenho tem como suporte a combinação racional de métodos gerais e automatizados de abordagem à formulação e resolução lógica de problemas. É pela generalidade, computabilidade, e combinabilidade lógica desses métodos que a IA se distingue como disciplina científica. Em contraste, outras disciplinas científicas usam técnicas inteligentes mas específicas do seu domínio; técnicas gerais mas sem explicitação do raciocínio; técnicas múltiplas mas não articuladas num todo automatizado.&lt;/p&gt;

&lt;p&gt;As técnicas da IA encontram-se em evolução rápida, e algumas vão-se consubstanciando em instrumentos de “software” comercialmente disponíveis, de utilização acessível àqueles com um mínimo de inclinação informática. Outras dessas técnicas, não existindo sob a forma de instrumento acabado acessível ao leigo, necessitam de um especialista para a sua aplicação casuística.&lt;/p&gt;

&lt;p&gt;A utilização da IA começa a generalizar-se com muitos êxitos de aplicação. Ocorrem anualmente inúmeros colóquios internacionais expressamente dedicados a essas aplicações. Em Portugal verifica-se um potencial considerável em IA, já consolidado em grande parte a nível do ensino e da investigação.&lt;/p&gt;

&lt;div style=&quot;margin-bottom: 5em;&quot;&gt;&lt;/div&gt;

&lt;h4 id=&quot;É-isso-ai-pessoal-em-breve-continuamos-esse-bate-papo-&quot;&gt;É isso ai pessoal, em breve continuamos esse bate papo ;)&lt;/h4&gt;
</description>
        <pubDate>Thu, 19 Jan 2017 00:00:00 -0200</pubDate>
        <link>http://localhost:4000/2017/01/19/inteligencia-artificial-historia-industria/</link>
        <guid isPermaLink="true">http://localhost:4000/2017/01/19/inteligencia-artificial-historia-industria/</guid>
        
        
        <category>IA</category>
        
      </item>
    
      <item>
        <title>Microsoft Azure Notebooks–Jupyter Notebooks as a Service</title>
        <description>&lt;p&gt;Essa é uma dica para a galera (que como eu), utiliza o Jupyter Notebooks como ferramenta de estudo ou trabalho.&lt;/p&gt;

&lt;p style=&quot;background-color: #35424a&quot;&gt;&lt;img title=&quot;capa&quot; style=&quot;border-left-width: 0px; border-right-width: 0px; background-image: none; border-bottom-width: 0px; float: none; padding-top: 0px; padding-left: 0px; margin-left: auto; display: block; padding-right: 0px; border-top-width: 0px; margin-right: auto&quot; alt=&quot;capa&quot; src=&quot;http://blob.vitormeriat.com.br/images/2016/10/capa.jpg&quot; width=&quot;752&quot; height=&quot;412&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Provavelmente se você está lendo isto, é por que já conhece o Jupyter Notebooks ou antigo IPython, e tem interesse em usar ou entender esta oferta. Caso você não conheça esta ferramenta, basta saber que o Jupyter Notebooks oferece um environment com suporte a várias linguagens de programação, incluindo Python, R, MATLAB e etc. Esta é uma ferramenta que caiu nas graças dos programadores por proporcionar um meio simples de programar, visualizar e documentar de maneira eficientes seus experimentos. Em breve escrevo algo específico sobre essa ferramenta aqui no blog.&lt;/p&gt;

&lt;p&gt;Por hora vamos analisar este serviço, que no momento em que escrevo este texto, está em PREVIEW.&lt;/p&gt;

&lt;p&gt;Creio que o primeiro passo é entregar algumas informações sobre o serviço. Até este momento os Notebooks estão rodando sobre environment Anaconda para o Python e Microsoft R Open para R. Sendo assim temos suporte aos pacotes já conhecidos no Anaconda. Algo muito importante de ressaltar é que temos a possibilidade de instalar pacotes de maneira normal (pip install), ou usando Conda (conda install). O mesmo vale para R.&lt;/p&gt;

&lt;h2 id=&quot;environments&quot;&gt;Environments&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Anaconda 4.1.0 para Python 2.7.11&lt;/li&gt;
  &lt;li&gt;Anaconda 4.1 para Python 3.5.1&lt;/li&gt;
  &lt;li&gt;MRO 3.3.0 para R&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;restrictions&quot;&gt;Restrictions&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;É possível acessar o github, PyPI, CRAN, OneDrive, DropBox, Google Drive e é claro, o Azure;&lt;/li&gt;
  &lt;li&gt;A memória é limitado a 4 GB;&lt;/li&gt;
  &lt;li&gt;Seus dados pode ter removido após 60 dias de inatividade;&lt;/li&gt;
  &lt;li&gt;Uso deve ser limitado a aprendizagem, investigação, computação em geral e etc. O que é meio lógico, já que o serviço (por hora gratuito), tem algumas limitações de processamento e privacidade.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;start&quot;&gt;Start&lt;/h2&gt;
&lt;p&gt;Para utilizar o serviço é algo tão simples quanto acessar o serviço e se autenticar no serviço.&lt;/p&gt;

&lt;p style=&quot;background-color: #35424a&quot;&gt;&lt;img title=&quot;azure-notebook-1&quot; style=&quot;border-top: 0px; border-right: 0px; background-image: none; border-bottom: 0px; float: none; padding-top: 0px; padding-left: 0px; margin-left: auto; border-left: 0px; display: block; padding-right: 0px; margin-right: auto&quot; alt=&quot;azure-notebook-1&quot; src=&quot;http://blob.vitormeriat.com.br/images/2016/10/azure-notebook-1.jpg&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Assim que você informar sua credencial, o serviço vai te solicitar a permissão para criar uma ID para sua conta no serviço. Diga sim e siga em frente…&lt;/p&gt;

&lt;p&gt;Assim que tudo estiver pronto, você deve ver uma tela como abaixo:&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;azure-notebook-2&quot; style=&quot;border-top: 0px; border-right: 0px; background-image: none; border-bottom: 0px; float: none; padding-top: 0px; padding-left: 0px; margin-left: auto; border-left: 0px; display: block; padding-right: 0px; margin-right: auto&quot; alt=&quot;azure-notebook-2&quot; src=&quot;http://blob.vitormeriat.com.br/images/2016/10/azure-notebook-2.jpg&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Done. Você já um ambiente pronto, e inclusive alguns exemplos para testar. De cara, uma coisa interessante notar é que podemos importar notebooks direto de nosso computador ou de uma URL.&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;azure-notebook-3&quot; style=&quot;border-top: 0px; border-right: 0px; background-image: none; border-bottom: 0px; float: none; padding-top: 0px; padding-left: 0px; margin-left: auto; border-left: 0px; display: block; padding-right: 0px; margin-right: auto&quot; alt=&quot;azure-notebook-3&quot; src=&quot;http://blob.vitormeriat.com.br/images/2016/10/azure-notebook-3.jpg&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Agora perceba que todos os nossos cadernos estão vinculados a uma biblioteca chamada &lt;strong&gt;Sample notebooks&lt;/strong&gt;. Sendo assim vamos criar uma biblioteca.&lt;/p&gt;

&lt;p&gt;Clique em &lt;strong&gt;My libraries&lt;/strong&gt;. Na página que se segue clique em &lt;strong&gt;New Library&lt;/strong&gt; e informe o nome, descrição e url personalizada.&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;azure-notebook-4&quot; style=&quot;border-top: 0px; border-right: 0px; background-image: none; border-bottom: 0px; float: none; padding-top: 0px; padding-left: 0px; margin-left: auto; border-left: 0px; display: block; padding-right: 0px; margin-right: auto&quot; alt=&quot;azure-notebook-4&quot; src=&quot;http://blob.vitormeriat.com.br/images/2016/10/azure-notebook-4.jpg&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Assim que sua biblioteca estiver criada você pode optar por importar um caderno ou abrir seu Jupyter Notebooks.&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;azure-notebook-5&quot; style=&quot;border-top: 0px; border-right: 0px; background-image: none; border-bottom: 0px; float: none; padding-top: 0px; padding-left: 0px; margin-left: auto; border-left: 0px; display: block; padding-right: 0px; margin-right: auto&quot; alt=&quot;azure-notebook-5&quot; src=&quot;http://blob.vitormeriat.com.br/images/2016/10/azure-notebook-5.jpg&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Agora estamos em terreno conhecido. É só criar um novo Notebook usando Py2, Py3 ou R.&lt;/p&gt;

&lt;p&gt;No próximo post vou mostrar como instalar pacotes de Python, R e como compartilhar sua biblioteca de forma pública.&lt;/p&gt;

&lt;div style=&quot;margin-bottom: 5em;&quot;&gt;&lt;/div&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;A princípio vale notar que esta é uma ferramenta em preview. Sendo assim está em desenvolvimento ativo. Acho que hoje é uma maneira muito válida de compartilhar seus cadernos em um ambiente pronto para execução. Vejo uma ótima oportunidade para ensino aqui. Creio que em breve o serviço deve evoluir para ofertas com alto poder de processamento e armazenamento. Digo isso por que hoje já conseguimos utilizar e integrar nossos cadernos com o Azure Machine Learning, logo, creio que a intenção da Microsoft seja mais que apenas oferecer um local para treinar e repositar experimentos na nuvem… espero ;)&lt;/p&gt;
</description>
        <pubDate>Thu, 20 Oct 2016 00:00:00 -0200</pubDate>
        <link>http://localhost:4000/2016/10/20/microsoft-azure-notebooksjupyter-notebooks-as-a-service/</link>
        <guid isPermaLink="true">http://localhost:4000/2016/10/20/microsoft-azure-notebooksjupyter-notebooks-as-a-service/</guid>
        
        
        <category>Data Science</category>
        
        <category>Machine Learning</category>
        
        <category>Python</category>
        
      </item>
    
      <item>
        <title>IoT Weekend Recife 2016 - Como a Inteligência Artificial vai mudar a Internet das Coisas</title>
        <description>&lt;p&gt;Olá pessoal, hoje, dia 06 de agosto de 2016 tive mais uma vez o privilégio de palestrar no IoT Weekend edição Recife. Esta é segunda vez em Recife e quarta edição geral do evento, que é inteiramente dedicado a Internet of Things, abrangendo do ponto de vista dos negócios aos famoso under the hood dos detalhes técnicos.&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;capa&quot; alt=&quot;capa&quot; src=&quot;http://blob.vitormeriat.com.br/images/2016/08/capa.png&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Esta edição vez estive falando novamente sobre Inteligência, dessa vez abordando como inteligência artificial está mudando a maneira como fazemos e pensamos na internet das coisas, com uma visão mais abrangente sobre o tema.&lt;/p&gt;

&lt;p&gt;Em suma nessa sessão tentei mostrar como os players atuais do mercado moldaram suas ferramentas e principalmente como isto pode lhe auxiliar no desenvolvimento de dispositivos cada vez mais inteligentes ou por que não dizer, cognitivos ou que aprendem.&lt;/p&gt;

&lt;p&gt;Alguns termos como a própria cognição parecem ser algo místico, porém fazendo um resumo rápido da história da computação, as máquinas mais antigas eram capazes de fazer cálculos. Anos depois, surgiram os sistemas programáveis, que são aqueles utilizados até hoje em nossos celulares, por exemplo. Os próximos passos, como por exemplo a computação cognitiva, trazem uma tecnologia capaz de processar informações e de aprender com elas de forma muito semelhante ao cérebro humano, sem que precisem ser programadas para tal.&lt;/p&gt;

&lt;p&gt;Existem uma série de outros temas a respeito, coisas que pretendo compartilhar em breve aqui no blog.&lt;/p&gt;

&lt;h3 id=&quot;ref&quot;&gt;Ref&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;http://www.iotweekend.com.br/&quot; target=&quot;_blank&quot;&gt;IoT Weekend&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Sat, 06 Aug 2016 00:00:00 -0300</pubDate>
        <link>http://localhost:4000/2016/08/06/iot-weekend-recife-2016-como-a-inteligncia-artificial-vai-mudar-a-internet-das-coisas/</link>
        <guid isPermaLink="true">http://localhost:4000/2016/08/06/iot-weekend-recife-2016-como-a-inteligncia-artificial-vai-mudar-a-internet-das-coisas/</guid>
        
        
        <category>Comunidade</category>
        
      </item>
    
  </channel>
</rss>
